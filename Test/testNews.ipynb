{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finvizfinance.quote import finvizfinance\n",
    "ticker = 'NFLX'\n",
    "stock = finvizfinance(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Tickers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-03-05 20:56:00</td>\n",
       "      <td>Netflix making live-action 'One Piece' from po...</td>\n",
       "      <td>https://finance.yahoo.com/news/netflix-making-...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-03-05 15:06:00</td>\n",
       "      <td>Britain's Prince Harry invited to King Charles...</td>\n",
       "      <td>https://finance.yahoo.com/news/britains-prince...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-03-05 08:38:00</td>\n",
       "      <td>Chris Rock Slaps Back in Netflixs First Live C...</td>\n",
       "      <td>https://finance.yahoo.com/m/40e4ae24-8fb3-3d6c...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-03-05 00:32:00</td>\n",
       "      <td>Chris Rock unleashes on Will Smith and wife Ja...</td>\n",
       "      <td>https://finance.yahoo.com/news/chris-rock-unle...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-03-03 15:44:00</td>\n",
       "      <td>Netflix is still Netflix as they produce live ...</td>\n",
       "      <td>https://finance.yahoo.com/video/netflix-still-...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-02-12 10:31:00</td>\n",
       "      <td>2 Stocks That Are Fantastic Deals Right Now</td>\n",
       "      <td>https://finance.yahoo.com/m/6aa18f20-0dfb-359d...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2023-02-12 07:31:00</td>\n",
       "      <td>1 Growth Stock to Buy in 2023, and 1 to Avoid ...</td>\n",
       "      <td>https://finance.yahoo.com/m/28459ca2-4694-3433...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2023-02-12 07:15:00</td>\n",
       "      <td>A Bull Market Is Coming: 1 FAANG Stock to Avoi...</td>\n",
       "      <td>https://finance.yahoo.com/m/f14b0c34-cc79-32c3...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2023-02-11 17:05:00</td>\n",
       "      <td>Is Netflix Stock A Buy After Video Streamer's ...</td>\n",
       "      <td>https://finance.yahoo.com/m/815ee59a-c296-3fd4...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2023-02-11 10:19:00</td>\n",
       "      <td>Warner Bros. Discovery Makes a Dramatic Strate...</td>\n",
       "      <td>https://finance.yahoo.com/m/03409878-5987-3605...</td>\n",
       "      <td>NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                                              Title  \\\n",
       "0  2023-03-05 20:56:00  Netflix making live-action 'One Piece' from po...   \n",
       "1  2023-03-05 15:06:00  Britain's Prince Harry invited to King Charles...   \n",
       "2  2023-03-05 08:38:00  Chris Rock Slaps Back in Netflixs First Live C...   \n",
       "3  2023-03-05 00:32:00  Chris Rock unleashes on Will Smith and wife Ja...   \n",
       "4  2023-03-03 15:44:00  Netflix is still Netflix as they produce live ...   \n",
       "..                 ...                                                ...   \n",
       "95 2023-02-12 10:31:00        2 Stocks That Are Fantastic Deals Right Now   \n",
       "96 2023-02-12 07:31:00  1 Growth Stock to Buy in 2023, and 1 to Avoid ...   \n",
       "97 2023-02-12 07:15:00  A Bull Market Is Coming: 1 FAANG Stock to Avoi...   \n",
       "98 2023-02-11 17:05:00  Is Netflix Stock A Buy After Video Streamer's ...   \n",
       "99 2023-02-11 10:19:00  Warner Bros. Discovery Makes a Dramatic Strate...   \n",
       "\n",
       "                                                 Link Tickers  \n",
       "0   https://finance.yahoo.com/news/netflix-making-...    NFLX  \n",
       "1   https://finance.yahoo.com/news/britains-prince...    NFLX  \n",
       "2   https://finance.yahoo.com/m/40e4ae24-8fb3-3d6c...    NFLX  \n",
       "3   https://finance.yahoo.com/news/chris-rock-unle...    NFLX  \n",
       "4   https://finance.yahoo.com/video/netflix-still-...    NFLX  \n",
       "..                                                ...     ...  \n",
       "95  https://finance.yahoo.com/m/6aa18f20-0dfb-359d...    NFLX  \n",
       "96  https://finance.yahoo.com/m/28459ca2-4694-3433...    NFLX  \n",
       "97  https://finance.yahoo.com/m/f14b0c34-cc79-32c3...    NFLX  \n",
       "98  https://finance.yahoo.com/m/815ee59a-c296-3fd4...    NFLX  \n",
       "99  https://finance.yahoo.com/m/03409878-5987-3605...    NFLX  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = stock.ticker_news()\n",
    "news_df['Tickers'] = ticker\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Status</th>\n",
       "      <th>Outer</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Argus</td>\n",
       "      <td>Buy</td>\n",
       "      <td>$340 → $390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Wolfe Research</td>\n",
       "      <td>Outperform</td>\n",
       "      <td>$366 → $417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Wedbush</td>\n",
       "      <td>Outperform</td>\n",
       "      <td>$400 → $410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>The Benchmark Company</td>\n",
       "      <td>Sell</td>\n",
       "      <td>$225 → $250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Robert W. Baird</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>$275 → $325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Pivotal Research Group</td>\n",
       "      <td>Buy</td>\n",
       "      <td>$375 → $400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Piper Sandler</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>$270 → $325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Oppenheimer</td>\n",
       "      <td>Outperform</td>\n",
       "      <td>$400 → $415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>MoffettNathanson</td>\n",
       "      <td>Market Perform</td>\n",
       "      <td>$240 → $250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Jefferies</td>\n",
       "      <td>Buy</td>\n",
       "      <td>$385 → $400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Guggenheim</td>\n",
       "      <td>Buy</td>\n",
       "      <td>$305 → $375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Goldman</td>\n",
       "      <td>Sell</td>\n",
       "      <td>$225 → $230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Evercore ISI</td>\n",
       "      <td>Outperform</td>\n",
       "      <td>$340 → $400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Deutsche Bank</td>\n",
       "      <td>Buy</td>\n",
       "      <td>$350 → $400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Canaccord Genuity</td>\n",
       "      <td>Buy</td>\n",
       "      <td>$365 → $400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>Jefferies</td>\n",
       "      <td>Hold → Buy</td>\n",
       "      <td>$310 → $385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>Initiated</td>\n",
       "      <td>New Street</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>$304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-12-29</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>CFRA</td>\n",
       "      <td>Sell → Buy</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>Reiterated</td>\n",
       "      <td>Jefferies</td>\n",
       "      <td>Hold</td>\n",
       "      <td>$250 → $310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-12-09</td>\n",
       "      <td>Upgrade</td>\n",
       "      <td>Wells Fargo</td>\n",
       "      <td>Equal Weight → Overweight</td>\n",
       "      <td>$300 → $400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Status                   Outer                     Rating  \\\n",
       "0  2023-01-23  Reiterated                   Argus                        Buy   \n",
       "1  2023-01-20  Reiterated          Wolfe Research                 Outperform   \n",
       "2  2023-01-20  Reiterated                 Wedbush                 Outperform   \n",
       "3  2023-01-20  Reiterated   The Benchmark Company                       Sell   \n",
       "4  2023-01-20  Reiterated         Robert W. Baird                    Neutral   \n",
       "5  2023-01-20  Reiterated  Pivotal Research Group                        Buy   \n",
       "6  2023-01-20  Reiterated           Piper Sandler                    Neutral   \n",
       "7  2023-01-20  Reiterated             Oppenheimer                 Outperform   \n",
       "8  2023-01-20  Reiterated        MoffettNathanson             Market Perform   \n",
       "9  2023-01-20  Reiterated               Jefferies                        Buy   \n",
       "10 2023-01-20  Reiterated              Guggenheim                        Buy   \n",
       "11 2023-01-20  Reiterated                 Goldman                       Sell   \n",
       "12 2023-01-20  Reiterated            Evercore ISI                 Outperform   \n",
       "13 2023-01-20  Reiterated           Deutsche Bank                        Buy   \n",
       "14 2023-01-20  Reiterated       Canaccord Genuity                        Buy   \n",
       "15 2023-01-12     Upgrade               Jefferies                 Hold → Buy   \n",
       "16 2023-01-04   Initiated              New Street                    Neutral   \n",
       "17 2022-12-29     Upgrade                    CFRA                 Sell → Buy   \n",
       "18 2022-12-14  Reiterated               Jefferies                       Hold   \n",
       "19 2022-12-09     Upgrade             Wells Fargo  Equal Weight → Overweight   \n",
       "\n",
       "          Price  \n",
       "0   $340 → $390  \n",
       "1   $366 → $417  \n",
       "2   $400 → $410  \n",
       "3   $225 → $250  \n",
       "4   $275 → $325  \n",
       "5   $375 → $400  \n",
       "6   $270 → $325  \n",
       "7   $400 → $415  \n",
       "8   $240 → $250  \n",
       "9   $385 → $400  \n",
       "10  $305 → $375  \n",
       "11  $225 → $230  \n",
       "12  $340 → $400  \n",
       "13  $350 → $400  \n",
       "14  $365 → $400  \n",
       "15  $310 → $385  \n",
       "16         $304  \n",
       "17               \n",
       "18  $250 → $310  \n",
       "19  $300 → $400  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_ratings_df = stock.ticker_outer_ratings()\n",
    "outer_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myfinance\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39myf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ticker\u001b[39m=\u001b[39m get_data(\u001b[39m\"\u001b[39m\u001b[39mamzn\u001b[39m\u001b[39m\"\u001b[39m, start_date\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m12/04/2009\u001b[39m\u001b[39m\"\u001b[39m, end_date\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m12/04/2019\u001b[39m\u001b[39m\"\u001b[39m, index_as_date \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m, interval\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m1wk\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m ticker\u001b[39m.\u001b[39minfo\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_data' is not defined"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "ticker= get_data(\"amzn\", start_date=\"12/04/2009\", end_date=\"12/04/2019\", index_as_date = True, interval=\"1wk\")\n",
    "ticker.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yahoo_fin.stock_info as si\n",
    "dow_list = si.tickers_nasdaq()\n",
    "print(\"Tickers in NasdaQ:\", len(dow_list))\n",
    "dow_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yahoo_fin.stock_info as si\n",
    "si.get_analysts_info('nflx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import *\n",
    "import yfinance as yf\n",
    "nasdaq = tickers_nasdaq()\n",
    "nasdaq_list = nasdaq[:10]\n",
    "for i in nasdaq_list:\n",
    "    ticker = yf.download(i,interval='1m',period='1d',progress=False)\n",
    "    ticker['Ticker'] = i\n",
    "    print(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yahoo_fin.stock_info import *\n",
    "import yfinance as yf\n",
    "ticker = \"ACE.BK\"\n",
    "data = yf.Ticker(ticker)\n",
    "data.news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "\n",
    "url = 'https://www.nasdaq.com/articles/will-roku-stock-break-hearts-this-week'\n",
    "headers = {\n",
    "    'User-Agent': 'Chrome/58.0.3029.110'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.content, 'lxml')\n",
    "data = soup.find('h1', class_='jupiter22-c-hero-article-title')\n",
    "\n",
    "if data:\n",
    "    print(data.text)\n",
    "else:\n",
    "    print('Could not find the data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "from unittest.mock import patch,MagicMock\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "def save_data_news(data):\n",
    "    # connect to the database\n",
    "    conn = sqlite3.connect('stock.sqlite')\n",
    "    # save the data to the database\n",
    "    data.to_sql('stock_news',con=conn,if_exists='append',index=False)\n",
    "    # close the connection\n",
    "    conn.close()\n",
    "df2 = pd.DataFrame()\n",
    "df1 = pd.DataFrame({'Datetime': ['2023-02-19'], 'Title':['ทอท.'], 'Link':['Test'], 'Body':['Test'], 'Ticker':['AOT']})\n",
    "df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "save_data_news(df2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "\n",
    "content_news = []\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = conn.cursor()\n",
    "query = \"SELECT Ticker FROM stock_info\"\n",
    "r_df = pd.read_sql(query, conn)\n",
    "list_db = r_df['Ticker'].values.tolist()\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "for i in list_db:\n",
    "    query2 = \"SELECT Datetime,ticker,body FROM stock_news WHERE `Ticker` = '%s'\" % i\n",
    "    news = pd.read_sql(query2, conn)\n",
    "    if not(news.empty):\n",
    "        df2 = pd.concat([df2,news],ignore_index=True)\n",
    "    \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    " \n",
    "# essential entity models downloads\n",
    "nltk.downloader.download('maxent_ne_chunker')\n",
    "nltk.downloader.download('words')\n",
    "nltk.downloader.download('treebank')\n",
    "nltk.downloader.download('maxent_treebank_pos_tagger')\n",
    "nltk.downloader.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>19.078545</td>\n",
       "      <td>72.878176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>28.651718</td>\n",
       "      <td>77.221939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>London</td>\n",
       "      <td>51.507336</td>\n",
       "      <td>-0.127650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Munich</td>\n",
       "      <td>48.137108</td>\n",
       "      <td>11.575382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>76.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city        lat       long\n",
       "0   Mumbai  19.078545  72.878176\n",
       "1    Delhi  28.651718  77.221939\n",
       "2   London  51.507336  -0.127650\n",
       "3   Munich  48.137108  11.575382\n",
       "4  Haryana  29.000000  76.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import locationtagger\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# initializing sample text\n",
    "sample_text = \"India has very rich and vivid culture\\\n",
    "       widely spread from Kerala to Nagaland to Haryana to Maharashtra. \" \\\n",
    "       \"Delhi being capital with Mumbai financial capital.\\\n",
    "       Can be said better than some western cities such as \" \\\n",
    "       \" Munich, London etc. Pakistan and Bangladesh share its borders\"\n",
    "\n",
    "def getcity_to_latlong(text):\n",
    "    # extracting entities.\n",
    "    place_entity = locationtagger.find_locations(text = text)\n",
    "\n",
    "    # calling the Nominatim tool\n",
    "    loc = Nominatim(user_agent=\"GetLoc\")\n",
    "    address = pd.DataFrame()\n",
    "\n",
    "    for i in place_entity.cities:\n",
    "        getLoc = loc.geocode(i)\n",
    "        ones = pd.DataFrame({'city':[i],'lat':[getLoc.latitude],'long':[getLoc.longitude]})\n",
    "        # getting all cities\n",
    "        address = pd.concat([address,ones],ignore_index=True)\n",
    "    return address\n",
    "\n",
    "getcity_to_latlong(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40876\n"
     ]
    }
   ],
   "source": [
    "a = len(df2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place = pd.DataFrame()\n",
    "count = 10000\n",
    "a = len(df2)\n",
    "#5529, 7218, 7249 error \n",
    "try:\n",
    "    for i in range(10000,a):\n",
    "        # if count < 5000:\n",
    "        #     data = getcity_to_latlong(df2.iloc[i]['Body'])\n",
    "        #     data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "        #     data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "        #     place = pd.concat([place,data],ignore_index=True)\n",
    "        # if count >= 5000 and count < 10000:\n",
    "        #     data = getcity_to_latlong(df2.iloc[i]['Body'])\n",
    "        #     data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "        #     data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "        #     place = pd.concat([place,data],ignore_index=True)\n",
    "        if count >= 10000 and count < 15000:\n",
    "            data = getcity_to_latlong(df2.iloc[i]['Body'])\n",
    "            data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "            data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "            place = pd.concat([place,data],ignore_index=True)\n",
    "        # if count >= 15000 and count < 20000:\n",
    "        #     data = getcity_to_latlong(df2.iloc[i]['Body'])\n",
    "        #     data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "        #     data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "        #     place = pd.concat([place,data],ignore_index=True)\n",
    "        # if count >= 20000:\n",
    "        #     data = getcity_to_latlong(df2.iloc[i]['Body'])\n",
    "        #     data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "        #     data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "        #     place = pd.concat([place,data],ignore_index=True)\n",
    "        else:\n",
    "            break\n",
    "        count += 1\n",
    "except:\n",
    "    pass\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# เพื่อ save ระวังข้อมูลซ้ำด้วยเด้อ\n",
    "import sqlite3\n",
    "\n",
    "address = place\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "address.to_sql('stock_city',con=conn,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Access</td>\n",
       "      <td>38.209249</td>\n",
       "      <td>-83.071005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen</td>\n",
       "      <td>40.807780</td>\n",
       "      <td>-84.057222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Almaty</td>\n",
       "      <td>43.236392</td>\n",
       "      <td>76.945728</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>America</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bank</td>\n",
       "      <td>51.513105</td>\n",
       "      <td>-0.089375</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Barron</td>\n",
       "      <td>45.423557</td>\n",
       "      <td>-91.845410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bristol</td>\n",
       "      <td>51.453802</td>\n",
       "      <td>-2.597298</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Calgary</td>\n",
       "      <td>51.046095</td>\n",
       "      <td>-114.065465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>California</td>\n",
       "      <td>36.701463</td>\n",
       "      <td>-118.755997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Canada</td>\n",
       "      <td>61.066692</td>\n",
       "      <td>-107.991707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandler</td>\n",
       "      <td>33.306203</td>\n",
       "      <td>-111.841185</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>51.487517</td>\n",
       "      <td>-0.168701</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chevron</td>\n",
       "      <td>50.382266</td>\n",
       "      <td>5.731471</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Colorado</td>\n",
       "      <td>38.725178</td>\n",
       "      <td>-105.607716</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Colorado Springs</td>\n",
       "      <td>38.833958</td>\n",
       "      <td>-104.825348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Columbia</td>\n",
       "      <td>4.099917</td>\n",
       "      <td>-72.908813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>38.692045</td>\n",
       "      <td>-75.401331</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dow</td>\n",
       "      <td>52.200158</td>\n",
       "      <td>0.124222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>England</td>\n",
       "      <td>52.531021</td>\n",
       "      <td>-1.264906</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Estepona</td>\n",
       "      <td>36.426807</td>\n",
       "      <td>-5.146848</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Four</td>\n",
       "      <td>45.587454</td>\n",
       "      <td>5.193922</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>German</td>\n",
       "      <td>51.163818</td>\n",
       "      <td>10.447831</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Globe</td>\n",
       "      <td>41.990376</td>\n",
       "      <td>-71.523673</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Graham</td>\n",
       "      <td>35.359542</td>\n",
       "      <td>-83.833778</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>22.279328</td>\n",
       "      <td>114.162813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kyiv</td>\n",
       "      <td>50.450034</td>\n",
       "      <td>30.524136</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Kyoto</td>\n",
       "      <td>35.021041</td>\n",
       "      <td>135.755607</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Lexington</td>\n",
       "      <td>38.046407</td>\n",
       "      <td>-84.497039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>London</td>\n",
       "      <td>51.507336</td>\n",
       "      <td>-0.127650</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Lynnwood</td>\n",
       "      <td>47.827866</td>\n",
       "      <td>-122.305393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>March</td>\n",
       "      <td>48.057857</td>\n",
       "      <td>7.779004</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Moderna</td>\n",
       "      <td>-8.432199</td>\n",
       "      <td>-37.411924</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Moscow</td>\n",
       "      <td>55.750446</td>\n",
       "      <td>37.617494</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Needham</td>\n",
       "      <td>31.986829</td>\n",
       "      <td>-88.333088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>New York</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Norfolk</td>\n",
       "      <td>52.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>North</td>\n",
       "      <td>8.771279</td>\n",
       "      <td>13.780363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>50.000678</td>\n",
       "      <td>-86.000977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Paris</td>\n",
       "      <td>48.858890</td>\n",
       "      <td>2.320041</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Potter</td>\n",
       "      <td>35.368335</td>\n",
       "      <td>-101.877658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Purchase</td>\n",
       "      <td>41.040931</td>\n",
       "      <td>-73.714575</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Russia</td>\n",
       "      <td>64.686314</td>\n",
       "      <td>97.745306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>59.927299</td>\n",
       "      <td>30.361444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Santa Clara</td>\n",
       "      <td>37.233325</td>\n",
       "      <td>-121.684635</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Saskatoon</td>\n",
       "      <td>52.131802</td>\n",
       "      <td>-106.660767</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Sens</td>\n",
       "      <td>48.197856</td>\n",
       "      <td>3.282606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>46.193239</td>\n",
       "      <td>-82.347307</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Street</td>\n",
       "      <td>51.126749</td>\n",
       "      <td>-2.739722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Strong</td>\n",
       "      <td>33.110360</td>\n",
       "      <td>-92.356579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Tornado</td>\n",
       "      <td>38.342872</td>\n",
       "      <td>-81.844296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Toronto</td>\n",
       "      <td>43.653482</td>\n",
       "      <td>-79.383935</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Us</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>37.123224</td>\n",
       "      <td>-78.492772</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Washington</td>\n",
       "      <td>38.895037</td>\n",
       "      <td>-77.036543</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city        lat        long  population\n",
       "0             Access  38.209249  -83.071005           1\n",
       "1              Allen  40.807780  -84.057222           1\n",
       "2             Almaty  43.236392   76.945728           1\n",
       "3            America  39.783730 -100.445882           1\n",
       "4               Bank  51.513105   -0.089375           2\n",
       "5             Barron  45.423557  -91.845410           1\n",
       "6            Bristol  51.453802   -2.597298           1\n",
       "7            Calgary  51.046095 -114.065465           1\n",
       "8         California  36.701463 -118.755997           1\n",
       "9             Canada  61.066692 -107.991707           1\n",
       "10          Chandler  33.306203 -111.841185           1\n",
       "11           Chelsea  51.487517   -0.168701           1\n",
       "12           Chevron  50.382266    5.731471           1\n",
       "13          Colorado  38.725178 -105.607716           1\n",
       "14  Colorado Springs  38.833958 -104.825348           1\n",
       "15          Columbia   4.099917  -72.908813           1\n",
       "16          Delaware  38.692045  -75.401331           1\n",
       "17               Dow  52.200158    0.124222           1\n",
       "18           England  52.531021   -1.264906           1\n",
       "19          Estepona  36.426807   -5.146848           1\n",
       "20              Four  45.587454    5.193922           1\n",
       "21            German  51.163818   10.447831           2\n",
       "22             Globe  41.990376  -71.523673          11\n",
       "23            Graham  35.359542  -83.833778           1\n",
       "24         Hong Kong  22.279328  114.162813           1\n",
       "25              Kyiv  50.450034   30.524136           1\n",
       "26             Kyoto  35.021041  135.755607           1\n",
       "27         Lexington  38.046407  -84.497039           1\n",
       "28            London  51.507336   -0.127650           2\n",
       "29          Lynnwood  47.827866 -122.305393           1\n",
       "30             March  48.057857    7.779004           3\n",
       "31           Moderna  -8.432199  -37.411924           2\n",
       "32            Moscow  55.750446   37.617494           1\n",
       "33           Needham  31.986829  -88.333088           1\n",
       "34          New York  40.712728  -74.006015           4\n",
       "35           Norfolk  52.666667    1.000000           1\n",
       "36             North   8.771279   13.780363           1\n",
       "37           Ontario  50.000678  -86.000977           1\n",
       "38             Paris  48.858890    2.320041           1\n",
       "39            Potter  35.368335 -101.877658           1\n",
       "40          Purchase  41.040931  -73.714575           2\n",
       "41            Russia  64.686314   97.745306           1\n",
       "42           Samsung  59.927299   30.361444           1\n",
       "43       Santa Clara  37.233325 -121.684635           1\n",
       "44         Saskatoon  52.131802 -106.660767           1\n",
       "45              Sens  48.197856    3.282606           1\n",
       "46           Spanish  46.193239  -82.347307           1\n",
       "47            Street  51.126749   -2.739722           1\n",
       "48            Strong  33.110360  -92.356579           1\n",
       "49           Tornado  38.342872  -81.844296           1\n",
       "50           Toronto  43.653482  -79.383935           1\n",
       "51                Us  39.783730 -100.445882           4\n",
       "52          Virginia  37.123224  -78.492772           1\n",
       "53        Washington  38.895037  -77.036543           2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = place\n",
    "add = address.groupby(address.columns.tolist(),as_index=False).size()\n",
    "add.rename(columns={'size': 'population'}, inplace=True)\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "df = add\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df['long'], df['lat'])]\n",
    "gdf = GeoDataFrame(df, geometry=geometry)   \n",
    "gdf['Size'] = gdf['population'] * 20\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(figsize=(20, 10),color='black', edgecolor='black')\n",
    "a = gdf.plot(ax=base, marker='o', column='population', cmap = 'Reds', markersize='Size',legend=True)\n",
    "a.set_facecolor(\"lightslategray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "แปลภาษาไทย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>ผู้สื่อข่าวรายงานว่า วันนี้(6 ก.พ.) เป็นวันแรก...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-02 00:00:00</td>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>นายกรภัทร วรเชษฐ์ ผู้อำนวยการ ฝ่ายวิจัยและการบ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>ADVERTISEMENT\\nบริษัทหลักทรัพย์ ไอร่า จำกัด ระ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>ADVERTISEMENT\\n บล.โนมูระ พัฒนสิน ระบุในบทวิเค...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30 00:00:00</td>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>อาการ “กลืนไม่เข้า…คายไม่ออก” ของเหล่าบรรดา “ผ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>2023-02-23 00:00:00</td>\n",
       "      <td>WHA.BK</td>\n",
       "      <td>บริษัท ดับบลิวเอชเอ คอร์ปอเรชั่น จำกัด (มหาชน...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7984</th>\n",
       "      <td>2023-02-23 00:00:00</td>\n",
       "      <td>WHA.BK</td>\n",
       "      <td>บริษัท ดับบลิวเอชเอ คอร์ปอเรชั่น จำกัด (มหาชน...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7985</th>\n",
       "      <td>2023-02-22 00:00:00</td>\n",
       "      <td>WHA.BK</td>\n",
       "      <td>บล.ดาโอ ระบุในบทวิเคราะห์วันนี้ (22 ก.พ.66) ว...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7986</th>\n",
       "      <td>2023-02-22 00:00:00</td>\n",
       "      <td>WHA.BK</td>\n",
       "      <td>ผู้สื่อข่าวรายงานว่า บริษัท บีดับบลิวเอฟ (ไทย...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7987</th>\n",
       "      <td>2023-02-22 00:00:00</td>\n",
       "      <td>WHA.BK</td>\n",
       "      <td>ก่อนอื่นต้องเรียนมิตรสหายให้ทราบตามตรงว่า “โม...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7988 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Datetime  Ticker  \\\n",
       "0     2023-02-06 00:00:00  AAV.BK   \n",
       "1     2023-02-02 00:00:00  AAV.BK   \n",
       "2     2023-02-01 00:00:00  AAV.BK   \n",
       "3     2023-01-31 00:00:00  AAV.BK   \n",
       "4     2023-01-30 00:00:00  AAV.BK   \n",
       "...                   ...     ...   \n",
       "7983  2023-02-23 00:00:00  WHA.BK   \n",
       "7984  2023-02-23 00:00:00  WHA.BK   \n",
       "7985  2023-02-22 00:00:00  WHA.BK   \n",
       "7986  2023-02-22 00:00:00  WHA.BK   \n",
       "7987  2023-02-22 00:00:00  WHA.BK   \n",
       "\n",
       "                                                   Body  \n",
       "0     ผู้สื่อข่าวรายงานว่า วันนี้(6 ก.พ.) เป็นวันแรก...  \n",
       "1     นายกรภัทร วรเชษฐ์ ผู้อำนวยการ ฝ่ายวิจัยและการบ...  \n",
       "2     ADVERTISEMENT\\nบริษัทหลักทรัพย์ ไอร่า จำกัด ระ...  \n",
       "3     ADVERTISEMENT\\n บล.โนมูระ พัฒนสิน ระบุในบทวิเค...  \n",
       "4     อาการ “กลืนไม่เข้า…คายไม่ออก” ของเหล่าบรรดา “ผ...  \n",
       "...                                                 ...  \n",
       "7983   บริษัท ดับบลิวเอชเอ คอร์ปอเรชั่น จำกัด (มหาชน...  \n",
       "7984   บริษัท ดับบลิวเอชเอ คอร์ปอเรชั่น จำกัด (มหาชน...  \n",
       "7985   บล.ดาโอ ระบุในบทวิเคราะห์วันนี้ (22 ก.พ.66) ว...  \n",
       "7986   ผู้สื่อข่าวรายงานว่า บริษัท บีดับบลิวเอฟ (ไทย...  \n",
       "7987   ก่อนอื่นต้องเรียนมิตรสหายให้ทราบตามตรงว่า “โม...  \n",
       "\n",
       "[7988 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import yfinance as yf\n",
    "\n",
    "content_news = []\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = conn.cursor()\n",
    "query = \"SELECT Ticker FROM stock_info WHERE `Index` = 'SET100'\"\n",
    "r_df = pd.read_sql(query, conn)\n",
    "list_db = r_df['Ticker'].values.tolist()\n",
    "thai = []\n",
    "df2 = pd.DataFrame()\n",
    "for j in list_db:\n",
    "    query2 = \"SELECT Datetime,ticker,body FROM stock_news WHERE `Ticker` = '%s'\" % j\n",
    "    news = pd.read_sql(query2, conn)\n",
    "    if not(news.empty):\n",
    "        df2 = pd.concat([df2,news],ignore_index=True)\n",
    "    \n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>Reporters reported that today (6 February) is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-02 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>Mr. Kornpat Worachet, Director of Research and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-01 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>Advertisement \\n Ira Securities Company Limite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-31 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>Advertisement \\n  Nomura Pattanasin Securities...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-30 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>Symptoms \"Swallow ... \"The guardian of Santira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2023-01-30 00:00:00</td>\n",
       "      <td>ADVANC</td>\n",
       "      <td>The Thai stock market index is closed at 1,681...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2023-01-30 00:00:00</td>\n",
       "      <td>ADVANC</td>\n",
       "      <td>Advertisement \\n Heng Heng shares \\n If we wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2023-01-25 00:00:00</td>\n",
       "      <td>ADVANC</td>\n",
       "      <td>Mr. Warun Thep Watcharaporn, Head of Business ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>2023-01-25 00:00:00</td>\n",
       "      <td>ADVANC</td>\n",
       "      <td>Overall, the global economy seems to have redu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2023-01-23 00:00:00</td>\n",
       "      <td>ADVANC</td>\n",
       "      <td>Pie Securities Public Company Limited or \"PI\" ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Datetime  Ticker  \\\n",
       "0   2023-02-06 00:00:00     AAV   \n",
       "1   2023-02-02 00:00:00     AAV   \n",
       "2   2023-02-01 00:00:00     AAV   \n",
       "3   2023-01-31 00:00:00     AAV   \n",
       "4   2023-01-30 00:00:00     AAV   \n",
       "..                  ...     ...   \n",
       "91  2023-01-30 00:00:00  ADVANC   \n",
       "92  2023-01-30 00:00:00  ADVANC   \n",
       "93  2023-01-25 00:00:00  ADVANC   \n",
       "94  2023-01-25 00:00:00  ADVANC   \n",
       "95  2023-01-23 00:00:00  ADVANC   \n",
       "\n",
       "                                                  Eng  \n",
       "0   Reporters reported that today (6 February) is ...  \n",
       "1   Mr. Kornpat Worachet, Director of Research and...  \n",
       "2   Advertisement \\n Ira Securities Company Limite...  \n",
       "3   Advertisement \\n  Nomura Pattanasin Securities...  \n",
       "4   Symptoms \"Swallow ... \"The guardian of Santira...  \n",
       "..                                                ...  \n",
       "91  The Thai stock market index is closed at 1,681...  \n",
       "92  Advertisement \\n Heng Heng shares \\n If we wan...  \n",
       "93  Mr. Warun Thep Watcharaporn, Head of Business ...  \n",
       "94  Overall, the global economy seems to have redu...  \n",
       "95  Pie Securities Public Company Limited or \"PI\" ...  \n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import translators as ts\n",
    "import translators.server as tss\n",
    "import pandas as pd\n",
    "\n",
    "count = 0\n",
    "a = len(df2)\n",
    "data_thai = pd.DataFrame()\n",
    "for i in range(a):\n",
    "    try:\n",
    "        data = pd.DataFrame({'Datetime':[df2.iloc[i]['Datetime']],'Ticker':[df2.iloc[i]['Ticker']],'Eng':[tss.google(df2.iloc[i]['Body'])]})\n",
    "        # data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "        # data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "        data_thai = pd.concat([data_thai,data],ignore_index=True)\n",
    "    except:\n",
    "        pass\n",
    "data_thai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phuket</td>\n",
       "      <td>7.936602</td>\n",
       "      <td>98.352929</td>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Egypt</td>\n",
       "      <td>26.254049</td>\n",
       "      <td>29.267547</td>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cuba</td>\n",
       "      <td>23.013134</td>\n",
       "      <td>-80.832875</td>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>1.357107</td>\n",
       "      <td>103.819499</td>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Russia</td>\n",
       "      <td>64.686314</td>\n",
       "      <td>97.745306</td>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Phuket</td>\n",
       "      <td>7.936602</td>\n",
       "      <td>98.352929</td>\n",
       "      <td>2022-11-14 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Chiang Mai</td>\n",
       "      <td>18.788278</td>\n",
       "      <td>98.985880</td>\n",
       "      <td>2022-11-14 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>Don Mueang</td>\n",
       "      <td>13.922654</td>\n",
       "      <td>100.600997</td>\n",
       "      <td>2022-11-14 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Us</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>2022-11-14 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>Power</td>\n",
       "      <td>42.676908</td>\n",
       "      <td>-112.886978</td>\n",
       "      <td>2022-11-14 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           city        lat        long             Datetime Ticker\n",
       "0        Phuket   7.936602   98.352929  2023-02-06 00:00:00    AAV\n",
       "1         Egypt  26.254049   29.267547  2023-02-06 00:00:00    AAV\n",
       "2          Cuba  23.013134  -80.832875  2023-02-06 00:00:00    AAV\n",
       "3     Singapore   1.357107  103.819499  2023-02-06 00:00:00    AAV\n",
       "4        Russia  64.686314   97.745306  2023-02-06 00:00:00    AAV\n",
       "..          ...        ...         ...                  ...    ...\n",
       "155      Phuket   7.936602   98.352929  2022-11-14 00:00:00    AAV\n",
       "156  Chiang Mai  18.788278   98.985880  2022-11-14 00:00:00    AAV\n",
       "157  Don Mueang  13.922654  100.600997  2022-11-14 00:00:00    AAV\n",
       "158          Us  39.783730 -100.445882  2022-11-14 00:00:00    AAV\n",
       "159       Power  42.676908 -112.886978  2022-11-14 00:00:00    AAV\n",
       "\n",
       "[160 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place = pd.DataFrame()\n",
    "count = 0\n",
    "a = len(data_thai)\n",
    "for i in range(a):\n",
    "    data = getcity_to_latlong(data_thai.iloc[i]['Eng'])\n",
    "    data['Datetime'] = data_thai.iloc[i]['Datetime']\n",
    "    data['Ticker'] = data_thai.iloc[i]['Ticker']\n",
    "    place = pd.concat([place,data],ignore_index=True)\n",
    "place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# เพื่อ save ระวังข้อมูลซ้ำด้วยเด้อ\n",
    "import sqlite3\n",
    "\n",
    "address = place\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "address.to_sql('stock_city',con=conn,if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anan</td>\n",
       "      <td>43.354900</td>\n",
       "      <td>0.817728</td>\n",
       "      <td>2023-01-19 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>-34.996496</td>\n",
       "      <td>-64.967282</td>\n",
       "      <td>2023-01-23 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>-34.996496</td>\n",
       "      <td>-64.967282</td>\n",
       "      <td>2023-02-06 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.748992</td>\n",
       "      <td>-84.390264</td>\n",
       "      <td>2022-11-22 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Au</td>\n",
       "      <td>-24.776109</td>\n",
       "      <td>134.755000</td>\n",
       "      <td>2023-01-19 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Us</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>2023-01-16 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Us</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>2023-01-17 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Valentine</td>\n",
       "      <td>43.094907</td>\n",
       "      <td>0.704317</td>\n",
       "      <td>2023-01-08 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Valentine</td>\n",
       "      <td>43.094907</td>\n",
       "      <td>0.704317</td>\n",
       "      <td>2023-01-24 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Village</td>\n",
       "      <td>50.182120</td>\n",
       "      <td>4.021761</td>\n",
       "      <td>2022-11-17 00:00:00</td>\n",
       "      <td>AAV</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          city        lat        long             Datetime Ticker  population\n",
       "0         Anan  43.354900    0.817728  2023-01-19 00:00:00    AAV           1\n",
       "1    Argentina -34.996496  -64.967282  2023-01-23 00:00:00    AAV           1\n",
       "2    Argentina -34.996496  -64.967282  2023-02-06 00:00:00    AAV           1\n",
       "3      Atlanta  33.748992  -84.390264  2022-11-22 00:00:00    AAV           1\n",
       "4           Au -24.776109  134.755000  2023-01-19 00:00:00    AAV           1\n",
       "..         ...        ...         ...                  ...    ...         ...\n",
       "146         Us  39.783730 -100.445882  2023-01-16 00:00:00    AAV           1\n",
       "147         Us  39.783730 -100.445882  2023-01-17 00:00:00    AAV           1\n",
       "148  Valentine  43.094907    0.704317  2023-01-08 00:00:00    AAV           1\n",
       "149  Valentine  43.094907    0.704317  2023-01-24 00:00:00    AAV           1\n",
       "150    Village  50.182120    4.021761  2022-11-17 00:00:00    AAV           1\n",
       "\n",
       "[151 rows x 6 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = place\n",
    "add = address.groupby(address.columns.tolist(),as_index=False).size()\n",
    "add.rename(columns={'size': 'population'}, inplace=True)\n",
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "df = add\n",
    "\n",
    "geometry = [Point(xy) for xy in zip(df['long'], df['lat'])]\n",
    "gdf = GeoDataFrame(df, geometry=geometry)   \n",
    "gdf['Size'] = gdf['population'] * 40\n",
    "#this is a simple map that goes with geopandas\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "base = world.plot(figsize=(20, 10),color='black', edgecolor='black')\n",
    "a = gdf.plot(ax=base, marker='o', column='population', cmap = 'Reds', markersize='Size',legend=True)\n",
    "a.set_facecolor(\"lightslategray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เพื่อ save ระวังข้อมูลซ้ำด้วยเด้อ\n",
    "import sqlite3\n",
    "\n",
    "address = place\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "address.to_sql('stock_city',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "\n",
    "def plot_spatial(ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    query = \"SELECT city,lat,long FROM stock_city WHERE `Ticker` = '%s'\" % ticker\n",
    "    address = pd.read_sql(query, conn)\n",
    "    add = address.groupby(address.columns.tolist(),as_index=False).size()\n",
    "    add.rename(columns={'size': 'population'}, inplace=True)\n",
    "    df = add\n",
    "\n",
    "    geometry = [Point(xy) for xy in zip(df['long'], df['lat'])]\n",
    "    gdf = GeoDataFrame(df, geometry=geometry)   \n",
    "    gdf['Size'] = gdf['population'] * 40\n",
    "    #this is a simple map that goes with geopandas\n",
    "    world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "    base = world.plot(figsize=(20, 10),color='black', edgecolor='black')\n",
    "    a = gdf.plot(ax=base, marker='o', column='population', cmap = 'Reds', markersize='Size',legend=True)\n",
    "    a.set_facecolor(\"lightslategray\")\n",
    "\n",
    "\n",
    "plot_spatial('AAV.BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from geopandas import GeoDataFrame\n",
    "\n",
    "def plot_spatial(ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    query = \"SELECT city,lat,long FROM stock_city WHERE `Ticker` = '%s'\" % ticker\n",
    "    address = pd.read_sql(query, conn)\n",
    "    add = address.groupby(address.columns.tolist(),as_index=False).size()\n",
    "    add.rename(columns={'size': 'population'}, inplace=True)\n",
    "    df = add\n",
    "\n",
    "    fig = px.scatter_geo(df,lat=\"lat\", lon=\"long\", color=\"population\",\n",
    "                     hover_name=\"city\", size=\"population\",\n",
    "                     projection=\"natural earth\")\n",
    "    return fig\n",
    "\n",
    "plot_spatial('AAV.BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "query = \"SELECT datetime FROM stock_table_hr WHERE datetime like '%+%' \"\n",
    "data = pd.read_sql(query, conn)\n",
    "\n",
    "data = data.values.tolist()\n",
    "fix = []\n",
    "for i in data:\n",
    "    fix.append(i[0].split('+')[0])\n",
    "# Convert strings to datetime objects\n",
    "dates = [datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S') for date_str in fix]\n",
    "count=0\n",
    "for j in dates:\n",
    "    query1 = \"UPDATE stock_table_hr SET datetime= ? WHERE datetime=?\"\n",
    "    cursor = conn.cursor()\n",
    "    print(query1)\n",
    "    cursor.execute(query1, (j,data[count][0]))\n",
    "    conn.commit()\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lucerne</td>\n",
       "      <td>47.050545</td>\n",
       "      <td>8.305468</td>\n",
       "      <td>2023-03-12 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Swiss</td>\n",
       "      <td>46.798562</td>\n",
       "      <td>8.231974</td>\n",
       "      <td>2023-03-12 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>White House</td>\n",
       "      <td>38.897700</td>\n",
       "      <td>-77.036553</td>\n",
       "      <td>2023-03-11 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>-34.996496</td>\n",
       "      <td>-64.967282</td>\n",
       "      <td>2023-03-11 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>London</td>\n",
       "      <td>51.507336</td>\n",
       "      <td>-0.127650</td>\n",
       "      <td>2023-03-11 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Paris</td>\n",
       "      <td>48.858890</td>\n",
       "      <td>2.320041</td>\n",
       "      <td>2023-03-11 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Samsung</td>\n",
       "      <td>59.927299</td>\n",
       "      <td>30.361444</td>\n",
       "      <td>2023-03-11 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>32.609970</td>\n",
       "      <td>-110.765184</td>\n",
       "      <td>2023-03-10 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cobalt</td>\n",
       "      <td>37.546081</td>\n",
       "      <td>-90.287263</td>\n",
       "      <td>2023-03-10 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>March</td>\n",
       "      <td>48.057857</td>\n",
       "      <td>7.779004</td>\n",
       "      <td>2023-03-09 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Finland</td>\n",
       "      <td>63.246778</td>\n",
       "      <td>25.920916</td>\n",
       "      <td>2023-03-09 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Meta</td>\n",
       "      <td>3.500009</td>\n",
       "      <td>-73.000009</td>\n",
       "      <td>2023-03-09 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Four</td>\n",
       "      <td>45.587454</td>\n",
       "      <td>5.193922</td>\n",
       "      <td>2023-03-09 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>47.603832</td>\n",
       "      <td>-122.330062</td>\n",
       "      <td>2023-03-09 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sequoia</td>\n",
       "      <td>37.806592</td>\n",
       "      <td>-119.895458</td>\n",
       "      <td>2023-03-08 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Griffin</td>\n",
       "      <td>33.246781</td>\n",
       "      <td>-84.264090</td>\n",
       "      <td>2023-03-07 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tel Aviv</td>\n",
       "      <td>32.085300</td>\n",
       "      <td>34.781806</td>\n",
       "      <td>2023-03-06 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Florida</td>\n",
       "      <td>27.756767</td>\n",
       "      <td>-81.463983</td>\n",
       "      <td>2023-03-05 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Norway</td>\n",
       "      <td>61.152939</td>\n",
       "      <td>8.787665</td>\n",
       "      <td>2023-03-05 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Norway</td>\n",
       "      <td>61.152939</td>\n",
       "      <td>8.787665</td>\n",
       "      <td>2023-03-05 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Marvell</td>\n",
       "      <td>34.556165</td>\n",
       "      <td>-90.911500</td>\n",
       "      <td>2023-03-03 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Dow</td>\n",
       "      <td>52.200158</td>\n",
       "      <td>0.124222</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dow</td>\n",
       "      <td>52.200158</td>\n",
       "      <td>0.124222</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Dow</td>\n",
       "      <td>52.200158</td>\n",
       "      <td>0.124222</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Tyler</td>\n",
       "      <td>32.351260</td>\n",
       "      <td>-95.301062</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>March</td>\n",
       "      <td>48.057857</td>\n",
       "      <td>7.779004</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>33.748992</td>\n",
       "      <td>-84.390264</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Canadian</td>\n",
       "      <td>35.543810</td>\n",
       "      <td>-98.003153</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Canada</td>\n",
       "      <td>61.066692</td>\n",
       "      <td>-107.991707</td>\n",
       "      <td>2023-03-02 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>32.609970</td>\n",
       "      <td>-110.765184</td>\n",
       "      <td>2023-03-01 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Strong</td>\n",
       "      <td>33.110360</td>\n",
       "      <td>-92.356579</td>\n",
       "      <td>2023-02-28 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Us</td>\n",
       "      <td>39.783730</td>\n",
       "      <td>-100.445882</td>\n",
       "      <td>2023-02-28 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ski</td>\n",
       "      <td>41.203361</td>\n",
       "      <td>47.180262</td>\n",
       "      <td>2023-02-26 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Dow</td>\n",
       "      <td>52.200158</td>\n",
       "      <td>0.124222</td>\n",
       "      <td>2023-02-24 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Hudson</td>\n",
       "      <td>40.738163</td>\n",
       "      <td>-74.055073</td>\n",
       "      <td>2023-02-24 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Adra</td>\n",
       "      <td>36.748834</td>\n",
       "      <td>-3.020362</td>\n",
       "      <td>2023-02-23 00:00:00</td>\n",
       "      <td>ABNB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           city        lat        long             Datetime Ticker\n",
       "0       Lucerne  47.050545    8.305468  2023-03-12 00:00:00   ABNB\n",
       "1         Swiss  46.798562    8.231974  2023-03-12 00:00:00   ABNB\n",
       "2   White House  38.897700  -77.036553  2023-03-11 00:00:00   ABNB\n",
       "3     Argentina -34.996496  -64.967282  2023-03-11 00:00:00   ABNB\n",
       "4        London  51.507336   -0.127650  2023-03-11 00:00:00   ABNB\n",
       "5         Paris  48.858890    2.320041  2023-03-11 00:00:00   ABNB\n",
       "6       Samsung  59.927299   30.361444  2023-03-11 00:00:00   ABNB\n",
       "7        Oracle  32.609970 -110.765184  2023-03-10 00:00:00   ABNB\n",
       "8        Cobalt  37.546081  -90.287263  2023-03-10 00:00:00   ABNB\n",
       "9         March  48.057857    7.779004  2023-03-09 00:00:00   ABNB\n",
       "10      Finland  63.246778   25.920916  2023-03-09 00:00:00   ABNB\n",
       "11         Meta   3.500009  -73.000009  2023-03-09 00:00:00   ABNB\n",
       "12         Four  45.587454    5.193922  2023-03-09 00:00:00   ABNB\n",
       "13      Seattle  47.603832 -122.330062  2023-03-09 00:00:00   ABNB\n",
       "14      Sequoia  37.806592 -119.895458  2023-03-08 00:00:00   ABNB\n",
       "15      Griffin  33.246781  -84.264090  2023-03-07 00:00:00   ABNB\n",
       "16     Tel Aviv  32.085300   34.781806  2023-03-06 00:00:00   ABNB\n",
       "17      Florida  27.756767  -81.463983  2023-03-05 00:00:00   ABNB\n",
       "18       Norway  61.152939    8.787665  2023-03-05 00:00:00   ABNB\n",
       "19       Norway  61.152939    8.787665  2023-03-05 00:00:00   ABNB\n",
       "20      Marvell  34.556165  -90.911500  2023-03-03 00:00:00   ABNB\n",
       "21          Dow  52.200158    0.124222  2023-03-02 00:00:00   ABNB\n",
       "22          Dow  52.200158    0.124222  2023-03-02 00:00:00   ABNB\n",
       "23          Dow  52.200158    0.124222  2023-03-02 00:00:00   ABNB\n",
       "24        Tyler  32.351260  -95.301062  2023-03-02 00:00:00   ABNB\n",
       "25        March  48.057857    7.779004  2023-03-02 00:00:00   ABNB\n",
       "26      Atlanta  33.748992  -84.390264  2023-03-02 00:00:00   ABNB\n",
       "27     Canadian  35.543810  -98.003153  2023-03-02 00:00:00   ABNB\n",
       "28       Canada  61.066692 -107.991707  2023-03-02 00:00:00   ABNB\n",
       "29       Oracle  32.609970 -110.765184  2023-03-01 00:00:00   ABNB\n",
       "30       Strong  33.110360  -92.356579  2023-02-28 00:00:00   ABNB\n",
       "31           Us  39.783730 -100.445882  2023-02-28 00:00:00   ABNB\n",
       "32          Ski  41.203361   47.180262  2023-02-26 00:00:00   ABNB\n",
       "33          Dow  52.200158    0.124222  2023-02-24 00:00:00   ABNB\n",
       "34       Hudson  40.738163  -74.055073  2023-02-24 00:00:00   ABNB\n",
       "35         Adra  36.748834   -3.020362  2023-02-23 00:00:00   ABNB"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import translators as ts\n",
    "import translators.server as tss\n",
    "import locationtagger\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "def trans_set100(df2):\n",
    "    count = 0\n",
    "    a = len(df2)\n",
    "    data_thai = pd.DataFrame()\n",
    "    for i in range(a):\n",
    "        try:\n",
    "            data = pd.DataFrame({'Datetime':[df2.iloc[i]['Datetime']],'Ticker':[df2.iloc[i]['Ticker']],'Body':[tss.google(df2.iloc[i]['Body'])]})\n",
    "            # data['Datetime'] = df2.iloc[i]['Datetime']\n",
    "            # data['Ticker'] = df2.iloc[i]['Ticker']\n",
    "            data_thai = pd.concat([data_thai,data],ignore_index=True)\n",
    "        except:\n",
    "            pass\n",
    "    return data_thai\n",
    "\n",
    "def getcity_and_latlong(text):\n",
    "    # extracting entities.\n",
    "    place_entity = locationtagger.find_locations(text = text)\n",
    "\n",
    "    # calling the Nominatim tool\n",
    "    loc = Nominatim(user_agent=\"GetLoc\")\n",
    "    address = pd.DataFrame({'city': [],'lat':[],'long':[]})\n",
    "\n",
    "    for i in place_entity.cities:\n",
    "        getLoc = loc.geocode(i)\n",
    "        ones_city = pd.DataFrame({'city':[i],'lat':[getLoc.latitude],'long':[getLoc.longitude]})\n",
    "        # getting all cities\n",
    "        address = pd.concat([address,ones_city],ignore_index=True)\n",
    "    return address\n",
    "    \n",
    "def get_latlong_for_all_content(df):\n",
    "    place = pd.DataFrame()\n",
    "    a = len(df)\n",
    "    for i in range(a):\n",
    "        data = getcity_and_latlong(df.iloc[i]['Body'])\n",
    "        data['Datetime'] = df.iloc[i]['Datetime']\n",
    "        data['Ticker'] = df.iloc[i]['Ticker']\n",
    "        place = pd.concat([place,data],ignore_index=True)\n",
    "    return place\n",
    "\n",
    "def update_place(ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    query_index = \"SELECT `Index` FROM stock_info WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_index = pd.read_sql(query_index, conn).values.tolist()[0][0]\n",
    "    query_Dplace = \"SELECT Datetime FROM stock_city WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_Dplace = pd.read_sql(query_Dplace, conn).sort_values(by=['Datetime'],ascending=False).values.tolist()[0][0]\n",
    "    query_news = \"SELECT Datetime,ticker,body FROM stock_news WHERE datetime > '%s' and `Ticker` == '%s'\" % (check_Dplace,ticker)\n",
    "    get_news = pd.read_sql(query_news, conn)\n",
    "    if check_index == 'SET100':\n",
    "        print('This is set100')\n",
    "        eng = trans_set100(get_news)\n",
    "        place = get_latlong_for_all_content(eng)\n",
    "    else:\n",
    "        place = get_latlong_for_all_content(get_news)\n",
    "    place.to_sql('stock_city',con=conn,if_exists='append',index=False)\n",
    "    return place\n",
    "\n",
    "update_place('ABNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c649cbfb4c288b76adc3417e379a1dde9839d571840c9111dd43481f544c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
