{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABNB', 'ADBE', 'ADI', 'ADSK', 'AEP', 'ALGN', 'AMAT', 'AMGN', 'ANSS', 'ATVI', 'AVGO', 'AZN', 'BIIB', 'BKNG', 'BKR', 'CEG', 'CHTR', 'COST', 'CPRT', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTSH', 'DLTR', 'DXCM', 'EA', 'EBAY', 'ENPH', 'EXC', 'FANG', 'FAST', 'FISV', 'FTNT', 'GOOG', 'GOOGL', 'HON', 'IDXX', 'ILMN', 'ISRG', 'JD', 'KHC', 'KLAC', 'LCID', 'LRCX', 'LULU', 'MAR', 'MCHP', 'MDLZ', 'MELI', 'MNST', 'MSFT', 'MU', 'ODFL', 'ORLY', 'PANW', 'PAYX', 'PCAR', 'PDD', 'PEP', 'QCOM', 'REGN', 'RIVN', 'ROST', 'SBUX', 'SGEN', 'SIRI', 'SNPS', 'TMUS', 'VRSK', 'VRTX', 'WDAY', 'XEL', 'ZM', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "nasdaq = []\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.nasdaq.com/market-activity/quotes/nasdaq-ndx-index')\n",
    "elements = driver.find_elements(By.XPATH, '//th[@class=\"nasdaq-ndx-index__cell nasdaq-ndx-index__cell--heading\"]')\n",
    "\n",
    "for element in elements:\n",
    "    nasdaq.append(element.text)\n",
    "print(nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "for stock in nasdaq:\n",
    "    datahr = yf.download(tickers=stock,period=\"2y\",interval=\"1h\",progress=False)\n",
    "    datad = yf.download(tickers=stock,period='10y',interval=\"1d\",progress=False)\n",
    "    datamo = yf.download(tickers=stock,period='max',interval=\"1mo\",progress=False)\n",
    "\n",
    "    datahr['Ticker'] = stock\n",
    "\n",
    "    datad.index.names = ['Datetime']\n",
    "\n",
    "    datad['Ticker'] = stock\n",
    "\n",
    "    datamo.index.names = ['Datetime']\n",
    "\n",
    "    datamo['Ticker'] = stock\n",
    "\n",
    "    datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-16</th>\n",
       "      <td>135.490005</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>132.789993</td>\n",
       "      <td>133.190002</td>\n",
       "      <td>131.605835</td>\n",
       "      <td>80576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>132.220001</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>129.283798</td>\n",
       "      <td>97918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18</th>\n",
       "      <td>129.199997</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.410004</td>\n",
       "      <td>129.710007</td>\n",
       "      <td>128.167236</td>\n",
       "      <td>96856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>130.240005</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>129.869995</td>\n",
       "      <td>128.325333</td>\n",
       "      <td>87668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22</th>\n",
       "      <td>128.009995</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>124.501358</td>\n",
       "      <td>103916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>150.639999</td>\n",
       "      <td>155.229996</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>154.649994</td>\n",
       "      <td>154.414230</td>\n",
       "      <td>83322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>153.880005</td>\n",
       "      <td>154.580002</td>\n",
       "      <td>151.169998</td>\n",
       "      <td>151.919998</td>\n",
       "      <td>151.688400</td>\n",
       "      <td>64120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>153.779999</td>\n",
       "      <td>154.330002</td>\n",
       "      <td>150.419998</td>\n",
       "      <td>150.869995</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>56007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>149.460007</td>\n",
       "      <td>151.339996</td>\n",
       "      <td>149.220001</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>57409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>150.951996</td>\n",
       "      <td>153.690002</td>\n",
       "      <td>150.919998</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>21700329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Datetime                                                                 \n",
       "2021-02-16  135.490005  136.009995  132.789993  133.190002  131.605835   \n",
       "2021-02-17  131.250000  132.220001  129.470001  130.839996  129.283798   \n",
       "2021-02-18  129.199997  130.000000  127.410004  129.710007  128.167236   \n",
       "2021-02-19  130.240005  130.710007  128.800003  129.869995  128.325333   \n",
       "2021-02-22  128.009995  129.720001  125.599998  126.000000  124.501358   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-02-07  150.639999  155.229996  150.639999  154.649994  154.414230   \n",
       "2023-02-08  153.880005  154.580002  151.169998  151.919998  151.688400   \n",
       "2023-02-09  153.779999  154.330002  150.419998  150.869995  150.639999   \n",
       "2023-02-10  149.460007  151.339996  149.220001  151.009995  151.009995   \n",
       "2023-02-13  150.951996  153.690002  150.919998  153.389999  153.389999   \n",
       "\n",
       "               Volume  \n",
       "Datetime               \n",
       "2021-02-16   80576300  \n",
       "2021-02-17   97918500  \n",
       "2021-02-18   96856700  \n",
       "2021-02-19   87668800  \n",
       "2021-02-22  103916400  \n",
       "...               ...  \n",
       "2023-02-07   83322600  \n",
       "2023-02-08   64120100  \n",
       "2023-02-09   56007100  \n",
       "2023-02-10   57409100  \n",
       "2023-02-13   21700329  \n",
       "\n",
       "[503 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datad = yf.download(tickers='AAPL',period=\"2y\",interval=\"1d\",progress=False)\n",
    "datad.index.names = ['Datetime']\n",
    "datad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_link = []\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "print(len(nasdaq))\n",
    "for j in nasdaq:\n",
    "    InsSec = []\n",
    "    driver.get(\"https://finance.yahoo.com/quote/%s/profile?p=%s\" %(j,j))\n",
    "    numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "    for i in numlink[:2]:\n",
    "        InsSec.append(i.text)\n",
    "    df1 = pd.DataFrame({'Ticker': [j], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "    df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "    print('-------')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_info',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BTC-USD', 'ETH-USD', 'USDT-USD', 'BNB-USD', 'USDC-USD', 'XRP-USD', 'BUSD-USD', 'ADA-USD', 'DOGE-USD', 'MATIC-USD', 'HEX-USD', 'SOL-USD', 'DOT-USD', 'SHIB-USD', 'LTC-USD', 'WTRX-USD', 'TRX-USD', 'AVAX-USD', 'STETH-USD', 'DAI-USD', 'UNI7083-USD', 'WBTC-USD', 'ATOM-USD', 'LINK-USD', 'LEO-USD', 'ETC-USD', 'XMR-USD', 'TON11419-USD', 'OKB-USD', 'BCH-USD', 'APT21794-USD', 'LDO-USD', 'HBAR-USD', 'XLM-USD', 'FIL-USD', 'NEAR-USD', 'APE18876-USD', 'CRO-USD', 'ALGO-USD', 'VET-USD', 'QNT-USD', 'ICP-USD', 'GRT6719-USD', 'FTM-USD', 'MANA-USD', 'TMG-USD', 'BTCB-USD', 'BIT11221-USD', 'AAVE-USD', 'EOS-USD', 'WBNB-USD', 'AXS-USD', 'EGLD-USD', 'FLOW-USD', 'THETA-USD', 'SAND-USD', 'FRAX-USD', 'LUNC-USD', 'XTZ-USD', 'TUSD-USD', 'IMX10603-USD', 'CHZ-USD', 'MINA-USD', 'HBTC-USD', 'USDP-USD', 'RPL-USD', 'HT-USD', 'KCS-USD', 'CRV-USD', 'BSV-USD', 'FXS-USD', 'DASH-USD', 'ZEC-USD', 'MKR-USD', 'USDD-USD', 'BTTOLD-USD', 'BTT-USD', 'CAKE-USD', 'XEC-USD', 'MIOTA-USD', 'TNC5524-USD', 'GMX11857-USD', 'SNX-USD', 'KLAY-USD', 'BGB-USD', 'NEO-USD', 'TWT-USD', 'GUSD-USD', 'OP-USD', 'RUNE-USD', 'LRC-USD', 'FTT-USD', 'AGIX-USD', 'PAXG-USD', 'OSMO-USD', 'XRD-USD', 'BABYDOGE-USD', 'GT-USD', 'ZIL-USD', 'CVX-USD']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "cryp = []\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://finance.yahoo.com/crypto/?offset=0&count=100')\n",
    "elements = driver.find_elements(By.XPATH, '//a[@class=\"Fw(600) C($linkColor)\"]')\n",
    "\n",
    "for element in elements:\n",
    "    cryp.append(element.text)\n",
    "print(cryp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Ticker Industry Group  Sector      Index\n",
      "0        BTC-USD         Crypto  Crypto  Crypto100\n",
      "1        ETH-USD         Crypto  Crypto  Crypto100\n",
      "2       USDT-USD         Crypto  Crypto  Crypto100\n",
      "3        BNB-USD         Crypto  Crypto  Crypto100\n",
      "4       USDC-USD         Crypto  Crypto  Crypto100\n",
      "..           ...            ...     ...        ...\n",
      "95       XRD-USD         Crypto  Crypto  Crypto100\n",
      "96  BABYDOGE-USD         Crypto  Crypto  Crypto100\n",
      "97        GT-USD         Crypto  Crypto  Crypto100\n",
      "98       ZIL-USD         Crypto  Crypto  Crypto100\n",
      "99       CVX-USD         Crypto  Crypto  Crypto100\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "cf2 = pd.DataFrame()\n",
    "for j in cryp:\n",
    "    cf1 = pd.DataFrame({'Ticker': [j], 'Industry Group': ['Crypto'], 'Sector': ['Crypto'], 'Index': ['Crypto100']})\n",
    "    cf2 = pd.concat([cf2,cf1],ignore_index=True)\n",
    "print(cf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "cf2.to_sql('stock_info',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "for stock in cryp:\n",
    "    # datahr = yf.download(tickers=stock,period=\"2y\",interval=\"1h\",progress=False)\n",
    "    # datad = yf.download(tickers=stock,period='max',interval=\"1d\",progress=False)\n",
    "    datamo = yf.download(tickers=stock,period='max',interval=\"1mo\",progress=False)\n",
    "\n",
    "    # datahr['Ticker'] = stock\n",
    "\n",
    "    # datad.index.names = ['Datetime']\n",
    "\n",
    "    # datad['Ticker'] = stock\n",
    "\n",
    "    datamo.index.names = ['Datetime']\n",
    "\n",
    "    datamo['Ticker'] = stock\n",
    "\n",
    "    # print(datad)\n",
    "    # datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    # datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Q1 '21\", \"Q2 '21\", \"Q3 '21\", \"Q4 '21\", \"Q1 '22\", \"Q2 '22\", \"Q3 '22\"]\n",
      "[['+5.36%', '+298.84%', '+66.68%', '+78.31%', '+70.13%', '+57.59%', '+28.92%'], [None, None, None, None, None, None, None], ['−20.76%', '+379.70%', '+52.24%', '+90.43%', '+104.32%', '+74.83%', '+29.21%'], [None, None, None, None, None, None, None], ['−2.91%', '+89.19%', '+92.88%', '+102.53%', '+98.56%', '+1002.21%', '+41.34%'], [None, None, None, None, None, None, None], ['−226.50%', '+91.09%', '+176.98%', '+101.81%', '+99.31%', '+772.31%', '+49.32%'], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], ['−244.16%', '+88.15%', '+280.20%', '+101.40%', '+98.40%', '+655.35%', '+45.62%'], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], ['−239.12%', '+88.53%', '+262.53%', '+101.33%', '+98.48%', '+632.20%', '+41.58%'], ['−239.12%', '+88.53%', '+230.16%', '+101.23%', '+98.48%', '+597.04%', '+46.01%'], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], ['−1.75%', '+96.54%', '+87.90%', '+103.58%', '+108.23%', '+3285.58%', '+37.41%'], ['−2.91%', '+89.19%', '+92.88%', '+102.53%', '+98.56%', '+1002.21%', '+41.34%'], [None, None, None, None, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "test = []\n",
    "test2 = []\n",
    "test3 = []\n",
    "count = 0\n",
    "revenue,YoYR = [],[]\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless')\n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.tradingview.com/symbols/NASDAQ-ABNB/financials-income-statement/')\n",
    "header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "\n",
    "Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "              raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "              raw21,raw22,raw23,raw24]\n",
    "\n",
    "YoY = [''] * len(Allelement)\n",
    "Oth = [''] * len(Allelement)\n",
    "for element in header:\n",
    "    test.append(element.text)\n",
    "year = test[0].split('\\n')[1:-1]\n",
    "for e in Allelement:\n",
    "    test2 = []\n",
    "    for h in e:\n",
    "        test2.append(h.text)\n",
    "    test2 = test2[0].split('\\n')\n",
    "    if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "        for k in range(len(test2)-3):\n",
    "            if k%2 == 0:\n",
    "                a = test2[k+2]\n",
    "                revenue.append(a[1:-1])\n",
    "            else:\n",
    "                YoYR.append(test2[k+2])\n",
    "    else:\n",
    "        for k in range(len(test2)-2):\n",
    "            a = test2[k+1]\n",
    "            revenue.append(a[1:-1])\n",
    "            YoYR.append(None)\n",
    "\n",
    "    YoY[count] = (YoYR)\n",
    "    Oth[count] = (revenue)\n",
    "    count += 1\n",
    "    YoYR = []\n",
    "    revenue = []\n",
    "\n",
    "print(year)\n",
    "print(YoY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total revenue YoY growth Total revenue Cost of goods sold Gross profit  \\\n",
      "0       886.94M                   +5.36%           −439.95M      446.99M   \n",
      "1         1.34B                 +298.84%           −502.55M      832.64M   \n",
      "2         2.24B                  +66.68%           −539.91M        1.70B   \n",
      "3         1.53B                  +78.31%           −295.31M        1.24B   \n",
      "4         1.51B                  +70.13%           −595.63M      913.30M   \n",
      "5         2.10B                  +57.59%           −648.36M        1.46B   \n",
      "6         2.88B                  +28.92%           −691.10M        2.19B   \n",
      "\n",
      "  YoY growth Gross profit Operating expenses (excl. COGS) Operating income  \\\n",
      "0                 −20.76%                        −781.95M         −334.96M   \n",
      "1                +379.70%                        −883.36M          −50.72M   \n",
      "2                 +52.24%                        −846.01M          851.51M   \n",
      "3                 +90.43%                          −1.16B           77.14M   \n",
      "4                +104.32%                        −918.12M           −4.81M   \n",
      "5                 +74.83%                        −998.18M          457.57M   \n",
      "6                 +29.21%                        −989.78M            1.20B   \n",
      "\n",
      "  YoY growth Operating income Non-operating income, total Pretax income  ...  \\\n",
      "0                      −2.91%                    −830.94M        −1.17B  ...   \n",
      "1                     +89.19%                      −6.27M       −56.98M  ...   \n",
      "2                     +92.88%                      −1.05M       850.46M  ...   \n",
      "3                    +102.53%                      −4.92M        72.22M  ...   \n",
      "4                     +98.56%                      −3.27M        −8.09M  ...   \n",
      "5                   +1002.21%                     −74.45M       383.11M  ...   \n",
      "6                     +41.34%                      66.37M         1.27B  ...   \n",
      "\n",
      "  Diluted EPS Diluted EPS YoY growth Average basic shares outstanding  \\\n",
      "0       −1.95               −239.12%                          600.96M   \n",
      "1       −0.11                +88.53%                          611.74M   \n",
      "2        1.22               +230.16%                          621.01M   \n",
      "3        0.08               +101.23%                          629.48M   \n",
      "4       −0.03                +98.48%                          635.31M   \n",
      "5        0.55               +597.04%                          638.41M   \n",
      "6        1.79                +46.01%                          638.70M   \n",
      "\n",
      "  Diluted shares outstanding    EBITDA YoY growth EBITDA      EBIT  \\\n",
      "0                    600.96M  −296.71M            −1.75%  −334.96M   \n",
      "1                    611.74M   −15.18M           +96.54%   −50.72M   \n",
      "2                    681.92M   885.20M           +87.90%   851.51M   \n",
      "3                    680.90M   107.98M          +103.58%    77.14M   \n",
      "4                    635.31M    24.42M          +108.23%    −4.81M   \n",
      "5                    683.54M   483.57M         +3285.58%   457.57M   \n",
      "6                    680.06M     1.22B           +37.41%     1.20B   \n",
      "\n",
      "  YoY growth EBIT Total operating expenses Quarterly  \n",
      "0          −2.91%                    1.22B    Q1 '21  \n",
      "1         +89.19%                    1.39B    Q2 '21  \n",
      "2         +92.88%                    1.39B    Q3 '21  \n",
      "3        +102.53%                    1.46B    Q4 '21  \n",
      "4         +98.56%                    1.51B    Q1 '22  \n",
      "5       +1002.21%                    1.65B    Q2 '22  \n",
      "6         +41.34%                    1.68B    Q3 '22  \n",
      "\n",
      "[7 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "a = range(len(Oth))\n",
    "df2 = pd.DataFrame()\n",
    "for i in range(len(year)):\n",
    "    data = {'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "        'Cost of goods sold':Oth[1][i],\n",
    "        'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "        'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "        'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "        'Non-operating income, total':Oth[5][i],\n",
    "        'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[7][i],\n",
    "        'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "        'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "        'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "        'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "        'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "        'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "        'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "        'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "        'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "    df = pd.DataFrame(data,index=[i])\n",
    "    df2 = pd.concat([df2,df],ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Currency: USD\\nQ2 '21\\nQ3 '21\\nQ4 '21\\nQ1 '22\\nQ2 '22\\nQ3 '22\\nQ4 '22\\nTTM\\nTotal revenue\\nYoY growth\\n\\u202a1.34B\\u202c\\n+298.84%\\n\\u202a2.24B\\u202c\\n+66.68%\\n\\u202a1.53B\\u202c\\n+78.31%\\n\\u202a1.51B\\u202c\\n+70.13%\\n\\u202a2.10B\\u202c\\n+57.59%\\n\\u202a2.88B\\u202c\\n+28.92%\\n\\u202a1.90B\\u202c\\n+24.14%\\n\\u202a8.40B\\u202c\\nCost of goods sold\\n\\u202a−502.55M\\u202c\\n\\u202a−539.91M\\u202c\\n\\u202a−295.31M\\u202c\\n\\u202a−595.63M\\u202c\\n\\u202a−648.36M\\u202c\\n\\u202a−691.10M\\u202c\\n\\u202a−345.00M\\u202c\\n\\u202a−2.28B\\u202c\\nGross profit\\nYoY growth\\n\\u202a832.64M\\u202c\\n+379.70%\\n\\u202a1.70B\\u202c\\n+52.24%\\n\\u202a1.24B\\u202c\\n+90.43%\\n\\u202a913.30M\\u202c\\n+104.32%\\n\\u202a1.46B\\u202c\\n+74.83%\\n\\u202a2.19B\\u202c\\n+29.21%\\n\\u202a1.56B\\u202c\\n+25.88%\\n\\u202a6.12B\\u202c\\nOperating expenses (excl. COGS)\\n\\u202a−883.36M\\u202c\\n\\u202a−846.01M\\u202c\\n\\u202a−1.16B\\u202c\\n\\u202a−918.12M\\u202c\\n\\u202a−998.18M\\u202c\\n\\u202a−989.78M\\u202c\\n\\u202a−1.32B\\u202c\\n\\u202a−4.23B\\u202c\\nOperating income\\nYoY growth\\n\\u202a−50.72M\\u202c\\n+89.19%\\n\\u202a851.51M\\u202c\\n+92.88%\\n\\u202a77.14M\\u202c\\n+102.53%\\n\\u202a−4.81M\\u202c\\n+98.56%\\n\\u202a457.57M\\u202c\\n+1002.21%\\n\\u202a1.20B\\u202c\\n+41.34%\\n\\u202a233.00M\\u202c\\n+202.06%\\n\\u202a1.89B\\u202c\\nNon-operating income, total\\n\\u202a−6.27M\\u202c\\n\\u202a−1.05M\\u202c\\n\\u202a−4.92M\\u202c\\n\\u202a−3.27M\\u202c\\n\\u202a−74.45M\\u202c\\n\\u202a66.37M\\u202c\\n\\u202a111.00M\\u202c\\n\\u202a99.64M\\u202c\\nPretax income\\nYoY growth\\n\\u202a−56.98M\\u202c\\n+91.09%\\n\\u202a850.46M\\u202c\\n+176.98%\\n\\u202a72.22M\\u202c\\n+101.81%\\n\\u202a−8.09M\\u202c\\n+99.31%\\n\\u202a383.11M\\u202c\\n+772.31%\\n\\u202a1.27B\\u202c\\n+49.32%\\n\\u202a344.00M\\u202c\\n+376.32%\\n\\u202a1.99B\\u202c\\nEquity in earnings\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n—\\nTaxes\\n\\u202a−11.23M\\u202c\\n\\u202a−16.57M\\u202c\\n\\u202a−17.72M\\u202c\\n\\u202a−10.71M\\u202c\\n\\u202a−4.27M\\u202c\\n\\u202a−55.61M\\u202c\\n\\u202a−25.00M\\u202c\\n\\u202a−95.59M\\u202c\\nNon-controlling/minority interest\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n—\\nAfter tax other income/expense\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n—\\nNet income before discontinued operations\\n\\u202a−68.22M\\u202c\\n\\u202a833.89M\\u202c\\n\\u202a54.50M\\u202c\\n\\u202a−18.79M\\u202c\\n\\u202a378.84M\\u202c\\n\\u202a1.21B\\u202c\\n\\u202a319.00M\\u202c\\n\\u202a1.89B\\u202c\\nDiscontinued operations\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n—\\nNet income\\nYoY growth\\n\\u202a−68.22M\\u202c\\n+88.15%\\n\\u202a833.89M\\u202c\\n+280.20%\\n\\u202a54.50M\\u202c\\n+101.40%\\n\\u202a−18.79M\\u202c\\n+98.40%\\n\\u202a378.84M\\u202c\\n+655.35%\\n\\u202a1.21B\\u202c\\n+45.62%\\n\\u202a319.00M\\u202c\\n+485.31%\\n\\u202a1.89B\\u202c\\nDilution adjustment\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n—\\nPreferred dividends\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n—\\nDiluted net income available to common stockholders\\n\\u202a−68.22M\\u202c\\n\\u202a833.89M\\u202c\\n\\u202a54.50M\\u202c\\n\\u202a−18.79M\\u202c\\n\\u202a378.84M\\u202c\\n\\u202a1.21B\\u202c\\n\\u202a319.00M\\u202c\\n\\u202a1.89B\\u202c\\nBasic earnings per share (Basic EPS)\\nYoY growth\\n\\u202a−0.11\\u202c\\n+88.53%\\n\\u202a1.34\\u202c\\n+262.53%\\n\\u202a0.09\\u202c\\n+101.33%\\n\\u202a−0.03\\u202c\\n+98.48%\\n\\u202a0.59\\u202c\\n+632.20%\\n\\u202a1.90\\u202c\\n+41.58%\\n\\u202a0.50\\u202c\\n+481.06%\\n\\u202a2.97\\u202c\\nDiluted earnings per share (Diluted EPS)\\nYoY growth\\n\\u202a−0.11\\u202c\\n+88.53%\\n\\u202a1.22\\u202c\\n+230.16%\\n\\u202a0.08\\u202c\\n+101.23%\\n\\u202a−0.03\\u202c\\n+98.48%\\n\\u202a0.55\\u202c\\n+597.04%\\n\\u202a1.79\\u202c\\n+46.01%\\n\\u202a0.47\\u202c\\n+493.38%\\n\\u202a2.78\\u202c\\nAverage basic shares outstanding\\n\\u202a611.74M\\u202c\\n\\u202a621.01M\\u202c\\n\\u202a629.48M\\u202c\\n\\u202a635.31M\\u202c\\n\\u202a638.41M\\u202c\\n\\u202a638.70M\\u202c\\n\\u202a634.00M\\u202c\\n—\\nDiluted shares outstanding\\n\\u202a611.74M\\u202c\\n\\u202a681.92M\\u202c\\n\\u202a680.90M\\u202c\\n\\u202a635.31M\\u202c\\n\\u202a683.54M\\u202c\\n\\u202a680.06M\\u202c\\n\\u202a672.00M\\u202c\\n—\\nEBITDA\\nYoY growth\\n\\u202a−15.18M\\u202c\\n+96.54%\\n\\u202a885.20M\\u202c\\n+87.90%\\n\\u202a107.98M\\u202c\\n+103.58%\\n\\u202a24.42M\\u202c\\n+108.23%\\n\\u202a483.57M\\u202c\\n+3285.58%\\n\\u202a1.22B\\u202c\\n+37.41%\\n\\u202a246.00M\\u202c\\n+127.82%\\n\\u202a1.97B\\u202c\\nEBIT\\nYoY growth\\n\\u202a−50.72M\\u202c\\n+89.19%\\n\\u202a851.51M\\u202c\\n+92.88%\\n\\u202a77.14M\\u202c\\n+102.53%\\n\\u202a−4.81M\\u202c\\n+98.56%\\n\\u202a457.57M\\u202c\\n+1002.21%\\n\\u202a1.20B\\u202c\\n+41.34%\\n\\u202a233.00M\\u202c\\n+202.06%\\n\\u202a1.89B\\u202c\\nTotal operating expenses\\n\\u202a1.39B\\u202c\\n\\u202a1.39B\\u202c\\n\\u202a1.46B\\u202c\\n\\u202a1.51B\\u202c\\n\\u202a1.65B\\u202c\\n\\u202a1.68B\\u202c\\n\\u202a1.67B\\u202c\\n\\u202a6.51B\\u202c\"]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "test = []\n",
    "test2 = []\n",
    "test3 = []\n",
    "count = 0\n",
    "revenue,YoYR = [],[]\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.tradingview.com/symbols/NASDAQ-ABNB/financials-income-statement/')\n",
    "header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]')\n",
    "\n",
    "for element in header:\n",
    "    test.append(element.text)\n",
    "#     revenue = []\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABNB',\n",
       " 'ADBE',\n",
       " 'ADI',\n",
       " 'ADSK',\n",
       " 'AEP',\n",
       " 'ALGN',\n",
       " 'AMAT',\n",
       " 'AMGN',\n",
       " 'ANSS',\n",
       " 'ATVI',\n",
       " 'AVGO',\n",
       " 'AZN',\n",
       " 'BIIB',\n",
       " 'BKNG',\n",
       " 'BKR',\n",
       " 'CEG',\n",
       " 'CHTR',\n",
       " 'COST',\n",
       " 'CPRT',\n",
       " 'CRWD',\n",
       " 'CSCO',\n",
       " 'CSGP',\n",
       " 'CSX',\n",
       " 'CTAS',\n",
       " 'CTSH',\n",
       " 'DLTR',\n",
       " 'DXCM',\n",
       " 'EA',\n",
       " 'EBAY',\n",
       " 'ENPH',\n",
       " 'EXC',\n",
       " 'FANG',\n",
       " 'FAST',\n",
       " 'FISV',\n",
       " 'FTNT',\n",
       " 'GOOG',\n",
       " 'GOOGL',\n",
       " 'HON',\n",
       " 'IDXX',\n",
       " 'ILMN',\n",
       " 'ISRG',\n",
       " 'JD',\n",
       " 'KHC',\n",
       " 'KLAC',\n",
       " 'LCID',\n",
       " 'LRCX',\n",
       " 'LULU',\n",
       " 'MAR',\n",
       " 'MCHP',\n",
       " 'MDLZ',\n",
       " 'MELI',\n",
       " 'MNST',\n",
       " 'MSFT',\n",
       " 'MU',\n",
       " 'ODFL',\n",
       " 'ORLY',\n",
       " 'PANW',\n",
       " 'PAYX',\n",
       " 'PCAR',\n",
       " 'PDD',\n",
       " 'PEP',\n",
       " 'QCOM',\n",
       " 'REGN',\n",
       " 'RIVN',\n",
       " 'ROST',\n",
       " 'SBUX',\n",
       " 'SGEN',\n",
       " 'SIRI',\n",
       " 'SNPS',\n",
       " 'TMUS',\n",
       " 'VRSK',\n",
       " 'VRTX',\n",
       " 'WDAY',\n",
       " 'XEL',\n",
       " 'ZM',\n",
       " 'ZS']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "query = \"SELECT Ticker FROM stock_info WHERE `Index` = 'NASDAQ100'\"\n",
    "ticker = pd.read_sql(query, conn)\n",
    "ticker = ticker['Ticker'].values.tolist()\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "test = []\n",
    "test2 = []\n",
    "test3 = []\n",
    "count = 0\n",
    "revenue,YoYR = [],[]\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "for t in ticker:\n",
    "    driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% t)\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-3):\n",
    "                if k%2 == 0:\n",
    "                    a = test2[k+2]\n",
    "                    revenue.append(a[1:-1])\n",
    "                else:\n",
    "                    YoYR.append(test2[k+2])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                revenue.append(a[1:-1])\n",
    "                YoYR.append(None)\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "        YoYR = []\n",
    "        revenue = []\n",
    "\n",
    "    a = range(len(Oth))\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':t,'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "            df = pd.DataFrame(data,index=[i])\n",
    "            df2 = pd.concat([df2,df],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_quarter',con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1d3d3cfcb20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "sql = \"DROP TABLE stock_quarter\"\n",
    "cur.execute(sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ของไทย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "query = \"SELECT Ticker FROM stock_info WHERE `Index` = 'SET100'\"\n",
    "ticker = pd.read_sql(query, conn)\n",
    "ticker = ticker['Ticker'].values.tolist()\n",
    "for i in range(len(ticker)):\n",
    "    ticker[i] = ticker[i].replace(\".BK\",\"\")\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Total revenue</th>\n",
       "      <th>YoY growth Total revenue</th>\n",
       "      <th>Cost of goods sold</th>\n",
       "      <th>Gross profit</th>\n",
       "      <th>YoY growth Gross profit</th>\n",
       "      <th>Operating expenses (excl. COGS)</th>\n",
       "      <th>Operating income</th>\n",
       "      <th>YoY growth Operating income</th>\n",
       "      <th>Non-operating income, total</th>\n",
       "      <th>...</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Diluted EPS YoY growth</th>\n",
       "      <th>Average basic shares outstanding</th>\n",
       "      <th>Diluted shares outstanding</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>YoY growth EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>YoY growth EBIT</th>\n",
       "      <th>Total operating expenses</th>\n",
       "      <th>Quarterly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ABNB</td>\n",
       "      <td>1.90B</td>\n",
       "      <td>+24.14%</td>\n",
       "      <td>−345.00M</td>\n",
       "      <td>1.56B</td>\n",
       "      <td>+25.88%</td>\n",
       "      <td>−1.32B</td>\n",
       "      <td>233.00M</td>\n",
       "      <td>+202.06%</td>\n",
       "      <td>111.00M</td>\n",
       "      <td>...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>+493.38%</td>\n",
       "      <td>634.00M</td>\n",
       "      <td>672.00M</td>\n",
       "      <td>246.00M</td>\n",
       "      <td>+127.82%</td>\n",
       "      <td>233.00M</td>\n",
       "      <td>+202.06%</td>\n",
       "      <td>1.67B</td>\n",
       "      <td>Q4 '22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker Total revenue YoY growth Total revenue Cost of goods sold  \\\n",
       "6   ABNB         1.90B                  +24.14%           −345.00M   \n",
       "\n",
       "  Gross profit YoY growth Gross profit Operating expenses (excl. COGS)  \\\n",
       "6        1.56B                 +25.88%                          −1.32B   \n",
       "\n",
       "  Operating income YoY growth Operating income Non-operating income, total  \\\n",
       "6          233.00M                    +202.06%                     111.00M   \n",
       "\n",
       "   ... Diluted EPS Diluted EPS YoY growth Average basic shares outstanding  \\\n",
       "6  ...        0.47               +493.38%                          634.00M   \n",
       "\n",
       "  Diluted shares outstanding   EBITDA YoY growth EBITDA     EBIT  \\\n",
       "6                    672.00M  246.00M          +127.82%  233.00M   \n",
       "\n",
       "  YoY growth EBIT Total operating expenses Quarterly  \n",
       "6        +202.06%                    1.67B    Q4 '22  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def download_quarter (ticker,save):\n",
    "    test = []\n",
    "    test2 = []\n",
    "    test3 = []\n",
    "    count = 0\n",
    "    revenue,YoYR = [],[]\n",
    "\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "\n",
    "    op = webdriver.ChromeOptions()\n",
    "    #op.add_argument('headless') \n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    thf2 = pd.DataFrame()\n",
    "    query_index = \"SELECT `Index` FROM stock_info WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_index = pd.read_sql(query_index, conn).values.tolist()[0][0]\n",
    "    tickerest = ticker.split('.')[0]\n",
    "    if check_index == 'SET100':\n",
    "        driver.get('https://www.tradingview.com/symbols/SET-%s/financials-income-statement/'% tickerest)\n",
    "    else:\n",
    "        driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% tickerest)\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-3):\n",
    "                if k%2 == 0:\n",
    "                    a = test2[k+2]\n",
    "                    revenue.append(a[1:-1])\n",
    "                else:\n",
    "                    YoYR.append(test2[k+2])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                revenue.append(a[1:-1])\n",
    "                YoYR.append(None)\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "        YoYR = []\n",
    "        revenue = []\n",
    "\n",
    "    a = range(len(Oth))\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':(ticker),'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "            thf = pd.DataFrame(data,index=[i])\n",
    "            thf2 = pd.concat([thf2,thf],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    if save == True:\n",
    "        thf2.to_sql('stock_quarter',con=conn,if_exists='append',index=False)\n",
    "    return thf2\n",
    "\n",
    "def update_quarter (ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    thf2 = download_quarter(ticker,False)\n",
    "    a = len(thf2)\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    count = 1\n",
    "    query = \"SELECT Quarterly FROM stock_quarter WHERE `Ticker` == '%s'\" % ticker\n",
    "    test = pd.read_sql(query, conn).values.tolist()[-1]\n",
    "    q = thf2['Quarterly']\n",
    "    for i in range(a):\n",
    "        if [list(thf2['Quarterly'].values)[i]] == test :\n",
    "            break\n",
    "        count += 1\n",
    "    data = thf2.iloc[count:,:]\n",
    "    data.to_sql('stock_quarter',con=conn,if_exists='append',index=False)\n",
    "    return data\n",
    "\n",
    "\n",
    "# download_quarter('AAV.BK',False)\n",
    "update_quarter('ABNB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def download_year (ticker,save):\n",
    "    test = []\n",
    "    test2 = []\n",
    "    test3 = []\n",
    "    count = 0\n",
    "    revenue,YoYR = [],[]\n",
    "\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "\n",
    "    op = webdriver.ChromeOptions()\n",
    "    op.add_argument('headless')\n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    thf2 = pd.DataFrame()\n",
    "    query_index = \"SELECT `Index` FROM stock_info WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_index = pd.read_sql(query_index, conn).values.tolist()[0][0]\n",
    "    tickerest = ticker.split('.')[0]\n",
    "    if check_index == 'SET100':\n",
    "        driver.get('https://www.tradingview.com/symbols/SET-%s/financials-income-statement/'% tickerest)\n",
    "    else:\n",
    "        driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% tickerest)\n",
    "    time.sleep(4)\n",
    "    year = driver.find_element(\"xpath\",'//*[@id=\"FY\"]')\n",
    "    year.click()\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        revenue = []\n",
    "        YoYR = []\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-1):\n",
    "                if k%2 == 0 and k > 0:\n",
    "                    YoYR.append(test2[k])\n",
    "                else:\n",
    "                    if k > 0 :\n",
    "                        a = test2[k]\n",
    "                        revenue.append(a[1:-1])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                YoYR.append(None)\n",
    "                revenue.append(a[1:-1])\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "    a = range(len(Oth))\n",
    "    s = '2018'\n",
    "    for i in range(len(year)):\n",
    "        if year[i] == s:\n",
    "            year = year[i:]\n",
    "            break\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':(ticker),'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Year':year[i]}\n",
    "            thf = pd.DataFrame(data,index=[i])\n",
    "            thf2 = pd.concat([thf2,thf],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    if save == True:\n",
    "        thf2.to_sql('stock_financial',con=conn,if_exists='append',index=False)\n",
    "    return thf2\n",
    "\n",
    "def update_year (ticker):\n",
    "    thf2 = download_year(ticker,False)\n",
    "    a = len(thf2)\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    count = 1\n",
    "    query = \"SELECT Year FROM stock_financial WHERE `Ticker` == '%s'\" % ticker\n",
    "    test = pd.read_sql(query, conn).values.tolist()[-1]\n",
    "    q = thf2['Year']\n",
    "    for i in range(a):\n",
    "        if [list(thf2['Year'].values)[i]] == test :\n",
    "            break\n",
    "        count += 1\n",
    "    data = thf2.iloc[count:,:]\n",
    "    data.to_sql('stock_financial',con=conn,if_exists='append',index=False)\n",
    "    return data\n",
    "\n",
    "def getAllticker():\n",
    "        conn = sqlite3.connect(\"stock.sqlite\")\n",
    "        cur = conn.cursor()\n",
    "        query = \"select Ticker from stock_info WHERE [Index] == 'NASDAQ'\"\n",
    "        r_df = pd.read_sql(query,conn)\n",
    "        list_db = r_df['Ticker'].values.tolist()\n",
    "        return list_db\n",
    "\n",
    "# All_Ticker = getAllticker()\n",
    "# for i in All_Ticker[59:]:\n",
    "#     try:\n",
    "#         download_year(i,True)\n",
    "#     except:\n",
    "#         print(i)\n",
    "# update_year('AAV.BK')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAV.BK', 'ACE.BK', 'ADVANC.BK', 'AMATA.BK', 'AOT.BK', 'AP.BK', 'AWC.BK', 'BAM.BK', 'BANPU.BK', 'BBL.BK', 'BCH.BK', 'BCP.BK', 'BCPG.BK', 'BDMS.BK', 'BEC.BK', 'BEM.BK', 'BGRIM.BK', 'BH.BK', 'BLA.BK', 'BTS.BK', 'BYD.BK', 'CBG.BK', 'CENTEL.BK', 'CHG.BK', 'CK.BK', 'CKP.BK', 'COM7.BK', 'CPALL.BK', 'CPF.BK', 'CPN.BK', 'CRC.BK', 'DELTA.BK', 'DOHOME.BK', 'DTAC.BK', 'EA.BK', 'EGCO.BK', 'EPG.BK', 'ESSO.BK', 'FORTH.BK', 'GLOBAL.BK', 'GPSC.BK', 'GULF.BK', 'GUNKUL.BK', 'HANA.BK', 'HMPRO.BK', 'INTUCH.BK', 'IRPC.BK', 'IVL.BK', 'JAS.BK', 'JMART.BK', 'JMT.BK', 'KBANK.BK', 'KCE.BK', 'KEX.BK', 'KKP.BK', 'KTB.BK', 'KTC.BK', 'LH.BK', 'MEGA.BK', 'MINT.BK', 'MTC.BK', 'NEX.BK', 'ONEE.BK', 'OR.BK', 'ORI.BK', 'OSP.BK', 'PLANB.BK', 'PSL.BK', 'PTG.BK', 'PTT.BK', 'PTTEP.BK', 'PTTGC.BK', 'QH.BK', 'RATCH.BK', 'RBF.BK', 'RCL.BK', 'SABUY.BK', 'SAWAD.BK', 'SCB.BK', 'SCC.BK', 'SCGP.BK', 'SINGER.BK', 'SPALI.BK', 'SPRC.BK', 'STA.BK', 'STARK.BK', 'STGT.BK', 'TCAP.BK', 'THANI.BK', 'THG.BK', 'TIDLOR.BK', 'TIPH.BK', 'TISCO.BK', 'TOP.BK', 'TQM.BK', 'TRUE.BK', 'TTB.BK', 'TU.BK', 'VGI.BK', 'WHA.BK', 'ABNB', 'ADBE', 'ADI', 'ADSK', 'AEP', 'ALGN', 'AMAT', 'AMGN', 'ANSS', 'ATVI', 'AVGO', 'AZN', 'BIIB', 'BKNG', 'BKR', 'CEG', 'CHTR', 'COST', 'CPRT', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTSH', 'DLTR', 'DXCM', 'EA', 'EBAY', 'ENPH', 'EXC', 'FANG', 'FAST', 'FISV', 'FTNT', 'GOOG', 'GOOGL', 'HON', 'IDXX', 'ILMN', 'ISRG', 'JD', 'KHC', 'KLAC', 'LCID', 'LRCX', 'LULU', 'MAR', 'MCHP', 'MDLZ', 'MELI', 'MNST', 'MSFT', 'MU', 'ODFL', 'ORLY', 'PANW', 'PAYX', 'PCAR', 'PDD', 'PEP', 'QCOM', 'REGN', 'RIVN', 'ROST', 'SBUX', 'SGEN', 'SIRI', 'SNPS', 'TMUS', 'VRSK', 'VRTX', 'WDAY', 'XEL', 'ZM', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def getAllticker():\n",
    "        conn = sqlite3.connect(\"stock.sqlite\")\n",
    "        cur = conn.cursor()\n",
    "        query = \"select Ticker from stock_info WHERE [Index] == 'SET100' or [Index] == 'NASDAQ100'\"\n",
    "        r_df = pd.read_sql(query,conn)\n",
    "        list_db = r_df['Ticker'].values.tolist()\n",
    "        return list_db\n",
    "\n",
    "All_Ticker = getAllticker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def download_info(Ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    all_link = []\n",
    "    op = webdriver.ChromeOptions()\n",
    "    op.add_argument('headless') \n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    df2 = pd.DataFrame()\n",
    "    InsSec = []\n",
    "    driver.get(\"https://finance.yahoo.com/quote/%s/profile?p=%s\"% (Ticker,Ticker))\n",
    "    numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "    for i in numlink[:2]:\n",
    "        InsSec.append(i.text)\n",
    "    df1 = pd.DataFrame({'Ticker': [Ticker], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "    df1.to_sql('stock_info',con=conn,if_exists='append',index=False)\n",
    "    return df1\n",
    "\n",
    "def download_stock(Ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    df_h = yf.download(tickers=Ticker, period='2y', interval='1h')\n",
    "    df_h['Ticker'] = Ticker\n",
    "    df_d = yf.download(tickers=Ticker, period='max', interval='1d')\n",
    "    df_d['Ticker'] = Ticker\n",
    "    df_d.index.names = ['Datetime']\n",
    "    df_mo = yf.download(tickers=Ticker, period='max', interval='1mo')\n",
    "    df_mo['Ticker'] = Ticker\n",
    "    df_mo.index.names = ['Datetime']\n",
    "\n",
    "    df_h.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    df_d.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    df_mo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)\n",
    "\n",
    "def download_year (ticker,save):\n",
    "    test = []\n",
    "    test2 = []\n",
    "    test3 = []\n",
    "    count = 0\n",
    "    revenue,YoYR = [],[]\n",
    "\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "\n",
    "    op = webdriver.ChromeOptions()\n",
    "    #op.add_argument('headless') \n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    thf2 = pd.DataFrame()\n",
    "    query_index = \"SELECT `Index` FROM stock_info WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_index = pd.read_sql(query_index, conn).values.tolist()[0][0]\n",
    "    tickerest = ticker.split('.')[0]\n",
    "    if check_index == 'SET100':\n",
    "        driver.get('https://www.tradingview.com/symbols/SET-%s/financials-income-statement/'% tickerest)\n",
    "    else:\n",
    "        driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% tickerest)\n",
    "    time.sleep(4)\n",
    "    year = driver.find_element(\"xpath\",'//*[@id=\"FY\"]')\n",
    "    year.click()\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        revenue = []\n",
    "        YoYR = []\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-1):\n",
    "                if k%2 == 0 and k > 0:\n",
    "                    YoYR.append(test2[k])\n",
    "                else:\n",
    "                    if k > 0 :\n",
    "                        a = test2[k]\n",
    "                        revenue.append(a[1:-1])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                YoYR.append(None)\n",
    "                revenue.append(a[1:-1])\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "    a = range(len(Oth))\n",
    "    s = '2018'\n",
    "    for i in range(len(year)):\n",
    "        if year[i] == s:\n",
    "            year = year[i:]\n",
    "            break\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':(ticker),'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Year':year[i]}\n",
    "            thf = pd.DataFrame(data,index=[i])\n",
    "            thf2 = pd.concat([thf2,thf],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    if save == True:\n",
    "        thf2.to_sql('stock_financial',con=conn,if_exists='append',index=False)\n",
    "    return thf2\n",
    "\n",
    "def download_quarter (ticker,save):\n",
    "    test = []\n",
    "    test2 = []\n",
    "    test3 = []\n",
    "    count = 0\n",
    "    revenue,YoYR = [],[]\n",
    "\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "\n",
    "    op = webdriver.ChromeOptions()\n",
    "    #op.add_argument('headless') \n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    thf2 = pd.DataFrame()\n",
    "    query_index = \"SELECT `Index` FROM stock_info WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_index = pd.read_sql(query_index, conn).values.tolist()[0][0]\n",
    "    tickerest = ticker.split('.')[0]\n",
    "    if check_index == 'SET100':\n",
    "        driver.get('https://www.tradingview.com/symbols/SET-%s/financials-income-statement/'% tickerest)\n",
    "    else:\n",
    "        driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% tickerest)\n",
    "\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-3):\n",
    "                if k%2 == 0:\n",
    "                    a = test2[k+2]\n",
    "                    revenue.append(a[1:-1])\n",
    "                else:\n",
    "                    YoYR.append(test2[k+2])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                revenue.append(a[1:-1])\n",
    "                YoYR.append(None)\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "        YoYR = []\n",
    "        revenue = []\n",
    "\n",
    "    a = range(len(Oth))\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':(ticker),'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "            thf = pd.DataFrame(data,index=[i])\n",
    "            thf2 = pd.concat([thf2,thf],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    if save == True:\n",
    "        thf2.to_sql('stock_quarter',con=conn,if_exists='append',index=False)\n",
    "    return thf2\n",
    "\n",
    "def download_new_stock(Ticker):\n",
    "    a = download_info(Ticker)\n",
    "    b = download_stock(Ticker)\n",
    "    c = download_year(Ticker,True)\n",
    "    d = download_quarter(Ticker,True)\n",
    "download_new_stock('CMRA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "error in index ix_stock_quarter_index after drop column: no such column: index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m conn \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(\u001b[39m\"\u001b[39m\u001b[39mstock.sqlite\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m cur \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mcursor()\n\u001b[1;32m----> 3\u001b[0m cur\u001b[39m.\u001b[39;49mexecute(\u001b[39m\"\u001b[39;49m\u001b[39mALTER TABLE stock_quarter DROP COLUMN [index]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      4\u001b[0m conn\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mOperationalError\u001b[0m: error in index ix_stock_quarter_index after drop column: no such column: index"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"ALTER TABLE stock_quarter DROP COLUMN [index]\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '']\n",
      "['', '']\n",
      "\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "head = []\n",
    "data_l = []\n",
    "TTM= ''\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "ticker = 'AAV.BK'\n",
    "driver.get(\"https://finance.yahoo.com/quote/AAV.BK/financials?p='%s'\" % ticker)\n",
    "time.sleep(5)\n",
    "header = driver.find_elements(By.XPATH, '//*[@id=\"Col1-1-Financials-Proxy\"]/section/div[3]/div[1]/div/div[1]/div')\n",
    "data = driver.find_elements(By.XPATH, '//*[@id=\"Col1-1-Financials-Proxy\"]/section/div[3]/div[1]/div')\n",
    "\n",
    "time.sleep(5)\n",
    "while data_l == [] or data_l == ['']:\n",
    "    for element in data:\n",
    "        data_l.append(element.text)\n",
    "    time.sleep(1)\n",
    "print(data_l)\n",
    "try:\n",
    "    TTM = data_l[0].split('\\n')[1][:3]\n",
    "except:\n",
    "    pass\n",
    "print(data_l)\n",
    "print(TTM)\n",
    "# for i in data_l[0].split('\\n')[1]:\n",
    "#     head.append()\n",
    "# df = pd.DataFrame({'year':[data_l[0].split('\\n')]})\n",
    "print(data_l[0].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Breakdown\\nTTM12/30/202212/30/202112/30/202012/30/2019\\nTotal Revenue\\n17,553,287 17,553,287 3,828,468 13,633,868 40,180,651\\nCost of Revenue\\n23,533,471 23,533,471 11,223,276 20,484,163 38,358,527\\nGross Profit\\n-5,980,184 -5,980,184 -7,394,807 -6,850,295 1,822,124\\nOperating Expense\\n1,726,321 1,726,321 1,437,711 1,850,767 3,294,605\\nOperating Income\\n-7,706,505 -7,706,505 -8,832,518 -8,701,062 -1,472,481\\nNet Non Operating Interest Income Expense\\n-2,190,313 -2,190,313 -1,848,417 -1,776,163 -765,529\\nOther Income Expense\\n-769,104 -769,104 -3,018,080 1,150,318 1,372,448\\nPretax Income\\n-10,665,922 -10,665,922 -13,699,015 -9,326,907 -865,562\\nTax Provision\\n-2,451,560 -2,451,560 -1,741,067 -659,978 599.706\\nNet Income Common Stockholders\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nDiluted NI Available to Com Stockholders\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nBasic EPS\\n- - -1.30 -0.94 -0.09\\nDiluted EPS\\n- - -1.30 -0.94 -0.09\\nBasic Average Shares\\n- - 5,119,513 5,085,317 5,085,317\\nDiluted Average Shares\\n- - 5,179,943 5,085,317 5,085,317\\nTotal Operating Income as Reported\\n-8,475,609 -8,475,609 -11,850,598 -7,550,743 -\\nTotal Expenses\\n25,259,792 25,259,792 12,660,986 22,334,930 41,653,132\\nNet Income from Continuing & Discontinued Operation\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nNormalized Income\\n-7,195,415 -7,195,415 -3,761,087 -5,158,316 -754,377\\nInterest Income\\n29,186 29,186 50,397 23,619 -\\nInterest Expense\\n2,113,770 2,113,770 1,786,662 1,603,008 765,529\\nNet Interest Income\\n-2,190,313 -2,190,313 -1,848,417 -1,776,163 -765,529\\nEBIT\\n-8,552,152 -8,552,152 -11,912,353 -7,723,899 -100,032\\nEBITDA\\n-2,438,099 - - - -\\nReconciled Cost of Revenue\\n23,533,471 23,533,471 11,223,276 20,484,163 38,358,527\\nReconciled Depreciation\\n6,114,053 6,114,053 5,434,314 5,738,993 1,716,746\\nNet Income from Continuing Operation Net Minority Interest\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nTotal Unusual Items Excluding Goodwill\\n-1,083,661 -1,083,661 -3,306,655 424,243 350,472\\nTotal Unusual Items\\n-1,083,661 -1,083,661 -3,306,655 424,243 350,472\\nNormalized EBITDA\\n-1,354,438 -1,354,438 -3,171,384 -2,409,150 1,266,241\\nTax Rate for Calcs\\n0 0 0 0 0\\nTax Effect of Unusual Items\\n-249,079 -249,079 -420,257 30,020 70,094'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Total revenue</th>\n",
       "      <th>YoY growth Total revenue</th>\n",
       "      <th>Cost of goods sold</th>\n",
       "      <th>Gross profit</th>\n",
       "      <th>YoY growth Gross profit</th>\n",
       "      <th>Operating expenses (excl. COGS)</th>\n",
       "      <th>Operating income</th>\n",
       "      <th>YoY growth Operating income</th>\n",
       "      <th>Non-operating income, total</th>\n",
       "      <th>...</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Diluted EPS YoY growth</th>\n",
       "      <th>Average basic shares outstanding</th>\n",
       "      <th>Diluted shares outstanding</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>YoY growth EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>YoY growth EBIT</th>\n",
       "      <th>Total operating expenses</th>\n",
       "      <th>Quarterly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>8.26B</td>\n",
       "      <td>+440.51%</td>\n",
       "      <td>−7.59B</td>\n",
       "      <td>671.99M</td>\n",
       "      <td>+129.60%</td>\n",
       "      <td>−538.07M</td>\n",
       "      <td>133.92M</td>\n",
       "      <td>+104.93%</td>\n",
       "      <td>3.67B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>+306.64%</td>\n",
       "      <td>11.36B</td>\n",
       "      <td>11.36B</td>\n",
       "      <td>1.52B</td>\n",
       "      <td>+282.52%</td>\n",
       "      <td>133.92M</td>\n",
       "      <td>+104.93%</td>\n",
       "      <td>8.13B</td>\n",
       "      <td>Q4 '22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker Total revenue YoY growth Total revenue Cost of goods sold  \\\n",
       "6  AAV.BK         8.26B                 +440.51%             −7.59B   \n",
       "\n",
       "  Gross profit YoY growth Gross profit Operating expenses (excl. COGS)  \\\n",
       "6      671.99M                +129.60%                        −538.07M   \n",
       "\n",
       "  Operating income YoY growth Operating income Non-operating income, total  \\\n",
       "6          133.92M                    +104.93%                       3.67B   \n",
       "\n",
       "   ... Diluted EPS Diluted EPS YoY growth Average basic shares outstanding  \\\n",
       "6  ...        0.27               +306.64%                           11.36B   \n",
       "\n",
       "  Diluted shares outstanding EBITDA YoY growth EBITDA     EBIT  \\\n",
       "6                     11.36B  1.52B          +282.52%  133.92M   \n",
       "\n",
       "  YoY growth EBIT Total operating expenses Quarterly  \n",
       "6        +104.93%                    8.13B    Q4 '22  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(thf2)\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "count = 1\n",
    "query = \"SELECT Quarterly FROM stock_quarter WHERE `Ticker` == '%s'\" % ('AAV.BK')\n",
    "test = pd.read_sql(query, conn).values.tolist()[-1]\n",
    "q = thf2['Quarterly']\n",
    "for i in range(a):\n",
    "    if [list(thf2['Quarterly'].values)[i]] == test :\n",
    "        break\n",
    "    count += 1\n",
    "data = thf2.iloc[count:,:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "thf2.to_sql('stock_quarter',con=con,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_quarter',con=con,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technology', 'Consumer Electronics']\n",
      "  Ticker Industry Group                Sector      Index\n",
      "0   AAPL     Technology  Consumer Electronics  NASDAQ100\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_link = []\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "InsSec = []\n",
    "driver.get(\"https://finance.yahoo.com/quote/AAPL/profile?p=AAPL\")\n",
    "numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "for i in numlink[:2]:\n",
    "    InsSec.append(i.text)\n",
    "print(InsSec)\n",
    "df1 = pd.DataFrame({'Ticker': [j], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_info',con=con,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td>16.678928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>16.663929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15</th>\n",
       "      <td>16.434286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-19</th>\n",
       "      <td>16.428213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-20</th>\n",
       "      <td>16.030357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>131.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>130.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>126.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>129.610001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>129.929993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL\n",
       "Date                  \n",
       "2013-02-13   16.678928\n",
       "2013-02-14   16.663929\n",
       "2013-02-15   16.434286\n",
       "2013-02-19   16.428213\n",
       "2013-02-20   16.030357\n",
       "...                ...\n",
       "2022-12-23  131.860001\n",
       "2022-12-27  130.029999\n",
       "2022-12-28  126.040001\n",
       "2022-12-29  129.610001\n",
       "2022-12-30  129.929993\n",
       "\n",
       "[2489 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "query = \"select * from stock_table_d where `ticker` == 'AAPL' and datetime > '2012-01-01' and datetime < '2023-01-01'\"\n",
    "df = pd.read_sql(query,conn)\n",
    "df['Date'] = pd.to_datetime(df['Datetime'])\n",
    "df.set_index(df['Date'],inplace = True)\n",
    "\n",
    "data = df.filter(['Close'])\n",
    "data.rename(columns={'Close':'AAPL'}, inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "miss = ['ABNB', 'ADI', 'AEP', 'AMGN', 'ATVI', 'BIIB', 'BKR', 'CSX', 'DXCM', 'EBAY', 'ENPH', 'EXC', 'FISV', 'GOOGL', 'HON', 'ILMN', 'JD', 'KHC', 'KLAC', 'LCID', 'LULU', 'MAR', 'MNST', 'MSFT', 'PANW', 'PCAR', 'PDD', 'PEP', 'REGN', 'RIVN', 'SIRI', 'VRTX', 'XEL', 'ZS']\n",
    "miss2 = ['ADI', 'AEP', 'BKR', 'CSGP', 'CSX', 'EXC', 'HON', 'KHC', 'KLAC']\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "again = []\n",
    "for i in miss:\n",
    "    print(i)\n",
    "    try:\n",
    "        datamo = yf.download(tickers=i,period='5y',interval=\"1mo\",progress=True)\n",
    "        datamo.index.names = ['Datetime']\n",
    "        datamo['Ticker'] = i\n",
    "        datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)\n",
    "    except:\n",
    "        again.append(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "miss = ['ABNB', 'AMGN', 'ATVI', 'BIIB', 'DXCM', 'EBAY', 'ENPH', 'FISV', 'GOOGL', 'ILMN', 'JD', 'LCID', 'LULU', 'MAR', 'MNST', 'MSFT', 'PANW', 'PCAR', 'PDD', 'PEP', 'REGN', 'RIVN', 'SIRI', 'VRTX', 'ZS']\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "again = []\n",
    "for i in miss:\n",
    "    print(i)\n",
    "    try:\n",
    "        datad = yf.download(tickers=i,period='max',interval=\"1d\",progress=True)\n",
    "        datad.index.names = ['Datetime']\n",
    "        datad['Ticker'] = i\n",
    "        datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    except:\n",
    "        again.append(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "miss = ['ABNB', 'AMGN', 'ATVI', 'BIIB', 'DXCM', 'EBAY', 'ENPH', 'FISV', 'GOOGL', 'ILMN', 'JD', 'LCID', 'LULU', 'MAR', 'MNST', 'MSFT', 'PANW', 'PCAR', 'PDD', 'PEP', 'REGN', 'RIVN', 'SIRI', 'VRTX', 'ZS']\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "again = []\n",
    "for i in miss:\n",
    "    print(i)\n",
    "    try:\n",
    "        datahr = yf.download(tickers=i,period='2y',interval=\"1h\",progress=True)\n",
    "        datahr.index.names = ['Datetime']\n",
    "        datahr['Ticker'] = i\n",
    "        datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    except:\n",
    "        again.append(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-03-17 15:00:00']\n",
      "['2023', '03', '17']\n",
      "0\n",
      "2023-03-17T10:00:00.000000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-03-17 16:00:00</th>\n",
       "      <td>30.25</td>\n",
       "      <td>30.25</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.25</td>\n",
       "      <td>30.25</td>\n",
       "      <td>724606</td>\n",
       "      <td>PTT.BK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Open   High   Low  Close  Adj Close  Volume  ticker\n",
       "Datetime                                                                 \n",
       "2023-03-17 16:00:00  30.25  30.25  30.0  30.25      30.25  724606  PTT.BK"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "def getLastDate(period,ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    cur = conn.cursor()\n",
    "    # Query last element of stock in database\n",
    "    if period == 'Hour':\n",
    "        query = \"SELECT * FROM stock_table_hr WHERE `ticker` = '%s'\" % ticker\n",
    "    elif period == 'Day':\n",
    "        query = \"SELECT * FROM stock_table_d WHERE `ticker` = '%s'\" % ticker\n",
    "    elif period == 'Month':\n",
    "        query = \"SELECT * FROM stock_table_mo WHERE `ticker` = '%s'\" % ticker\n",
    "    else:\n",
    "        return False\n",
    "    r_df = pd.read_sql(query, conn)\n",
    "    # Cut data to get only datatime\n",
    "    last = r_df.tail(1).Datetime.to_string().split()\n",
    "    LastDate = last[1].split()[0].split('-')\n",
    "    cur.close()\n",
    "    return LastDate,r_df\n",
    "\n",
    "def getDiffDay(period,ticker):\n",
    "    LastDate,r_df = getLastDate(period,ticker)\n",
    "    if LastDate == False:\n",
    "        return False\n",
    "    # Get datetime for now\n",
    "    x = datetime.datetime.now()\n",
    "    count = 0\n",
    "    DayM = 0\n",
    "    DayMo365 = {'1':31,'2':28,'3':31,'4':30,'5':31,'6':30,'7':31,'8':31,'9':30,'10':31,'11':30,'12':31}\n",
    "    DiffMo = int(x.month) - int(LastDate[1])\n",
    "    DiffYe = int(x.year) - int(LastDate[0])\n",
    "    # Get differend day for dowload stock\n",
    "    if DiffYe == 0:\n",
    "        if DiffMo == 0:\n",
    "            DiffDay = int(x.day) - int(LastDate[2])\n",
    "            if DiffDay != 0:pass\n",
    "        elif DiffMo != 0 :\n",
    "            for u in range(DiffMo):\n",
    "                DayM = DayM + DayMo365[str(int(LastDate[1])+count)]\n",
    "                count += 1\n",
    "            DiffDay = DayM - int(LastDate[2]) + int(x.day)\n",
    "    elif DiffYe != 0:\n",
    "        dayly = 0\n",
    "        dayn = 0\n",
    "        for j in range(1,int(LastDate[1])):\n",
    "            dayly = dayly + DayMo365[str(j)]\n",
    "        for i in range(1,int(x.month)):\n",
    "            dayn = dayn + DayMo365[str(i)]\n",
    "        DiffDay = (365*DiffYe) - dayly + dayn - int(LastDate[2]) + int(x.day)   \n",
    "    return DiffDay\n",
    "    \n",
    "def update(period,ticker):\n",
    "    LastDate,r_df = getLastDate(period,ticker)\n",
    "    DiffDay = getDiffDay(period,ticker)\n",
    "    print(r_df.tail(1)['Datetime'].values)\n",
    "    print(LastDate)\n",
    "    print(DiffDay)\n",
    "    if DiffDay == False:\n",
    "        DiffDay += 1\n",
    "    down = 0\n",
    "    count = 0\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    query = \"SELECT `Index` FROM stock_info WHERE `ticker` = '%s'\" % ticker\n",
    "    for_ind = pd.read_sql(query, conn)\n",
    "    ok = r_df.tail(1).Datetime.to_string().split()[2]\n",
    "    #for get extra time in database\n",
    "    if for_ind['Index'].values == 'NASDAQ100':\n",
    "        DiffDay = str(DiffDay)+'d'\n",
    "        if ok == '09:30:00':down = 0\n",
    "        elif ok == '10:30:00':down = 1\n",
    "        elif ok == '11:30:00':down = 2\n",
    "        elif ok == '12:30:00':down = 3\n",
    "        elif ok == '13:30:00':down = 4\n",
    "        elif ok == '14:30:00':down = 5\n",
    "        elif ok == '15:30:00':down = 6\n",
    "    elif for_ind['Index'].values == 'SET100':\n",
    "        DiffDay = str(DiffDay)+'d'\n",
    "        if ok == '10:00:00':down = 0\n",
    "        elif ok == '11:00:00':down = 1\n",
    "        elif ok == '12:00:00':down = 2\n",
    "        elif ok == '14:00:00':down = 3\n",
    "        elif ok == '15:00:00':down = 4\n",
    "        elif ok == '16:00:00':down = 5\n",
    "    elif for_ind['Index'].values == 'CRYPTO100':\n",
    "        DiffDay = str(DiffDay+1)+'d'\n",
    "        if ok == '00:00:00':down = 0\n",
    "        elif ok == '01:00:00':down = 1\n",
    "        elif ok == '02:00:00':down = 2\n",
    "        elif ok == '03:00:00':down = 3\n",
    "        elif ok == '04:00:00':down = 4\n",
    "        elif ok == '05:00:00':down = 5\n",
    "        elif ok == '06:00:00':down = 6\n",
    "        elif ok == '07:00:00':down = 7\n",
    "        elif ok == '08:00:00':down = 8\n",
    "        elif ok == '09:00:00':down = 9\n",
    "        elif ok == '10:00:00':down = 10\n",
    "        elif ok == '11:00:00':down = 11\n",
    "        elif ok == '12:00:00':down = 12\n",
    "        elif ok == '13:00:00':down = 13\n",
    "        elif ok == '14:00:00':down = 14\n",
    "        elif ok == '15:00:00':down = 15\n",
    "        elif ok == '16:00:00':down = 16\n",
    "        elif ok == '17:00:00':down = 17\n",
    "        elif ok == '18:00:00':down = 18\n",
    "        elif ok == '19:00:00':down = 19\n",
    "        elif ok == '20:00:00':down = 20\n",
    "        elif ok == '21:00:00':down = 21\n",
    "        elif ok == '22:00:00':down = 22\n",
    "        elif ok == '23:00:00':down = 23\n",
    "    # Select period to download\n",
    "    if period == 'Hour':data = yf.download(tickers=ticker, period=DiffDay, interval='1h',progress=False)\n",
    "    elif period == 'Day':data = yf.download(tickers=ticker, period=DiffDay, interval='1d',progress=False)\n",
    "    elif period == 'Month':data = yf.download(tickers=ticker, period=DiffDay, interval='1mo',progress=False)\n",
    "    # Get number of extra stock\n",
    "    print(data.index.values[0])\n",
    "    for i in data.index.day:\n",
    "        if data.index.year[count] == int(LastDate[0]):\n",
    "            if data.index.month[count] == int(LastDate[1]):\n",
    "                if period == 'Month':\n",
    "                    if i == int(LastDate[2])+1 or i == int(LastDate[2])+2 or i == int(LastDate[2])+3 or i == int(LastDate[2]):\n",
    "                        if str(data.index.values[0]).split('T')[0] == r_df.tail(1)['Datetime'].values[0].split(' ')[0]:\n",
    "                            count += 1\n",
    "                        break\n",
    "                else:\n",
    "                    if i == int(LastDate[2])+1 or i == int(LastDate[2])+2 or i == int(LastDate[2])+3 or i == int(LastDate[2]):\n",
    "                        count += 1\n",
    "                        break\n",
    "        count += 1\n",
    "    # Cut extra stock off\n",
    "    count = count + down\n",
    "    data['ticker'] = ticker\n",
    "    data.index.names = ['Datetime']\n",
    "    data = data.iloc[count:,:]\n",
    "    # Select period to download and Save to sqlite\n",
    "    # if period == 'Hour':data.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    # elif period == 'Day':data.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    # elif period == 'Month':data.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)\n",
    "    return data\n",
    "\n",
    "def getAllticker():\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    cur = conn.cursor()\n",
    "    query = \"select Ticker from stock_info\"\n",
    "    r_df = pd.read_sql(query,conn)\n",
    "    list_db = r_df['Ticker'].values.tolist()\n",
    "    return list_db\n",
    "    \n",
    "def updateAll():\n",
    "    period = ['Hour','Day','Month']\n",
    "    Ticker = getAllticker()\n",
    "    miss = []\n",
    "    for  i in Ticker:\n",
    "        try:\n",
    "            for j in period:\n",
    "                update(j,i)\n",
    "        except:\n",
    "            miss.append(i)\n",
    "            pass\n",
    "    print(miss)\n",
    "# updateAll()\n",
    "# getAllticker()\n",
    "# print(getDiffDay('Month','ACE.BK'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "data = yf.download(tickers='ptt.bk', period='10d', interval='1h',progress=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Not found ticker'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "def change_stock(Ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    query = \"SELECT Datetime,Open,Close FROM stock_table_hr WHERE [Ticker] = '%s'\" % Ticker\n",
    "    stock = pd.read_sql(query,conn)\n",
    "    try:\n",
    "        Open = stock.tail(1)['Open'].values.tolist()[0]\n",
    "        Close = stock.tail(1)['Close'].values.tolist()[0]\n",
    "    except:\n",
    "        return 'Not found ticker'\n",
    "    Diff = pd.DataFrame({'Ticker': [Ticker],'Diff':[int((Close-Open)*100)/100], 'Ratio': [str(int(((Close-Open)/Close)*10000)/100) + '%']})\n",
    "    return Diff\n",
    "\n",
    "def getAllticker():\n",
    "        conn = sqlite3.connect(\"stock.sqlite\")\n",
    "        cur = conn.cursor()\n",
    "        query = \"select Ticker from stock_info\"\n",
    "        r_df = pd.read_sql(query,conn)\n",
    "        list_db = r_df['Ticker'].values.tolist()\n",
    "        return list_db\n",
    "\n",
    "def All_change_stock():\n",
    "    Ticker = getAllticker()\n",
    "    df2 = pd.DataFrame()\n",
    "    for i in Ticker:\n",
    "        df = change_stock(i)\n",
    "        df2 = pd.concat([df2,df],ignore_index=True)\n",
    "    return df2\n",
    "change_stock('asdwasdw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c649cbfb4c288b76adc3417e379a1dde9839d571840c9111dd43481f544c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
