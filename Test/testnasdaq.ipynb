{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABNB', 'ADBE', 'ADI', 'ADSK', 'AEP', 'ALGN', 'AMAT', 'AMGN', 'ANSS', 'ATVI', 'AVGO', 'AZN', 'BIIB', 'BKNG', 'BKR', 'CEG', 'CHTR', 'COST', 'CPRT', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTSH', 'DLTR', 'DXCM', 'EA', 'EBAY', 'ENPH', 'EXC', 'FANG', 'FAST', 'FISV', 'FTNT', 'GOOG', 'GOOGL', 'HON', 'IDXX', 'ILMN', 'ISRG', 'JD', 'KHC', 'KLAC', 'LCID', 'LRCX', 'LULU', 'MAR', 'MCHP', 'MDLZ', 'MELI', 'MNST', 'MSFT', 'MU', 'ODFL', 'ORLY', 'PANW', 'PAYX', 'PCAR', 'PDD', 'PEP', 'QCOM', 'REGN', 'RIVN', 'ROST', 'SBUX', 'SGEN', 'SIRI', 'SNPS', 'TMUS', 'VRSK', 'VRTX', 'WDAY', 'XEL', 'ZM', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "nasdaq = []\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.nasdaq.com/market-activity/quotes/nasdaq-ndx-index')\n",
    "elements = driver.find_elements(By.XPATH, '//th[@class=\"nasdaq-ndx-index__cell nasdaq-ndx-index__cell--heading\"]')\n",
    "\n",
    "for element in elements:\n",
    "    nasdaq.append(element.text)\n",
    "print(nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- ADI: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- ADP: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- AEP: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- BKR: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- CSX: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- EXC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- HON: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- KHC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- KLAC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- TXN: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- XEL: Exception('Lost data during merge despite all attempts to align data (see above)')\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "for stock in nasdaq:\n",
    "    datahr = yf.download(tickers=stock,period=\"2y\",interval=\"1h\",progress=False)\n",
    "    datad = yf.download(tickers=stock,period='10y',interval=\"1d\",progress=False)\n",
    "    datamo = yf.download(tickers=stock,period='max',interval=\"1mo\",progress=False)\n",
    "\n",
    "    datahr['Ticker'] = stock\n",
    "\n",
    "    datad.index.names = ['Datetime']\n",
    "\n",
    "    datad['Ticker'] = stock\n",
    "\n",
    "    datamo.index.names = ['Datetime']\n",
    "\n",
    "    datamo['Ticker'] = stock\n",
    "\n",
    "    datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-16</th>\n",
       "      <td>135.490005</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>132.789993</td>\n",
       "      <td>133.190002</td>\n",
       "      <td>131.605835</td>\n",
       "      <td>80576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>132.220001</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>129.283798</td>\n",
       "      <td>97918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18</th>\n",
       "      <td>129.199997</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.410004</td>\n",
       "      <td>129.710007</td>\n",
       "      <td>128.167236</td>\n",
       "      <td>96856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>130.240005</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>129.869995</td>\n",
       "      <td>128.325333</td>\n",
       "      <td>87668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22</th>\n",
       "      <td>128.009995</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>124.501358</td>\n",
       "      <td>103916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>150.639999</td>\n",
       "      <td>155.229996</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>154.649994</td>\n",
       "      <td>154.414230</td>\n",
       "      <td>83322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>153.880005</td>\n",
       "      <td>154.580002</td>\n",
       "      <td>151.169998</td>\n",
       "      <td>151.919998</td>\n",
       "      <td>151.688400</td>\n",
       "      <td>64120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>153.779999</td>\n",
       "      <td>154.330002</td>\n",
       "      <td>150.419998</td>\n",
       "      <td>150.869995</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>56007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>149.460007</td>\n",
       "      <td>151.339996</td>\n",
       "      <td>149.220001</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>57409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>150.951996</td>\n",
       "      <td>153.690002</td>\n",
       "      <td>150.919998</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>21700329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Datetime                                                                 \n",
       "2021-02-16  135.490005  136.009995  132.789993  133.190002  131.605835   \n",
       "2021-02-17  131.250000  132.220001  129.470001  130.839996  129.283798   \n",
       "2021-02-18  129.199997  130.000000  127.410004  129.710007  128.167236   \n",
       "2021-02-19  130.240005  130.710007  128.800003  129.869995  128.325333   \n",
       "2021-02-22  128.009995  129.720001  125.599998  126.000000  124.501358   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-02-07  150.639999  155.229996  150.639999  154.649994  154.414230   \n",
       "2023-02-08  153.880005  154.580002  151.169998  151.919998  151.688400   \n",
       "2023-02-09  153.779999  154.330002  150.419998  150.869995  150.639999   \n",
       "2023-02-10  149.460007  151.339996  149.220001  151.009995  151.009995   \n",
       "2023-02-13  150.951996  153.690002  150.919998  153.389999  153.389999   \n",
       "\n",
       "               Volume  \n",
       "Datetime               \n",
       "2021-02-16   80576300  \n",
       "2021-02-17   97918500  \n",
       "2021-02-18   96856700  \n",
       "2021-02-19   87668800  \n",
       "2021-02-22  103916400  \n",
       "...               ...  \n",
       "2023-02-07   83322600  \n",
       "2023-02-08   64120100  \n",
       "2023-02-09   56007100  \n",
       "2023-02-10   57409100  \n",
       "2023-02-13   21700329  \n",
       "\n",
       "[503 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datad = yf.download(tickers='AAPL',period=\"2y\",interval=\"1d\",progress=False)\n",
    "datad.index.names = ['Datetime']\n",
    "datad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_link = []\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "print(len(nasdaq))\n",
    "for j in nasdaq:\n",
    "    InsSec = []\n",
    "    driver.get(\"https://finance.yahoo.com/quote/%s/profile?p=%s\" %(j,j))\n",
    "    numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "    for i in numlink[:2]:\n",
    "        InsSec.append(i.text)\n",
    "    df1 = pd.DataFrame({'Ticker': [j], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "    df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "    print('-------')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_info',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BTC-USD', 'ETH-USD', 'USDT-USD', 'BNB-USD', 'USDC-USD', 'XRP-USD', 'BUSD-USD', 'ADA-USD', 'DOGE-USD', 'MATIC-USD', 'HEX-USD', 'SOL-USD', 'DOT-USD', 'SHIB-USD', 'LTC-USD', 'WTRX-USD', 'TRX-USD', 'AVAX-USD', 'STETH-USD', 'DAI-USD', 'UNI7083-USD', 'WBTC-USD', 'ATOM-USD', 'LINK-USD', 'LEO-USD', 'ETC-USD', 'XMR-USD', 'TON11419-USD', 'OKB-USD', 'BCH-USD', 'APT21794-USD', 'LDO-USD', 'HBAR-USD', 'XLM-USD', 'FIL-USD', 'NEAR-USD', 'APE18876-USD', 'CRO-USD', 'ALGO-USD', 'VET-USD', 'QNT-USD', 'ICP-USD', 'GRT6719-USD', 'FTM-USD', 'MANA-USD', 'TMG-USD', 'BTCB-USD', 'BIT11221-USD', 'AAVE-USD', 'EOS-USD', 'WBNB-USD', 'AXS-USD', 'EGLD-USD', 'FLOW-USD', 'THETA-USD', 'SAND-USD', 'FRAX-USD', 'LUNC-USD', 'XTZ-USD', 'TUSD-USD', 'IMX10603-USD', 'CHZ-USD', 'MINA-USD', 'HBTC-USD', 'USDP-USD', 'RPL-USD', 'HT-USD', 'KCS-USD', 'CRV-USD', 'BSV-USD', 'FXS-USD', 'DASH-USD', 'ZEC-USD', 'MKR-USD', 'USDD-USD', 'BTTOLD-USD', 'BTT-USD', 'CAKE-USD', 'XEC-USD', 'MIOTA-USD', 'TNC5524-USD', 'GMX11857-USD', 'SNX-USD', 'KLAY-USD', 'BGB-USD', 'NEO-USD', 'TWT-USD', 'GUSD-USD', 'OP-USD', 'RUNE-USD', 'LRC-USD', 'FTT-USD', 'AGIX-USD', 'PAXG-USD', 'OSMO-USD', 'XRD-USD', 'BABYDOGE-USD', 'GT-USD', 'ZIL-USD', 'CVX-USD']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "cryp = []\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://finance.yahoo.com/crypto/?offset=0&count=100')\n",
    "elements = driver.find_elements(By.XPATH, '//a[@class=\"Fw(600) C($linkColor)\"]')\n",
    "\n",
    "for element in elements:\n",
    "    cryp.append(element.text)\n",
    "print(cryp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Ticker Industry Group  Sector      Index\n",
      "0        BTC-USD         Crypto  Crypto  Crypto100\n",
      "1        ETH-USD         Crypto  Crypto  Crypto100\n",
      "2       USDT-USD         Crypto  Crypto  Crypto100\n",
      "3        BNB-USD         Crypto  Crypto  Crypto100\n",
      "4       USDC-USD         Crypto  Crypto  Crypto100\n",
      "..           ...            ...     ...        ...\n",
      "95       XRD-USD         Crypto  Crypto  Crypto100\n",
      "96  BABYDOGE-USD         Crypto  Crypto  Crypto100\n",
      "97        GT-USD         Crypto  Crypto  Crypto100\n",
      "98       ZIL-USD         Crypto  Crypto  Crypto100\n",
      "99       CVX-USD         Crypto  Crypto  Crypto100\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "cf2 = pd.DataFrame()\n",
    "for j in cryp:\n",
    "    cf1 = pd.DataFrame({'Ticker': [j], 'Industry Group': ['Crypto'], 'Sector': ['Crypto'], 'Index': ['Crypto100']})\n",
    "    cf2 = pd.concat([cf2,cf1],ignore_index=True)\n",
    "print(cf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "cf2.to_sql('stock_info',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "for stock in cryp:\n",
    "    # datahr = yf.download(tickers=stock,period=\"2y\",interval=\"1h\",progress=False)\n",
    "    # datad = yf.download(tickers=stock,period='max',interval=\"1d\",progress=False)\n",
    "    datamo = yf.download(tickers=stock,period='max',interval=\"1mo\",progress=False)\n",
    "\n",
    "    # datahr['Ticker'] = stock\n",
    "\n",
    "    # datad.index.names = ['Datetime']\n",
    "\n",
    "    # datad['Ticker'] = stock\n",
    "\n",
    "    datamo.index.names = ['Datetime']\n",
    "\n",
    "    datamo['Ticker'] = stock\n",
    "\n",
    "    # print(datad)\n",
    "    # datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    # datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Q1 '21\", \"Q2 '21\", \"Q3 '21\", \"Q4 '21\", \"Q1 '22\", \"Q2 '22\", \"Q3 '22\"]\n",
      "[['+5.36%', '+298.84%', '+66.68%', '+78.31%', '+70.13%', '+57.59%', '+28.92%'], [None, None, None, None, None, None, None], ['âˆ’20.76%', '+379.70%', '+52.24%', '+90.43%', '+104.32%', '+74.83%', '+29.21%'], [None, None, None, None, None, None, None], ['âˆ’2.91%', '+89.19%', '+92.88%', '+102.53%', '+98.56%', '+1002.21%', '+41.34%'], [None, None, None, None, None, None, None], ['âˆ’226.50%', '+91.09%', '+176.98%', '+101.81%', '+99.31%', '+772.31%', '+49.32%'], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], ['âˆ’244.16%', '+88.15%', '+280.20%', '+101.40%', '+98.40%', '+655.35%', '+45.62%'], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], ['âˆ’239.12%', '+88.53%', '+262.53%', '+101.33%', '+98.48%', '+632.20%', '+41.58%'], ['âˆ’239.12%', '+88.53%', '+230.16%', '+101.23%', '+98.48%', '+597.04%', '+46.01%'], [None, None, None, None, None, None, None], [None, None, None, None, None, None, None], ['âˆ’1.75%', '+96.54%', '+87.90%', '+103.58%', '+108.23%', '+3285.58%', '+37.41%'], ['âˆ’2.91%', '+89.19%', '+92.88%', '+102.53%', '+98.56%', '+1002.21%', '+41.34%'], [None, None, None, None, None, None, None]]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "test = []\n",
    "test2 = []\n",
    "test3 = []\n",
    "count = 0\n",
    "revenue,YoYR = [],[]\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless')\n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.tradingview.com/symbols/NASDAQ-ABNB/financials-income-statement/')\n",
    "header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "\n",
    "Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "              raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "              raw21,raw22,raw23,raw24]\n",
    "\n",
    "YoY = [''] * len(Allelement)\n",
    "Oth = [''] * len(Allelement)\n",
    "for element in header:\n",
    "    test.append(element.text)\n",
    "year = test[0].split('\\n')[1:-1]\n",
    "for e in Allelement:\n",
    "    test2 = []\n",
    "    for h in e:\n",
    "        test2.append(h.text)\n",
    "    test2 = test2[0].split('\\n')\n",
    "    if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "        for k in range(len(test2)-3):\n",
    "            if k%2 == 0:\n",
    "                a = test2[k+2]\n",
    "                revenue.append(a[1:-1])\n",
    "            else:\n",
    "                YoYR.append(test2[k+2])\n",
    "    else:\n",
    "        for k in range(len(test2)-2):\n",
    "            a = test2[k+1]\n",
    "            revenue.append(a[1:-1])\n",
    "            YoYR.append(None)\n",
    "\n",
    "    YoY[count] = (YoYR)\n",
    "    Oth[count] = (revenue)\n",
    "    count += 1\n",
    "    YoYR = []\n",
    "    revenue = []\n",
    "\n",
    "print(year)\n",
    "print(YoY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total revenue YoY growth Total revenue Cost of goods sold Gross profit  \\\n",
      "0       886.94M                   +5.36%           âˆ’439.95M      446.99M   \n",
      "1         1.34B                 +298.84%           âˆ’502.55M      832.64M   \n",
      "2         2.24B                  +66.68%           âˆ’539.91M        1.70B   \n",
      "3         1.53B                  +78.31%           âˆ’295.31M        1.24B   \n",
      "4         1.51B                  +70.13%           âˆ’595.63M      913.30M   \n",
      "5         2.10B                  +57.59%           âˆ’648.36M        1.46B   \n",
      "6         2.88B                  +28.92%           âˆ’691.10M        2.19B   \n",
      "\n",
      "  YoY growth Gross profit Operating expenses (excl. COGS) Operating income  \\\n",
      "0                 âˆ’20.76%                        âˆ’781.95M         âˆ’334.96M   \n",
      "1                +379.70%                        âˆ’883.36M          âˆ’50.72M   \n",
      "2                 +52.24%                        âˆ’846.01M          851.51M   \n",
      "3                 +90.43%                          âˆ’1.16B           77.14M   \n",
      "4                +104.32%                        âˆ’918.12M           âˆ’4.81M   \n",
      "5                 +74.83%                        âˆ’998.18M          457.57M   \n",
      "6                 +29.21%                        âˆ’989.78M            1.20B   \n",
      "\n",
      "  YoY growth Operating income Non-operating income, total Pretax income  ...  \\\n",
      "0                      âˆ’2.91%                    âˆ’830.94M        âˆ’1.17B  ...   \n",
      "1                     +89.19%                      âˆ’6.27M       âˆ’56.98M  ...   \n",
      "2                     +92.88%                      âˆ’1.05M       850.46M  ...   \n",
      "3                    +102.53%                      âˆ’4.92M        72.22M  ...   \n",
      "4                     +98.56%                      âˆ’3.27M        âˆ’8.09M  ...   \n",
      "5                   +1002.21%                     âˆ’74.45M       383.11M  ...   \n",
      "6                     +41.34%                      66.37M         1.27B  ...   \n",
      "\n",
      "  Diluted EPS Diluted EPS YoY growth Average basic shares outstanding  \\\n",
      "0       âˆ’1.95               âˆ’239.12%                          600.96M   \n",
      "1       âˆ’0.11                +88.53%                          611.74M   \n",
      "2        1.22               +230.16%                          621.01M   \n",
      "3        0.08               +101.23%                          629.48M   \n",
      "4       âˆ’0.03                +98.48%                          635.31M   \n",
      "5        0.55               +597.04%                          638.41M   \n",
      "6        1.79                +46.01%                          638.70M   \n",
      "\n",
      "  Diluted shares outstanding    EBITDA YoY growth EBITDA      EBIT  \\\n",
      "0                    600.96M  âˆ’296.71M            âˆ’1.75%  âˆ’334.96M   \n",
      "1                    611.74M   âˆ’15.18M           +96.54%   âˆ’50.72M   \n",
      "2                    681.92M   885.20M           +87.90%   851.51M   \n",
      "3                    680.90M   107.98M          +103.58%    77.14M   \n",
      "4                    635.31M    24.42M          +108.23%    âˆ’4.81M   \n",
      "5                    683.54M   483.57M         +3285.58%   457.57M   \n",
      "6                    680.06M     1.22B           +37.41%     1.20B   \n",
      "\n",
      "  YoY growth EBIT Total operating expenses Quarterly  \n",
      "0          âˆ’2.91%                    1.22B    Q1 '21  \n",
      "1         +89.19%                    1.39B    Q2 '21  \n",
      "2         +92.88%                    1.39B    Q3 '21  \n",
      "3        +102.53%                    1.46B    Q4 '21  \n",
      "4         +98.56%                    1.51B    Q1 '22  \n",
      "5       +1002.21%                    1.65B    Q2 '22  \n",
      "6         +41.34%                    1.68B    Q3 '22  \n",
      "\n",
      "[7 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "a = range(len(Oth))\n",
    "df2 = pd.DataFrame()\n",
    "for i in range(len(year)):\n",
    "    data = {'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "        'Cost of goods sold':Oth[1][i],\n",
    "        'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "        'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "        'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "        'Non-operating income, total':Oth[5][i],\n",
    "        'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[7][i],\n",
    "        'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "        'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "        'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "        'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "        'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "        'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "        'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "        'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "        'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "    df = pd.DataFrame(data,index=[i])\n",
    "    df2 = pd.concat([df2,df],ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Currency: USD\\nQ2 '21\\nQ3 '21\\nQ4 '21\\nQ1 '22\\nQ2 '22\\nQ3 '22\\nQ4 '22\\nTTM\\nTotal revenue\\nYoY growth\\n\\u202a1.34B\\u202c\\n+298.84%\\n\\u202a2.24B\\u202c\\n+66.68%\\n\\u202a1.53B\\u202c\\n+78.31%\\n\\u202a1.51B\\u202c\\n+70.13%\\n\\u202a2.10B\\u202c\\n+57.59%\\n\\u202a2.88B\\u202c\\n+28.92%\\n\\u202a1.90B\\u202c\\n+24.14%\\n\\u202a8.40B\\u202c\\nCost of goods sold\\n\\u202aâˆ’502.55M\\u202c\\n\\u202aâˆ’539.91M\\u202c\\n\\u202aâˆ’295.31M\\u202c\\n\\u202aâˆ’595.63M\\u202c\\n\\u202aâˆ’648.36M\\u202c\\n\\u202aâˆ’691.10M\\u202c\\n\\u202aâˆ’345.00M\\u202c\\n\\u202aâˆ’2.28B\\u202c\\nGross profit\\nYoY growth\\n\\u202a832.64M\\u202c\\n+379.70%\\n\\u202a1.70B\\u202c\\n+52.24%\\n\\u202a1.24B\\u202c\\n+90.43%\\n\\u202a913.30M\\u202c\\n+104.32%\\n\\u202a1.46B\\u202c\\n+74.83%\\n\\u202a2.19B\\u202c\\n+29.21%\\n\\u202a1.56B\\u202c\\n+25.88%\\n\\u202a6.12B\\u202c\\nOperating expenses (excl. COGS)\\n\\u202aâˆ’883.36M\\u202c\\n\\u202aâˆ’846.01M\\u202c\\n\\u202aâˆ’1.16B\\u202c\\n\\u202aâˆ’918.12M\\u202c\\n\\u202aâˆ’998.18M\\u202c\\n\\u202aâˆ’989.78M\\u202c\\n\\u202aâˆ’1.32B\\u202c\\n\\u202aâˆ’4.23B\\u202c\\nOperating income\\nYoY growth\\n\\u202aâˆ’50.72M\\u202c\\n+89.19%\\n\\u202a851.51M\\u202c\\n+92.88%\\n\\u202a77.14M\\u202c\\n+102.53%\\n\\u202aâˆ’4.81M\\u202c\\n+98.56%\\n\\u202a457.57M\\u202c\\n+1002.21%\\n\\u202a1.20B\\u202c\\n+41.34%\\n\\u202a233.00M\\u202c\\n+202.06%\\n\\u202a1.89B\\u202c\\nNon-operating income, total\\n\\u202aâˆ’6.27M\\u202c\\n\\u202aâˆ’1.05M\\u202c\\n\\u202aâˆ’4.92M\\u202c\\n\\u202aâˆ’3.27M\\u202c\\n\\u202aâˆ’74.45M\\u202c\\n\\u202a66.37M\\u202c\\n\\u202a111.00M\\u202c\\n\\u202a99.64M\\u202c\\nPretax income\\nYoY growth\\n\\u202aâˆ’56.98M\\u202c\\n+91.09%\\n\\u202a850.46M\\u202c\\n+176.98%\\n\\u202a72.22M\\u202c\\n+101.81%\\n\\u202aâˆ’8.09M\\u202c\\n+99.31%\\n\\u202a383.11M\\u202c\\n+772.31%\\n\\u202a1.27B\\u202c\\n+49.32%\\n\\u202a344.00M\\u202c\\n+376.32%\\n\\u202a1.99B\\u202c\\nEquity in earnings\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\nâ€”\\nTaxes\\n\\u202aâˆ’11.23M\\u202c\\n\\u202aâˆ’16.57M\\u202c\\n\\u202aâˆ’17.72M\\u202c\\n\\u202aâˆ’10.71M\\u202c\\n\\u202aâˆ’4.27M\\u202c\\n\\u202aâˆ’55.61M\\u202c\\n\\u202aâˆ’25.00M\\u202c\\n\\u202aâˆ’95.59M\\u202c\\nNon-controlling/minority interest\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\nâ€”\\nAfter tax other income/expense\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\nâ€”\\nNet income before discontinued operations\\n\\u202aâˆ’68.22M\\u202c\\n\\u202a833.89M\\u202c\\n\\u202a54.50M\\u202c\\n\\u202aâˆ’18.79M\\u202c\\n\\u202a378.84M\\u202c\\n\\u202a1.21B\\u202c\\n\\u202a319.00M\\u202c\\n\\u202a1.89B\\u202c\\nDiscontinued operations\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\nâ€”\\nNet income\\nYoY growth\\n\\u202aâˆ’68.22M\\u202c\\n+88.15%\\n\\u202a833.89M\\u202c\\n+280.20%\\n\\u202a54.50M\\u202c\\n+101.40%\\n\\u202aâˆ’18.79M\\u202c\\n+98.40%\\n\\u202a378.84M\\u202c\\n+655.35%\\n\\u202a1.21B\\u202c\\n+45.62%\\n\\u202a319.00M\\u202c\\n+485.31%\\n\\u202a1.89B\\u202c\\nDilution adjustment\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\nâ€”\\nPreferred dividends\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\n\\u202a0.00\\u202c\\nâ€”\\nDiluted net income available to common stockholders\\n\\u202aâˆ’68.22M\\u202c\\n\\u202a833.89M\\u202c\\n\\u202a54.50M\\u202c\\n\\u202aâˆ’18.79M\\u202c\\n\\u202a378.84M\\u202c\\n\\u202a1.21B\\u202c\\n\\u202a319.00M\\u202c\\n\\u202a1.89B\\u202c\\nBasic earnings per share (Basic EPS)\\nYoY growth\\n\\u202aâˆ’0.11\\u202c\\n+88.53%\\n\\u202a1.34\\u202c\\n+262.53%\\n\\u202a0.09\\u202c\\n+101.33%\\n\\u202aâˆ’0.03\\u202c\\n+98.48%\\n\\u202a0.59\\u202c\\n+632.20%\\n\\u202a1.90\\u202c\\n+41.58%\\n\\u202a0.50\\u202c\\n+481.06%\\n\\u202a2.97\\u202c\\nDiluted earnings per share (Diluted EPS)\\nYoY growth\\n\\u202aâˆ’0.11\\u202c\\n+88.53%\\n\\u202a1.22\\u202c\\n+230.16%\\n\\u202a0.08\\u202c\\n+101.23%\\n\\u202aâˆ’0.03\\u202c\\n+98.48%\\n\\u202a0.55\\u202c\\n+597.04%\\n\\u202a1.79\\u202c\\n+46.01%\\n\\u202a0.47\\u202c\\n+493.38%\\n\\u202a2.78\\u202c\\nAverage basic shares outstanding\\n\\u202a611.74M\\u202c\\n\\u202a621.01M\\u202c\\n\\u202a629.48M\\u202c\\n\\u202a635.31M\\u202c\\n\\u202a638.41M\\u202c\\n\\u202a638.70M\\u202c\\n\\u202a634.00M\\u202c\\nâ€”\\nDiluted shares outstanding\\n\\u202a611.74M\\u202c\\n\\u202a681.92M\\u202c\\n\\u202a680.90M\\u202c\\n\\u202a635.31M\\u202c\\n\\u202a683.54M\\u202c\\n\\u202a680.06M\\u202c\\n\\u202a672.00M\\u202c\\nâ€”\\nEBITDA\\nYoY growth\\n\\u202aâˆ’15.18M\\u202c\\n+96.54%\\n\\u202a885.20M\\u202c\\n+87.90%\\n\\u202a107.98M\\u202c\\n+103.58%\\n\\u202a24.42M\\u202c\\n+108.23%\\n\\u202a483.57M\\u202c\\n+3285.58%\\n\\u202a1.22B\\u202c\\n+37.41%\\n\\u202a246.00M\\u202c\\n+127.82%\\n\\u202a1.97B\\u202c\\nEBIT\\nYoY growth\\n\\u202aâˆ’50.72M\\u202c\\n+89.19%\\n\\u202a851.51M\\u202c\\n+92.88%\\n\\u202a77.14M\\u202c\\n+102.53%\\n\\u202aâˆ’4.81M\\u202c\\n+98.56%\\n\\u202a457.57M\\u202c\\n+1002.21%\\n\\u202a1.20B\\u202c\\n+41.34%\\n\\u202a233.00M\\u202c\\n+202.06%\\n\\u202a1.89B\\u202c\\nTotal operating expenses\\n\\u202a1.39B\\u202c\\n\\u202a1.39B\\u202c\\n\\u202a1.46B\\u202c\\n\\u202a1.51B\\u202c\\n\\u202a1.65B\\u202c\\n\\u202a1.68B\\u202c\\n\\u202a1.67B\\u202c\\n\\u202a6.51B\\u202c\"]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "test = []\n",
    "test2 = []\n",
    "test3 = []\n",
    "count = 0\n",
    "revenue,YoYR = [],[]\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.tradingview.com/symbols/NASDAQ-ABNB/financials-income-statement/')\n",
    "header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]')\n",
    "\n",
    "for element in header:\n",
    "    test.append(element.text)\n",
    "#     revenue = []\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABNB',\n",
       " 'ADBE',\n",
       " 'ADI',\n",
       " 'ADSK',\n",
       " 'AEP',\n",
       " 'ALGN',\n",
       " 'AMAT',\n",
       " 'AMGN',\n",
       " 'ANSS',\n",
       " 'ATVI',\n",
       " 'AVGO',\n",
       " 'AZN',\n",
       " 'BIIB',\n",
       " 'BKNG',\n",
       " 'BKR',\n",
       " 'CEG',\n",
       " 'CHTR',\n",
       " 'COST',\n",
       " 'CPRT',\n",
       " 'CRWD',\n",
       " 'CSCO',\n",
       " 'CSGP',\n",
       " 'CSX',\n",
       " 'CTAS',\n",
       " 'CTSH',\n",
       " 'DLTR',\n",
       " 'DXCM',\n",
       " 'EA',\n",
       " 'EBAY',\n",
       " 'ENPH',\n",
       " 'EXC',\n",
       " 'FANG',\n",
       " 'FAST',\n",
       " 'FISV',\n",
       " 'FTNT',\n",
       " 'GOOG',\n",
       " 'GOOGL',\n",
       " 'HON',\n",
       " 'IDXX',\n",
       " 'ILMN',\n",
       " 'ISRG',\n",
       " 'JD',\n",
       " 'KHC',\n",
       " 'KLAC',\n",
       " 'LCID',\n",
       " 'LRCX',\n",
       " 'LULU',\n",
       " 'MAR',\n",
       " 'MCHP',\n",
       " 'MDLZ',\n",
       " 'MELI',\n",
       " 'MNST',\n",
       " 'MSFT',\n",
       " 'MU',\n",
       " 'ODFL',\n",
       " 'ORLY',\n",
       " 'PANW',\n",
       " 'PAYX',\n",
       " 'PCAR',\n",
       " 'PDD',\n",
       " 'PEP',\n",
       " 'QCOM',\n",
       " 'REGN',\n",
       " 'RIVN',\n",
       " 'ROST',\n",
       " 'SBUX',\n",
       " 'SGEN',\n",
       " 'SIRI',\n",
       " 'SNPS',\n",
       " 'TMUS',\n",
       " 'VRSK',\n",
       " 'VRTX',\n",
       " 'WDAY',\n",
       " 'XEL',\n",
       " 'ZM',\n",
       " 'ZS']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "query = \"SELECT Ticker FROM stock_info WHERE `Index` = 'NASDAQ100'\"\n",
    "ticker = pd.read_sql(query, conn)\n",
    "ticker = ticker['Ticker'].values.tolist()\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "test = []\n",
    "test2 = []\n",
    "test3 = []\n",
    "count = 0\n",
    "revenue,YoYR = [],[]\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "for t in ticker:\n",
    "    driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% t)\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-3):\n",
    "                if k%2 == 0:\n",
    "                    a = test2[k+2]\n",
    "                    revenue.append(a[1:-1])\n",
    "                else:\n",
    "                    YoYR.append(test2[k+2])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                revenue.append(a[1:-1])\n",
    "                YoYR.append(None)\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "        YoYR = []\n",
    "        revenue = []\n",
    "\n",
    "    a = range(len(Oth))\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':t,'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "            df = pd.DataFrame(data,index=[i])\n",
    "            df2 = pd.concat([df2,df],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "532"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_quarter',con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1d3d3cfcb20>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "sql = \"DROP TABLE stock_quarter\"\n",
    "cur.execute(sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "à¸‚à¸­à¸‡à¹„à¸—à¸¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "query = \"SELECT Ticker FROM stock_info WHERE `Index` = 'SET100'\"\n",
    "ticker = pd.read_sql(query, conn)\n",
    "ticker = ticker['Ticker'].values.tolist()\n",
    "for i in range(len(ticker)):\n",
    "    ticker[i] = ticker[i].replace(\".BK\",\"\")\n",
    "ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def download_quarter (ticker,save):\n",
    "    test = []\n",
    "    test2 = []\n",
    "    test3 = []\n",
    "    count = 0\n",
    "    revenue,YoYR = [],[]\n",
    "\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    con = sqlite3.connect(\"stock.sqlite\")\n",
    "    cur = con.cursor()\n",
    "\n",
    "    op = webdriver.ChromeOptions()\n",
    "    #op.add_argument('headless') \n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    thf2 = pd.DataFrame()\n",
    "    ticker = ticker.split('.')[0]\n",
    "    driver.get('https://www.tradingview.com/symbols/SET-%s/financials-income-statement/'% ticker)\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-3):\n",
    "                if k%2 == 0:\n",
    "                    a = test2[k+2]\n",
    "                    revenue.append(a[1:-1])\n",
    "                else:\n",
    "                    YoYR.append(test2[k+2])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                revenue.append(a[1:-1])\n",
    "                YoYR.append(None)\n",
    "\n",
    "        YoY[count] = (YoYR)\n",
    "        Oth[count] = (revenue)\n",
    "        count += 1\n",
    "        YoYR = []\n",
    "        revenue = []\n",
    "\n",
    "    a = range(len(Oth))\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':(ticker+'.BK'),'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Quarterly':year[i]}\n",
    "            thf = pd.DataFrame(data,index=[i])\n",
    "            thf2 = pd.concat([thf2,thf],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    if save == True:\n",
    "        thf2.to_sql('stock_quarter',con=conn,if_exists='append',index=False)\n",
    "    return thf2\n",
    "\n",
    "def update_quarter (ticker):\n",
    "    thf2 = download_quarter(ticker,False)\n",
    "    a = len(thf2)\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    count = 1\n",
    "    query = \"SELECT Quarterly FROM stock_quarter WHERE `Ticker` == '%s'\" % ('AAV.BK')\n",
    "    test = pd.read_sql(query, conn).values.tolist()[-1]\n",
    "    q = thf2['Quarterly']\n",
    "    for i in range(a):\n",
    "        if [list(thf2['Quarterly'].values)[i]] == test :\n",
    "            break\n",
    "        count += 1\n",
    "    data = thf2.iloc[count:,:]\n",
    "    # data.to_sql('stock_quarter',con=conn,if_exists='append',index=False)\n",
    "    return data\n",
    "\n",
    "\n",
    "# download_quarter('AAV.BK',False)\n",
    "# update_quarter('AAV.BK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Total revenue</th>\n",
       "      <th>YoY growth Total revenue</th>\n",
       "      <th>Cost of goods sold</th>\n",
       "      <th>Gross profit</th>\n",
       "      <th>YoY growth Gross profit</th>\n",
       "      <th>Operating expenses (excl. COGS)</th>\n",
       "      <th>Operating income</th>\n",
       "      <th>YoY growth Operating income</th>\n",
       "      <th>Non-operating income, total</th>\n",
       "      <th>...</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Diluted EPS YoY growth</th>\n",
       "      <th>Average basic shares outstanding</th>\n",
       "      <th>Diluted shares outstanding</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>YoY growth EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>YoY growth EBIT</th>\n",
       "      <th>Total operating expenses</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>40.18B</td>\n",
       "      <td>+8.27</td>\n",
       "      <td>âˆ’36.50B</td>\n",
       "      <td>1.73B</td>\n",
       "      <td>âˆ’50.92</td>\n",
       "      <td>âˆ’3.04B</td>\n",
       "      <td>âˆ’1.47B</td>\n",
       "      <td>âˆ’132.52</td>\n",
       "      <td>551.65M</td>\n",
       "      <td>...</td>\n",
       "      <td>âˆ’0.09</td>\n",
       "      <td>âˆ’95.27</td>\n",
       "      <td>5.10B</td>\n",
       "      <td>5.10B</td>\n",
       "      <td>244.27M</td>\n",
       "      <td>âˆ’69.70</td>\n",
       "      <td>âˆ’1.47B</td>\n",
       "      <td>âˆ’132.52</td>\n",
       "      <td>39.54B</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>13.63B</td>\n",
       "      <td>+3.28</td>\n",
       "      <td>âˆ’38.45B</td>\n",
       "      <td>âˆ’7.32B</td>\n",
       "      <td>âˆ’28.03</td>\n",
       "      <td>âˆ’3.20B</td>\n",
       "      <td>âˆ’8.70B</td>\n",
       "      <td>âˆ’131.81</td>\n",
       "      <td>606.92M</td>\n",
       "      <td>...</td>\n",
       "      <td>âˆ’0.93</td>\n",
       "      <td>âˆ’778.10</td>\n",
       "      <td>5.10B</td>\n",
       "      <td>5.10B</td>\n",
       "      <td>âˆ’2.35B</td>\n",
       "      <td>âˆ’76.32</td>\n",
       "      <td>âˆ’8.70B</td>\n",
       "      <td>âˆ’131.81</td>\n",
       "      <td>41.65B</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>3.83B</td>\n",
       "      <td>âˆ’66.07</td>\n",
       "      <td>âˆ’20.96B</td>\n",
       "      <td>âˆ’7.87B</td>\n",
       "      <td>âˆ’522.72</td>\n",
       "      <td>âˆ’1.38B</td>\n",
       "      <td>âˆ’8.83B</td>\n",
       "      <td>âˆ’490.91</td>\n",
       "      <td>âˆ’625.84M</td>\n",
       "      <td>...</td>\n",
       "      <td>âˆ’1.30</td>\n",
       "      <td>âˆ’905.49</td>\n",
       "      <td>5.10B</td>\n",
       "      <td>5.10B</td>\n",
       "      <td>âˆ’3.40B</td>\n",
       "      <td>âˆ’1060.45</td>\n",
       "      <td>âˆ’8.83B</td>\n",
       "      <td>âˆ’490.91</td>\n",
       "      <td>22.33B</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>17.55B</td>\n",
       "      <td>âˆ’71.92</td>\n",
       "      <td>âˆ’11.70B</td>\n",
       "      <td>âˆ’6.38B</td>\n",
       "      <td>âˆ’7.51</td>\n",
       "      <td>âˆ’961.20M</td>\n",
       "      <td>âˆ’7.71B</td>\n",
       "      <td>âˆ’1.51</td>\n",
       "      <td>âˆ’4.87B</td>\n",
       "      <td>...</td>\n",
       "      <td>âˆ’0.69</td>\n",
       "      <td>âˆ’39.01</td>\n",
       "      <td>5.12B</td>\n",
       "      <td>5.12B</td>\n",
       "      <td>âˆ’1.60B</td>\n",
       "      <td>âˆ’45.04</td>\n",
       "      <td>âˆ’7.71B</td>\n",
       "      <td>âˆ’1.51</td>\n",
       "      <td>12.66B</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>17.55B</td>\n",
       "      <td>+358.49</td>\n",
       "      <td>âˆ’23.93B</td>\n",
       "      <td>âˆ’5.98B</td>\n",
       "      <td>+18.93</td>\n",
       "      <td>âˆ’1.33B</td>\n",
       "      <td>âˆ’7.71B</td>\n",
       "      <td>+12.75</td>\n",
       "      <td>âˆ’2.96B</td>\n",
       "      <td>...</td>\n",
       "      <td>âˆ’0.69</td>\n",
       "      <td>+46.70</td>\n",
       "      <td>11.60B</td>\n",
       "      <td>11.60B</td>\n",
       "      <td>âˆ’1.60B</td>\n",
       "      <td>+52.88</td>\n",
       "      <td>âˆ’7.71B</td>\n",
       "      <td>+12.75</td>\n",
       "      <td>25.26B</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker Total revenue YoY growth Total revenue Cost of goods sold  \\\n",
       "0  AAV.BK        40.18B                    +8.27            âˆ’36.50B   \n",
       "1  AAV.BK        13.63B                    +3.28            âˆ’38.45B   \n",
       "2  AAV.BK         3.83B                   âˆ’66.07            âˆ’20.96B   \n",
       "3  AAV.BK        17.55B                   âˆ’71.92            âˆ’11.70B   \n",
       "4  AAV.BK        17.55B                  +358.49            âˆ’23.93B   \n",
       "\n",
       "  Gross profit YoY growth Gross profit Operating expenses (excl. COGS)  \\\n",
       "0        1.73B                  âˆ’50.92                          âˆ’3.04B   \n",
       "1       âˆ’7.32B                  âˆ’28.03                          âˆ’3.20B   \n",
       "2       âˆ’7.87B                 âˆ’522.72                          âˆ’1.38B   \n",
       "3       âˆ’6.38B                   âˆ’7.51                        âˆ’961.20M   \n",
       "4       âˆ’5.98B                  +18.93                          âˆ’1.33B   \n",
       "\n",
       "  Operating income YoY growth Operating income Non-operating income, total  \\\n",
       "0           âˆ’1.47B                     âˆ’132.52                     551.65M   \n",
       "1           âˆ’8.70B                     âˆ’131.81                     606.92M   \n",
       "2           âˆ’8.83B                     âˆ’490.91                    âˆ’625.84M   \n",
       "3           âˆ’7.71B                       âˆ’1.51                      âˆ’4.87B   \n",
       "4           âˆ’7.71B                      +12.75                      âˆ’2.96B   \n",
       "\n",
       "   ... Diluted EPS Diluted EPS YoY growth Average basic shares outstanding  \\\n",
       "0  ...       âˆ’0.09                 âˆ’95.27                            5.10B   \n",
       "1  ...       âˆ’0.93                âˆ’778.10                            5.10B   \n",
       "2  ...       âˆ’1.30                âˆ’905.49                            5.10B   \n",
       "3  ...       âˆ’0.69                 âˆ’39.01                            5.12B   \n",
       "4  ...       âˆ’0.69                 +46.70                           11.60B   \n",
       "\n",
       "  Diluted shares outstanding   EBITDA YoY growth EBITDA    EBIT  \\\n",
       "0                      5.10B  244.27M            âˆ’69.70  âˆ’1.47B   \n",
       "1                      5.10B   âˆ’2.35B            âˆ’76.32  âˆ’8.70B   \n",
       "2                      5.10B   âˆ’3.40B          âˆ’1060.45  âˆ’8.83B   \n",
       "3                      5.12B   âˆ’1.60B            âˆ’45.04  âˆ’7.71B   \n",
       "4                     11.60B   âˆ’1.60B            +52.88  âˆ’7.71B   \n",
       "\n",
       "  YoY growth EBIT Total operating expenses  Year  \n",
       "0         âˆ’132.52                   39.54B  2018  \n",
       "1         âˆ’131.81                   41.65B  2019  \n",
       "2         âˆ’490.91                   22.33B  2020  \n",
       "3           âˆ’1.51                   12.66B  2021  \n",
       "4          +12.75                   25.26B  2022  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def download_year (ticker,save):\n",
    "    test = []\n",
    "    test2 = []\n",
    "    test3 = []\n",
    "    count = 0\n",
    "    revenue,YoYR = [],[]\n",
    "\n",
    "    # Create a SQL connection to our SQLite database\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "\n",
    "    op = webdriver.ChromeOptions()\n",
    "    #op.add_argument('headless') \n",
    "    driver = webdriver.Chrome(options=op)\n",
    "    thf2 = pd.DataFrame()\n",
    "    query_index = \"SELECT `Index` FROM stock_info WHERE `Ticker` = '%s'\" % ticker\n",
    "    check_index = pd.read_sql(query_index, conn).values.tolist()[0][0]\n",
    "    ticker = ticker.split('.')[0]\n",
    "    if check_index == 'SET100':\n",
    "        driver.get('https://www.tradingview.com/symbols/SET-%s/financials-income-statement/'% ticker)\n",
    "    else:\n",
    "        driver.get('https://www.tradingview.com/symbols/NASDAQ-%s/financials-income-statement/'% ticker)\n",
    "    year = driver.find_element(\"xpath\",'//*[@id=\"FY\"]')\n",
    "    year.click()\n",
    "    header = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[1]')\n",
    "    raw1 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[2]')\n",
    "    raw2 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[3]')\n",
    "    raw3 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[4]')\n",
    "    raw4 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[5]')\n",
    "    raw5 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[6]')\n",
    "    raw6 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[7]')\n",
    "    raw7 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[8]')\n",
    "    raw8 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[9]')\n",
    "    raw9 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[10]')\n",
    "    raw10 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[11]')\n",
    "    raw11 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[12]')\n",
    "    raw12 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[13]')\n",
    "    raw13 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[14]')\n",
    "    raw14 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[15]')\n",
    "    raw15 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[16]')\n",
    "    raw16 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[17]')\n",
    "    raw17 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[18]')\n",
    "    raw18 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[19]')\n",
    "    raw19 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[20]')\n",
    "    raw20 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[21]')\n",
    "    raw21 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[22]')\n",
    "    raw22 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[23]')\n",
    "    raw23 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[24]')\n",
    "    raw24 = driver.find_elements(By.XPATH, '//*[@id=\"js-category-content\"]/div/div[2]/div[2]/div/div/div[5]/div[2]/div/div[1]/div[25]')\n",
    "    time.sleep(4)\n",
    "    Allelement = [raw1,raw2,raw3,raw4,raw5,raw6,raw7,raw8,raw9,raw10,\n",
    "                raw11,raw12,raw13,raw14,raw15,raw16,raw17,raw18,raw19,raw20,\n",
    "                raw21,raw22,raw23,raw24]\n",
    "\n",
    "    YoY = [''] * len(Allelement)\n",
    "    Oth = [''] * len(Allelement)\n",
    "    for element in header:\n",
    "        test.append(element.text)\n",
    "    year = test[0].split('\\n')[1:-1]\n",
    "    for e in Allelement:\n",
    "        revenue = []\n",
    "        YoYR = []\n",
    "        test2 = []\n",
    "        for h in e:\n",
    "            test2.append(h.text)\n",
    "        test2 = test2[0].split('\\n')\n",
    "        if (e == raw1) or (e == raw3) or (e == raw5) or (e == raw7) or (e == raw14) or (e == raw18) or (e == raw19) or (e == raw22) or (e == raw23):\n",
    "            for k in range(len(test2)-2):\n",
    "                if k%2 == 0:\n",
    "                    a = test2[k+2]\n",
    "                    revenue.append(a[:-1])\n",
    "                else:\n",
    "                    YoYR.append(test2[k+2][1:-1])\n",
    "        else:\n",
    "            for k in range(len(test2)-2):\n",
    "                a = test2[k+1]\n",
    "                revenue.append(None)\n",
    "                YoYR.append(a[1:-1])\n",
    "\n",
    "        YoY[count] = (revenue)\n",
    "        Oth[count] = (YoYR)\n",
    "        count += 1\n",
    "    a = range(len(Oth))\n",
    "    year = year[2:]\n",
    "    for i in range(len(year)):\n",
    "        try:\n",
    "            data = {'Ticker':(ticker+'.BK'),'Total revenue':Oth[0][i],'YoY growth Total revenue':YoY[0][i],\n",
    "                'Cost of goods sold':Oth[1][i],\n",
    "                'Gross profit':Oth[2][i],'YoY growth Gross profit':YoY[2][i],\n",
    "                'Operating expenses (excl. COGS)':Oth[3][i],\n",
    "                'Operating income':Oth[4][i],'YoY growth Operating income' : YoY[4][i],\n",
    "                'Non-operating income, total':Oth[5][i],\n",
    "                'Pretax income':Oth[6][i],'YoY growth Pretax income':YoY[6][i],\n",
    "                'Equity in earnings':Oth[7][i],'Taxes':Oth[8][i],\n",
    "                'Non-controlling/minority interest':Oth[9][i],'After tax other income/expense':Oth[10][i],\n",
    "                'Net income before discontinued operations':Oth[11][i],'Discontinued operations':Oth[12][i],\n",
    "                'Net income':Oth[13][i],'YoY growth Net income':YoY[13][i],\n",
    "                'Dilution adjustment':Oth[14][i],'Preferred dividends':Oth[15][i],'Diluted net income available to common stockholders':Oth[16][i],\n",
    "                'Basic EPS':Oth[17][i],'YoY growth Basic EPS':YoY[17][i],'Diluted EPS':Oth[18][i],'Diluted EPS YoY growth':YoY[18][i],\n",
    "                'Average basic shares outstanding':Oth[19][i],'Diluted shares outstanding':Oth[20][i],\n",
    "                'EBITDA':Oth[21][i],'YoY growth EBITDA':YoY[21][i],'EBIT':Oth[22][i],'YoY growth EBIT': YoY[22][i],\n",
    "                'Total operating expenses':Oth[23][i],'Year':year[i]}\n",
    "            thf = pd.DataFrame(data,index=[i])\n",
    "            thf2 = pd.concat([thf2,thf],ignore_index=True)\n",
    "        except:\n",
    "            print(i)\n",
    "            print('error here')\n",
    "    count = 0\n",
    "    year = []\n",
    "    if save == True:\n",
    "        thf2.to_sql('stock_quarter',con=conn,if_exists='append',index=False)\n",
    "    return thf2\n",
    "\n",
    "download_year('AAV.BK',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"ALTER TABLE stock_quarter DROP COLUMN [index]\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '']\n",
      "['', '']\n",
      "\n",
      "['']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "head = []\n",
    "data_l = []\n",
    "TTM= ''\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "ticker = 'AAV.BK'\n",
    "driver.get(\"https://finance.yahoo.com/quote/AAV.BK/financials?p='%s'\" % ticker)\n",
    "time.sleep(5)\n",
    "header = driver.find_elements(By.XPATH, '//*[@id=\"Col1-1-Financials-Proxy\"]/section/div[3]/div[1]/div/div[1]/div')\n",
    "data = driver.find_elements(By.XPATH, '//*[@id=\"Col1-1-Financials-Proxy\"]/section/div[3]/div[1]/div')\n",
    "\n",
    "time.sleep(5)\n",
    "while data_l == [] or data_l == ['']:\n",
    "    for element in data:\n",
    "        data_l.append(element.text)\n",
    "    time.sleep(1)\n",
    "print(data_l)\n",
    "try:\n",
    "    TTM = data_l[0].split('\\n')[1][:3]\n",
    "except:\n",
    "    pass\n",
    "print(data_l)\n",
    "print(TTM)\n",
    "# for i in data_l[0].split('\\n')[1]:\n",
    "#     head.append()\n",
    "# df = pd.DataFrame({'year':[data_l[0].split('\\n')]})\n",
    "print(data_l[0].split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Breakdown\\nTTM12/30/202212/30/202112/30/202012/30/2019\\nTotal Revenue\\n17,553,287 17,553,287 3,828,468 13,633,868 40,180,651\\nCost of Revenue\\n23,533,471 23,533,471 11,223,276 20,484,163 38,358,527\\nGross Profit\\n-5,980,184 -5,980,184 -7,394,807 -6,850,295 1,822,124\\nOperating Expense\\n1,726,321 1,726,321 1,437,711 1,850,767 3,294,605\\nOperating Income\\n-7,706,505 -7,706,505 -8,832,518 -8,701,062 -1,472,481\\nNet Non Operating Interest Income Expense\\n-2,190,313 -2,190,313 -1,848,417 -1,776,163 -765,529\\nOther Income Expense\\n-769,104 -769,104 -3,018,080 1,150,318 1,372,448\\nPretax Income\\n-10,665,922 -10,665,922 -13,699,015 -9,326,907 -865,562\\nTax Provision\\n-2,451,560 -2,451,560 -1,741,067 -659,978 599.706\\nNet Income Common Stockholders\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nDiluted NI Available to Com Stockholders\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nBasic EPS\\n- - -1.30 -0.94 -0.09\\nDiluted EPS\\n- - -1.30 -0.94 -0.09\\nBasic Average Shares\\n- - 5,119,513 5,085,317 5,085,317\\nDiluted Average Shares\\n- - 5,179,943 5,085,317 5,085,317\\nTotal Operating Income as Reported\\n-8,475,609 -8,475,609 -11,850,598 -7,550,743 -\\nTotal Expenses\\n25,259,792 25,259,792 12,660,986 22,334,930 41,653,132\\nNet Income from Continuing & Discontinued Operation\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nNormalized Income\\n-7,195,415 -7,195,415 -3,761,087 -5,158,316 -754,377\\nInterest Income\\n29,186 29,186 50,397 23,619 -\\nInterest Expense\\n2,113,770 2,113,770 1,786,662 1,603,008 765,529\\nNet Interest Income\\n-2,190,313 -2,190,313 -1,848,417 -1,776,163 -765,529\\nEBIT\\n-8,552,152 -8,552,152 -11,912,353 -7,723,899 -100,032\\nEBITDA\\n-2,438,099 - - - -\\nReconciled Cost of Revenue\\n23,533,471 23,533,471 11,223,276 20,484,163 38,358,527\\nReconciled Depreciation\\n6,114,053 6,114,053 5,434,314 5,738,993 1,716,746\\nNet Income from Continuing Operation Net Minority Interest\\n-8,029,997 -8,029,997 -6,647,486 -4,764,092 -473,999\\nTotal Unusual Items Excluding Goodwill\\n-1,083,661 -1,083,661 -3,306,655 424,243 350,472\\nTotal Unusual Items\\n-1,083,661 -1,083,661 -3,306,655 424,243 350,472\\nNormalized EBITDA\\n-1,354,438 -1,354,438 -3,171,384 -2,409,150 1,266,241\\nTax Rate for Calcs\\n0 0 0 0 0\\nTax Effect of Unusual Items\\n-249,079 -249,079 -420,257 30,020 70,094'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Total revenue</th>\n",
       "      <th>YoY growth Total revenue</th>\n",
       "      <th>Cost of goods sold</th>\n",
       "      <th>Gross profit</th>\n",
       "      <th>YoY growth Gross profit</th>\n",
       "      <th>Operating expenses (excl. COGS)</th>\n",
       "      <th>Operating income</th>\n",
       "      <th>YoY growth Operating income</th>\n",
       "      <th>Non-operating income, total</th>\n",
       "      <th>...</th>\n",
       "      <th>Diluted EPS</th>\n",
       "      <th>Diluted EPS YoY growth</th>\n",
       "      <th>Average basic shares outstanding</th>\n",
       "      <th>Diluted shares outstanding</th>\n",
       "      <th>EBITDA</th>\n",
       "      <th>YoY growth EBITDA</th>\n",
       "      <th>EBIT</th>\n",
       "      <th>YoY growth EBIT</th>\n",
       "      <th>Total operating expenses</th>\n",
       "      <th>Quarterly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AAV.BK</td>\n",
       "      <td>8.26B</td>\n",
       "      <td>+440.51%</td>\n",
       "      <td>âˆ’7.59B</td>\n",
       "      <td>671.99M</td>\n",
       "      <td>+129.60%</td>\n",
       "      <td>âˆ’538.07M</td>\n",
       "      <td>133.92M</td>\n",
       "      <td>+104.93%</td>\n",
       "      <td>3.67B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27</td>\n",
       "      <td>+306.64%</td>\n",
       "      <td>11.36B</td>\n",
       "      <td>11.36B</td>\n",
       "      <td>1.52B</td>\n",
       "      <td>+282.52%</td>\n",
       "      <td>133.92M</td>\n",
       "      <td>+104.93%</td>\n",
       "      <td>8.13B</td>\n",
       "      <td>Q4 '22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ticker Total revenue YoY growth Total revenue Cost of goods sold  \\\n",
       "6  AAV.BK         8.26B                 +440.51%             âˆ’7.59B   \n",
       "\n",
       "  Gross profit YoY growth Gross profit Operating expenses (excl. COGS)  \\\n",
       "6      671.99M                +129.60%                        âˆ’538.07M   \n",
       "\n",
       "  Operating income YoY growth Operating income Non-operating income, total  \\\n",
       "6          133.92M                    +104.93%                       3.67B   \n",
       "\n",
       "   ... Diluted EPS Diluted EPS YoY growth Average basic shares outstanding  \\\n",
       "6  ...        0.27               +306.64%                           11.36B   \n",
       "\n",
       "  Diluted shares outstanding EBITDA YoY growth EBITDA     EBIT  \\\n",
       "6                     11.36B  1.52B          +282.52%  133.92M   \n",
       "\n",
       "  YoY growth EBIT Total operating expenses Quarterly  \n",
       "6        +104.93%                    8.13B    Q4 '22  \n",
       "\n",
       "[1 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = len(thf2)\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "count = 1\n",
    "query = \"SELECT Quarterly FROM stock_quarter WHERE `Ticker` == '%s'\" % ('AAV.BK')\n",
    "test = pd.read_sql(query, conn).values.tolist()[-1]\n",
    "q = thf2['Quarterly']\n",
    "for i in range(a):\n",
    "    if [list(thf2['Quarterly'].values)[i]] == test :\n",
    "        break\n",
    "    count += 1\n",
    "data = thf2.iloc[count:,:]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "thf2.to_sql('stock_quarter',con=con,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_quarter',con=con,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Technology', 'Consumer Electronics']\n",
      "  Ticker Industry Group                Sector      Index\n",
      "0   AAPL     Technology  Consumer Electronics  NASDAQ100\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_link = []\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "InsSec = []\n",
    "driver.get(\"https://finance.yahoo.com/quote/AAPL/profile?p=AAPL\")\n",
    "numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "for i in numlink[:2]:\n",
    "    InsSec.append(i.text)\n",
    "print(InsSec)\n",
    "df1 = pd.DataFrame({'Ticker': [j], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_info',con=con,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-02-13</th>\n",
       "      <td>16.678928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-14</th>\n",
       "      <td>16.663929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-15</th>\n",
       "      <td>16.434286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-19</th>\n",
       "      <td>16.428213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-02-20</th>\n",
       "      <td>16.030357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-23</th>\n",
       "      <td>131.860001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>130.029999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>126.040001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>129.610001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>129.929993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2489 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AAPL\n",
       "Date                  \n",
       "2013-02-13   16.678928\n",
       "2013-02-14   16.663929\n",
       "2013-02-15   16.434286\n",
       "2013-02-19   16.428213\n",
       "2013-02-20   16.030357\n",
       "...                ...\n",
       "2022-12-23  131.860001\n",
       "2022-12-27  130.029999\n",
       "2022-12-28  126.040001\n",
       "2022-12-29  129.610001\n",
       "2022-12-30  129.929993\n",
       "\n",
       "[2489 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "query = \"select * from stock_table_d where `ticker` == 'AAPL' and datetime > '2012-01-01' and datetime < '2023-01-01'\"\n",
    "df = pd.read_sql(query,conn)\n",
    "df['Date'] = pd.to_datetime(df['Datetime'])\n",
    "df.set_index(df['Date'],inplace = True)\n",
    "\n",
    "data = df.filter(['Close'])\n",
    "data.rename(columns={'Close':'AAPL'}, inplace=True)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABNB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ADI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AEP\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ATVI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BIIB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BKR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "CSX\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DXCM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EBAY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ENPH\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EXC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FISV\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GOOGL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "HON\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ILMN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KHC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "KLAC\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LCID\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LULU\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MAR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MNST\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MSFT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PANW\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PCAR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PDD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PEP\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "REGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RIVN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SIRI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "VRTX\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "XEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ZS\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "miss = ['ABNB', 'ADI', 'AEP', 'AMGN', 'ATVI', 'BIIB', 'BKR', 'CSX', 'DXCM', 'EBAY', 'ENPH', 'EXC', 'FISV', 'GOOGL', 'HON', 'ILMN', 'JD', 'KHC', 'KLAC', 'LCID', 'LULU', 'MAR', 'MNST', 'MSFT', 'PANW', 'PCAR', 'PDD', 'PEP', 'REGN', 'RIVN', 'SIRI', 'VRTX', 'XEL', 'ZS']\n",
    "miss2 = ['ADI', 'AEP', 'BKR', 'CSGP', 'CSX', 'EXC', 'HON', 'KHC', 'KLAC']\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "again = []\n",
    "for i in miss:\n",
    "    print(i)\n",
    "    try:\n",
    "        datamo = yf.download(tickers=i,period='5y',interval=\"1mo\",progress=True)\n",
    "        datamo.index.names = ['Datetime']\n",
    "        datamo['Ticker'] = i\n",
    "        datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)\n",
    "    except:\n",
    "        again.append(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABNB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ATVI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BIIB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DXCM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EBAY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ENPH\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FISV\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GOOGL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ILMN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LCID\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LULU\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MAR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MNST\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MSFT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PANW\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PCAR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PDD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PEP\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "REGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RIVN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SIRI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "VRTX\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ZS\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "miss = ['ABNB', 'AMGN', 'ATVI', 'BIIB', 'DXCM', 'EBAY', 'ENPH', 'FISV', 'GOOGL', 'ILMN', 'JD', 'LCID', 'LULU', 'MAR', 'MNST', 'MSFT', 'PANW', 'PCAR', 'PDD', 'PEP', 'REGN', 'RIVN', 'SIRI', 'VRTX', 'ZS']\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "again = []\n",
    "for i in miss:\n",
    "    print(i)\n",
    "    try:\n",
    "        datad = yf.download(tickers=i,period='max',interval=\"1d\",progress=True)\n",
    "        datad.index.names = ['Datetime']\n",
    "        datad['Ticker'] = i\n",
    "        datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    except:\n",
    "        again.append(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABNB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "AMGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ATVI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "BIIB\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "DXCM\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "EBAY\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ENPH\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FISV\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "GOOGL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ILMN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "JD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LCID\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "LULU\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MAR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MNST\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "MSFT\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PANW\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PCAR\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PDD\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "PEP\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "REGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "RIVN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "SIRI\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "VRTX\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "ZS\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "miss = ['ABNB', 'AMGN', 'ATVI', 'BIIB', 'DXCM', 'EBAY', 'ENPH', 'FISV', 'GOOGL', 'ILMN', 'JD', 'LCID', 'LULU', 'MAR', 'MNST', 'MSFT', 'PANW', 'PCAR', 'PDD', 'PEP', 'REGN', 'RIVN', 'SIRI', 'VRTX', 'ZS']\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "again = []\n",
    "for i in miss:\n",
    "    print(i)\n",
    "    try:\n",
    "        datahr = yf.download(tickers=i,period='2y',interval=\"1h\",progress=True)\n",
    "        datahr.index.names = ['Datetime']\n",
    "        datahr['Ticker'] = i\n",
    "        datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    except:\n",
    "        again.append(i)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "def getLastDate(period,ticker):\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    cur = conn.cursor()\n",
    "    # Query last element of stock in database\n",
    "    if period == 'Hour':\n",
    "        query = \"SELECT * FROM stock_table_hr WHERE `ticker` = '%s'\" % ticker\n",
    "    elif period == 'Day':\n",
    "        query = \"SELECT * FROM stock_table_d WHERE `ticker` = '%s'\" % ticker\n",
    "    elif period == 'Month':\n",
    "        query = \"SELECT * FROM stock_table_mo WHERE `ticker` = '%s'\" % ticker\n",
    "    else:\n",
    "        return False\n",
    "    r_df = pd.read_sql(query, conn)\n",
    "    # Cut data to get only datatime\n",
    "    last = r_df.tail(1).Datetime.to_string().split()\n",
    "    LastDate = last[1].split()[0].split('-')\n",
    "    cur.close()\n",
    "    return LastDate,r_df\n",
    "\n",
    "def getDiffDay(period,ticker):\n",
    "    LastDate,r_df = getLastDate(period,ticker)\n",
    "    if LastDate == False:\n",
    "        return False\n",
    "    # Get datetime for now\n",
    "    x = datetime.datetime.now()\n",
    "    count = 0\n",
    "    DayM = 0\n",
    "    DayMo365 = {'1':31,'2':28,'3':31,'4':30,'5':31,'6':30,'7':31,'8':31,'9':30,'10':31,'11':30,'12':31}\n",
    "    DiffMo = int(x.month) - int(LastDate[1])\n",
    "    DiffYe = int(x.year) - int(LastDate[0])\n",
    "    # Get differend day for dowload stock\n",
    "    if DiffYe == 0:\n",
    "        if DiffMo == 0:\n",
    "            DiffDay = int(x.day) - int(LastDate[2])\n",
    "            if DiffDay != 0:pass\n",
    "        elif DiffMo != 0 :\n",
    "            for u in range(DiffMo):\n",
    "                DayM = DayM + DayMo365[str(int(LastDate[1])+count)]\n",
    "                count += 1\n",
    "            DiffDay = DayM - int(LastDate[2]) + int(x.day)\n",
    "    elif DiffYe != 0:\n",
    "        dayly = 0\n",
    "        dayn = 0\n",
    "        for j in range(1,int(LastDate[1])):\n",
    "            dayly = dayly + DayMo365[str(j)]\n",
    "        for i in range(1,int(x.month)):\n",
    "            dayn = dayn + DayMo365[str(i)]\n",
    "        DiffDay = (365*DiffYe) - dayly + dayn - int(LastDate[2]) + int(x.day)   \n",
    "    return DiffDay\n",
    "    \n",
    "def update(period,ticker):\n",
    "    LastDate,r_df = getLastDate(period,ticker)\n",
    "    DiffDay = getDiffDay(period,ticker)\n",
    "    if DiffDay == False:\n",
    "        return False\n",
    "    down = 0\n",
    "    count = 0\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    query = \"SELECT `Index` FROM stock_info WHERE `ticker` = '%s'\" % ticker\n",
    "    for_ind = pd.read_sql(query, conn)\n",
    "    ok = r_df.tail(1).Datetime.to_string().split()[2]\n",
    "    #for get extra time in database\n",
    "    if for_ind['Index'].values == 'NASDAQ100':\n",
    "        DiffDay = str(DiffDay)+'d'\n",
    "        if ok == '09:30:00':down = 6\n",
    "        elif ok == '10:30:00':down = 5\n",
    "        elif ok == '11:30:00':down = 4\n",
    "        elif ok == '12:30:00':down = 3\n",
    "        elif ok == '13:30:00':down = 2\n",
    "        elif ok == '14:30:00':down = 1\n",
    "        elif ok == '15:30:00':down = 0\n",
    "    elif for_ind['Index'].values == 'SET100':\n",
    "        DiffDay = str(DiffDay)+'d'\n",
    "        if ok == '10:00:00':down = 5\n",
    "        elif ok == '11:00:00':down = 4\n",
    "        elif ok == '12:00:00':down = 3\n",
    "        elif ok == '14:00:00':down = 2\n",
    "        elif ok == '15:00:00':down = 1\n",
    "        elif ok == '16:00:00':down = 0\n",
    "    elif for_ind['Index'].values == 'CRYPTO100':\n",
    "        DiffDay = str(DiffDay+1)+'d'\n",
    "        if ok == '00:00:00':down = 23\n",
    "        elif ok == '01:00:00':down = 22\n",
    "        elif ok == '02:00:00':down = 21\n",
    "        elif ok == '03:00:00':down = 20\n",
    "        elif ok == '04:00:00':down = 19\n",
    "        elif ok == '05:00:00':down = 18\n",
    "        elif ok == '06:00:00':down = 17\n",
    "        elif ok == '07:00:00':down = 16\n",
    "        elif ok == '08:00:00':down = 15\n",
    "        elif ok == '09:00:00':down = 14\n",
    "        elif ok == '10:00:00':down = 13\n",
    "        elif ok == '11:00:00':down = 12\n",
    "        elif ok == '12:00:00':down = 11\n",
    "        elif ok == '13:00:00':down = 10\n",
    "        elif ok == '14:00:00':down = 9\n",
    "        elif ok == '15:00:00':down = 8\n",
    "        elif ok == '16:00:00':down = 7\n",
    "        elif ok == '17:00:00':down = 6\n",
    "        elif ok == '18:00:00':down = 5\n",
    "        elif ok == '19:00:00':down = 4\n",
    "        elif ok == '20:00:00':down = 3\n",
    "        elif ok == '21:00:00':down = 2\n",
    "        elif ok == '22:00:00':down = 1\n",
    "        elif ok == '23:00:00':down = 0\n",
    "    # Select period to download\n",
    "    if period == 'Hour':data = yf.download(tickers=ticker, period=DiffDay, interval='1h',progress=False)\n",
    "    elif period == 'Day':data = yf.download(tickers=ticker, period=DiffDay, interval='1d',progress=False)\n",
    "    elif period == 'Month':data = yf.download(tickers=ticker, period=DiffDay, interval='1mo',progress=False)\n",
    "    # Get number of extra stock\n",
    "    for i in data.index.day:\n",
    "        if data.index.year[count] == int(LastDate[0]):\n",
    "            if data.index.month[count] == int(LastDate[1]):\n",
    "                if period == 'Month':\n",
    "                    if i == int(LastDate[2])+1 or i == int(LastDate[2])+2 or i == int(LastDate[2])+3 or i == int(LastDate[2]):\n",
    "                        break\n",
    "                else:\n",
    "                    if i == int(LastDate[2])+1 or i == int(LastDate[2])+2 or i == int(LastDate[2])+3:\n",
    "                        break\n",
    "        count += 1\n",
    "    # Cut extra stock off\n",
    "    count = count - down\n",
    "    data['ticker'] = ticker\n",
    "    data.index.names = ['Datetime']\n",
    "    data = data.iloc[count:,:]\n",
    "    # Select period to download and Save to sqlite\n",
    "    if period == 'Hour':data.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    elif period == 'Day':data.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    elif period == 'Month':data.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)\n",
    "    return data\n",
    "\n",
    "def getAllticker():\n",
    "    conn = sqlite3.connect(\"stock.sqlite\")\n",
    "    cur = conn.cursor()\n",
    "    query = \"select Ticker from stock_info\"\n",
    "    r_df = pd.read_sql(query,conn)\n",
    "    list_db = r_df['Ticker'].values.tolist()\n",
    "    return list_db\n",
    "    \n",
    "def updateAll():\n",
    "    period = ['Hour','Day','Month']\n",
    "    Ticker = getAllticker()\n",
    "    miss = []\n",
    "    for  i in Ticker:\n",
    "        try:\n",
    "            for j in period:\n",
    "                update(j,i)\n",
    "        except:\n",
    "            miss.append(i)\n",
    "            pass\n",
    "    print(miss)\n",
    "updateAll()\n",
    "# getAllticker()\n",
    "# print(getDiffDay('Month','ACE.BK'))\n",
    "# update('Hour','BTC-USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-27 10:00:00</th>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27 11:00:00</th>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>614877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27 12:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>647942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27 14:00:00</th>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>2254827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27 15:00:00</th>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>1331363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27 16:00:00</th>\n",
       "      <td>32.50</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>10936148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 10:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 11:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>1891005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 12:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1128379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 14:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>24545046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 15:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>11966341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-28 16:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>1258242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 10:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 11:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>695090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 12:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>421125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 14:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>1118220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 15:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>12376017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-01 16:00:00</th>\n",
       "      <td>32.25</td>\n",
       "      <td>32.25</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1118067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 10:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 11:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1030288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 12:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>484909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 14:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>14368367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 15:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>9946234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-02 16:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>775751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 10:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 11:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>1068065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 12:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>471585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 14:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>2539068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 15:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>2249950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-03 16:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1934995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 10:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.50</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 11:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1967480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 12:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>865405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 14:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>2109125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 15:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>9057907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-07 16:00:00</th>\n",
       "      <td>32.00</td>\n",
       "      <td>32.25</td>\n",
       "      <td>31.75</td>\n",
       "      <td>32.00</td>\n",
       "      <td>32.00</td>\n",
       "      <td>4760031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 10:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 11:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>1344946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 12:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>247755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 14:00:00</th>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.75</td>\n",
       "      <td>776278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 15:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>8634849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-08 16:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.75</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>1906922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 10:00:00</th>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>6461644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 11:00:00</th>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.50</td>\n",
       "      <td>8806956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 12:00:00</th>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>427256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 14:00:00</th>\n",
       "      <td>31.25</td>\n",
       "      <td>31.50</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>11293468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 15:00:00</th>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>1875025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-09 16:00:00</th>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.25</td>\n",
       "      <td>31.25</td>\n",
       "      <td>3481345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 10:00:00</th>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 11:00:00</th>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>1811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 12:00:00</th>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>486808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 14:00:00</th>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>1689162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 15:00:00</th>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.50</td>\n",
       "      <td>1536527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-10 16:00:00</th>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>3150765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-13 10:00:00</th>\n",
       "      <td>30.50</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.25</td>\n",
       "      <td>30.75</td>\n",
       "      <td>30.75</td>\n",
       "      <td>7464223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-13 11:00:00</th>\n",
       "      <td>30.75</td>\n",
       "      <td>31.00</td>\n",
       "      <td>30.50</td>\n",
       "      <td>31.00</td>\n",
       "      <td>31.00</td>\n",
       "      <td>6826408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Open   High    Low  Close  Adj Close    Volume\n",
       "Datetime                                                            \n",
       "2023-02-27 10:00:00  32.50  32.50  32.00  32.25      32.25         0\n",
       "2023-02-27 11:00:00  32.50  32.50  32.25  32.25      32.25    614877\n",
       "2023-02-27 12:00:00  32.25  32.50  32.25  32.50      32.50    647942\n",
       "2023-02-27 14:00:00  32.50  32.50  32.25  32.50      32.50   2254827\n",
       "2023-02-27 15:00:00  32.50  32.50  32.25  32.50      32.50   1331363\n",
       "2023-02-27 16:00:00  32.50  32.50  32.00  32.25      32.25  10936148\n",
       "2023-02-28 10:00:00  32.25  32.50  32.00  32.25      32.25         0\n",
       "2023-02-28 11:00:00  32.25  32.25  32.00  32.25      32.25   1891005\n",
       "2023-02-28 12:00:00  32.25  32.25  32.00  32.00      32.00   1128379\n",
       "2023-02-28 14:00:00  32.00  32.25  31.75  32.00      32.00  24545046\n",
       "2023-02-28 15:00:00  32.00  32.00  31.75  32.00      32.00  11966341\n",
       "2023-02-28 16:00:00  32.00  32.00  31.75  31.75      31.75   1258242\n",
       "2023-03-01 10:00:00  32.25  32.25  32.00  32.25      32.25         0\n",
       "2023-03-01 11:00:00  32.25  32.25  32.00  32.00      32.00    695090\n",
       "2023-03-01 12:00:00  32.00  32.25  32.00  32.00      32.00    421125\n",
       "2023-03-01 14:00:00  32.00  32.25  32.00  32.25      32.25   1118220\n",
       "2023-03-01 15:00:00  32.25  32.50  32.00  32.25      32.25  12376017\n",
       "2023-03-01 16:00:00  32.25  32.25  32.00  32.00      32.00   1118067\n",
       "2023-03-02 10:00:00  31.50  31.75  31.25  31.50      31.50         0\n",
       "2023-03-02 11:00:00  31.50  31.75  31.50  31.50      31.50   1030288\n",
       "2023-03-02 12:00:00  31.50  31.75  31.50  31.50      31.50    484909\n",
       "2023-03-02 14:00:00  31.50  31.75  31.25  31.50      31.50  14368367\n",
       "2023-03-02 15:00:00  31.50  31.75  31.25  31.50      31.50   9946234\n",
       "2023-03-02 16:00:00  31.50  31.75  31.50  31.75      31.75    775751\n",
       "2023-03-03 10:00:00  31.50  31.75  31.50  31.50      31.50         0\n",
       "2023-03-03 11:00:00  31.75  31.75  31.50  31.75      31.75   1068065\n",
       "2023-03-03 12:00:00  31.75  31.75  31.50  31.50      31.50    471585\n",
       "2023-03-03 14:00:00  31.50  31.75  31.50  31.50      31.50   2539068\n",
       "2023-03-03 15:00:00  31.50  31.75  31.50  31.50      31.50   2249950\n",
       "2023-03-03 16:00:00  31.75  31.75  31.50  31.50      31.50   1934995\n",
       "2023-03-07 10:00:00  31.75  32.00  31.50  32.00      32.00         0\n",
       "2023-03-07 11:00:00  32.00  32.00  31.75  32.00      32.00   1967480\n",
       "2023-03-07 12:00:00  32.00  32.00  31.75  32.00      32.00    865405\n",
       "2023-03-07 14:00:00  32.00  32.00  31.75  31.75      31.75   2109125\n",
       "2023-03-07 15:00:00  32.00  32.25  31.75  32.00      32.00   9057907\n",
       "2023-03-07 16:00:00  32.00  32.25  31.75  32.00      32.00   4760031\n",
       "2023-03-08 10:00:00  31.50  31.75  31.50  31.50      31.50         0\n",
       "2023-03-08 11:00:00  31.75  31.75  31.50  31.75      31.75   1344946\n",
       "2023-03-08 12:00:00  31.75  31.75  31.50  31.75      31.75    247755\n",
       "2023-03-08 14:00:00  31.75  31.75  31.50  31.75      31.75    776278\n",
       "2023-03-08 15:00:00  31.50  31.75  31.50  31.50      31.50   8634849\n",
       "2023-03-08 16:00:00  31.50  31.75  31.50  31.50      31.50   1906922\n",
       "2023-03-09 10:00:00  31.50  31.50  31.00  31.25      31.25   6461644\n",
       "2023-03-09 11:00:00  31.25  31.50  31.25  31.50      31.50   8806956\n",
       "2023-03-09 12:00:00  31.25  31.50  31.25  31.25      31.25    427256\n",
       "2023-03-09 14:00:00  31.25  31.50  31.00  31.25      31.25  11293468\n",
       "2023-03-09 15:00:00  31.25  31.25  31.00  31.25      31.25   1875025\n",
       "2023-03-09 16:00:00  31.25  31.25  31.00  31.25      31.25   3481345\n",
       "2023-03-10 10:00:00  30.50  30.75  30.50  30.75      30.75         0\n",
       "2023-03-10 11:00:00  30.50  30.75  30.50  30.75      30.75   1811911\n",
       "2023-03-10 12:00:00  30.75  30.75  30.50  30.75      30.75    486808\n",
       "2023-03-10 14:00:00  30.50  30.75  30.50  30.75      30.75   1689162\n",
       "2023-03-10 15:00:00  30.75  30.75  30.50  30.50      30.50   1536527\n",
       "2023-03-10 16:00:00  30.75  30.75  30.50  30.75      30.75   3150765\n",
       "2023-03-13 10:00:00  30.50  30.75  30.25  30.75      30.75   7464223\n",
       "2023-03-13 11:00:00  30.75  31.00  30.50  31.00      31.00   6826408"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import datetime\n",
    "\n",
    "data = yf.download(tickers='ptt.bk', period='10d', interval='1h',progress=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c649cbfb4c288b76adc3417e379a1dde9839d571840c9111dd43481f544c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
