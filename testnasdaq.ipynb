{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'ABNB', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AEP', 'ALGN', 'AMAT', 'ASML', 'ATVI', 'AVGO', 'BIIB', 'BKR', 'CDNS', 'CEG', 'CHTR', 'CMCSA', 'COST', 'CPRT', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTSH', 'DDOG', 'DLTR', 'DXCM', 'EA', 'ENPH', 'EXC', 'FANG', 'FAST', 'FISV', 'FTNT', 'GILD', 'HON', 'IDXX', 'ILMN', 'INTU', 'ISRG', 'JD', 'KDP', 'KHC', 'KLAC', 'LRCX', 'LULU', 'MAR', 'MCHP', 'MELI', 'NXPI', 'ODFL', 'ORLY', 'PANW', 'PAYX', 'PCAR', 'PDD', 'PYPL', 'QCOM', 'REGN', 'RIVN', 'ROST', 'SGEN', 'SNPS', 'TEAM', 'TSLA', 'TXN', 'VRSK', 'VRTX', 'WBA', 'WDAY', 'XEL', 'ZM', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "nasdaq = []\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.nasdaq.com/market-activity/quotes/nasdaq-ndx-index')\n",
    "elements = driver.find_elements(By.XPATH, '//th[@class=\"nasdaq-ndx-index__cell nasdaq-ndx-index__cell--heading\"]')\n",
    "\n",
    "for element in elements:\n",
    "    nasdaq.append(element.text)\n",
    "print(nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- ADI: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- ADP: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- AEP: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- BKR: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- CSX: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- EXC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- HON: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- KHC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- KLAC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- TXN: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- XEL: Exception('Lost data during merge despite all attempts to align data (see above)')\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "for stock in nasdaq:\n",
    "    datahr = yf.download(tickers=stock,period=\"2y\",interval=\"1h\",progress=False)\n",
    "    datad = yf.download(tickers=stock,period='10y',interval=\"1d\",progress=False)\n",
    "    datamo = yf.download(tickers=stock,period='max',interval=\"1mo\",progress=False)\n",
    "\n",
    "    datahr['Ticker'] = stock\n",
    "\n",
    "    datad.index.names = ['Datetime']\n",
    "\n",
    "    datad['Ticker'] = stock\n",
    "\n",
    "    datamo.index.names = ['Datetime']\n",
    "\n",
    "    datamo['Ticker'] = stock\n",
    "\n",
    "    datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-16</th>\n",
       "      <td>135.490005</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>132.789993</td>\n",
       "      <td>133.190002</td>\n",
       "      <td>131.605835</td>\n",
       "      <td>80576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>132.220001</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>129.283798</td>\n",
       "      <td>97918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18</th>\n",
       "      <td>129.199997</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.410004</td>\n",
       "      <td>129.710007</td>\n",
       "      <td>128.167236</td>\n",
       "      <td>96856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>130.240005</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>129.869995</td>\n",
       "      <td>128.325333</td>\n",
       "      <td>87668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22</th>\n",
       "      <td>128.009995</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>124.501358</td>\n",
       "      <td>103916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>150.639999</td>\n",
       "      <td>155.229996</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>154.649994</td>\n",
       "      <td>154.414230</td>\n",
       "      <td>83322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>153.880005</td>\n",
       "      <td>154.580002</td>\n",
       "      <td>151.169998</td>\n",
       "      <td>151.919998</td>\n",
       "      <td>151.688400</td>\n",
       "      <td>64120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>153.779999</td>\n",
       "      <td>154.330002</td>\n",
       "      <td>150.419998</td>\n",
       "      <td>150.869995</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>56007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>149.460007</td>\n",
       "      <td>151.339996</td>\n",
       "      <td>149.220001</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>57409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>150.951996</td>\n",
       "      <td>153.690002</td>\n",
       "      <td>150.919998</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>21700329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Datetime                                                                 \n",
       "2021-02-16  135.490005  136.009995  132.789993  133.190002  131.605835   \n",
       "2021-02-17  131.250000  132.220001  129.470001  130.839996  129.283798   \n",
       "2021-02-18  129.199997  130.000000  127.410004  129.710007  128.167236   \n",
       "2021-02-19  130.240005  130.710007  128.800003  129.869995  128.325333   \n",
       "2021-02-22  128.009995  129.720001  125.599998  126.000000  124.501358   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-02-07  150.639999  155.229996  150.639999  154.649994  154.414230   \n",
       "2023-02-08  153.880005  154.580002  151.169998  151.919998  151.688400   \n",
       "2023-02-09  153.779999  154.330002  150.419998  150.869995  150.639999   \n",
       "2023-02-10  149.460007  151.339996  149.220001  151.009995  151.009995   \n",
       "2023-02-13  150.951996  153.690002  150.919998  153.389999  153.389999   \n",
       "\n",
       "               Volume  \n",
       "Datetime               \n",
       "2021-02-16   80576300  \n",
       "2021-02-17   97918500  \n",
       "2021-02-18   96856700  \n",
       "2021-02-19   87668800  \n",
       "2021-02-22  103916400  \n",
       "...               ...  \n",
       "2023-02-07   83322600  \n",
       "2023-02-08   64120100  \n",
       "2023-02-09   56007100  \n",
       "2023-02-10   57409100  \n",
       "2023-02-13   21700329  \n",
       "\n",
       "[503 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datad = yf.download(tickers='AAPL',period=\"2y\",interval=\"1d\",progress=False)\n",
    "datad.index.names = ['Datetime']\n",
    "datad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "   Ticker     Industry Group                          Sector      Index\n",
      "0    AAPL         Technology            Consumer Electronics  NASDAQ100\n",
      "1    ABNB  Consumer Cyclical                 Travel Services  NASDAQ100\n",
      "2    ADBE         Technology         Software—Infrastructure  NASDAQ100\n",
      "3     ADI         Technology                  Semiconductors  NASDAQ100\n",
      "4     ADP        Industrials  Staffing & Employment Services  NASDAQ100\n",
      "..    ...                ...                             ...        ...\n",
      "70    WBA         Healthcare        Pharmaceutical Retailers  NASDAQ100\n",
      "71   WDAY         Technology            Software—Application  NASDAQ100\n",
      "72    XEL          Utilities    Utilities—Regulated Electric  NASDAQ100\n",
      "73     ZM         Technology            Software—Application  NASDAQ100\n",
      "74     ZS         Technology         Software—Infrastructure  NASDAQ100\n",
      "\n",
      "[75 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_link = []\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "print(len(nasdaq))\n",
    "for j in nasdaq:\n",
    "    InsSec = []\n",
    "    driver.get(\"https://finance.yahoo.com/quote/%s/profile?p=%s\" %(j,j))\n",
    "    numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "    for i in numlink[:2]:\n",
    "        InsSec.append(i.text)\n",
    "    df1 = pd.DataFrame({'Ticker': [j], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "    df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "    print('-------')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_info',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c649cbfb4c288b76adc3417e379a1dde9839d571840c9111dd43481f544c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
