{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'ABNB', 'ADBE', 'ADI', 'ADP', 'ADSK', 'AEP', 'ALGN', 'AMAT', 'ASML', 'ATVI', 'AVGO', 'BIIB', 'BKR', 'CDNS', 'CEG', 'CHTR', 'CMCSA', 'COST', 'CPRT', 'CRWD', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTSH', 'DDOG', 'DLTR', 'DXCM', 'EA', 'ENPH', 'EXC', 'FANG', 'FAST', 'FISV', 'FTNT', 'GILD', 'HON', 'IDXX', 'ILMN', 'INTU', 'ISRG', 'JD', 'KDP', 'KHC', 'KLAC', 'LRCX', 'LULU', 'MAR', 'MCHP', 'MELI', 'NXPI', 'ODFL', 'ORLY', 'PANW', 'PAYX', 'PCAR', 'PDD', 'PYPL', 'QCOM', 'REGN', 'RIVN', 'ROST', 'SGEN', 'SNPS', 'TEAM', 'TSLA', 'TXN', 'VRSK', 'VRTX', 'WBA', 'WDAY', 'XEL', 'ZM', 'ZS']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "nasdaq = []\n",
    "\n",
    "# Create a SQL connection to our SQLite database\n",
    "con = sqlite3.connect(\"stock.sqlite\")\n",
    "cur = con.cursor()\n",
    "\n",
    "op = webdriver.ChromeOptions()\n",
    "#op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op) \n",
    "driver.get('https://www.nasdaq.com/market-activity/quotes/nasdaq-ndx-index')\n",
    "elements = driver.find_elements(By.XPATH, '//th[@class=\"nasdaq-ndx-index__cell nasdaq-ndx-index__cell--heading\"]')\n",
    "\n",
    "for element in elements:\n",
    "    nasdaq.append(element.text)\n",
    "print(nasdaq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "- ADI: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- ADP: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- AEP: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- BKR: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- CSX: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- EXC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- HON: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- KHC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- KLAC: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- TXN: Exception('Lost data during merge despite all attempts to align data (see above)')\n",
      "\n",
      "1 Failed download:\n",
      "- XEL: Exception('Lost data during merge despite all attempts to align data (see above)')\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "for stock in nasdaq:\n",
    "    datahr = yf.download(tickers=stock,period=\"2y\",interval=\"1h\",progress=False)\n",
    "    datad = yf.download(tickers=stock,period='10y',interval=\"1d\",progress=False)\n",
    "    datamo = yf.download(tickers=stock,period='max',interval=\"1mo\",progress=False)\n",
    "\n",
    "    datahr['Ticker'] = stock\n",
    "\n",
    "    datad.index.names = ['Datetime']\n",
    "\n",
    "    datad['Ticker'] = stock\n",
    "\n",
    "    datamo.index.names = ['Datetime']\n",
    "\n",
    "    datamo['Ticker'] = stock\n",
    "\n",
    "    datahr.to_sql('stock_table_hr',con=conn,if_exists='append',index=True)\n",
    "    datad.to_sql('stock_table_d',con=conn,if_exists='append',index=True)\n",
    "    datamo.to_sql('stock_table_mo',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-02-16</th>\n",
       "      <td>135.490005</td>\n",
       "      <td>136.009995</td>\n",
       "      <td>132.789993</td>\n",
       "      <td>133.190002</td>\n",
       "      <td>131.605835</td>\n",
       "      <td>80576300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-17</th>\n",
       "      <td>131.250000</td>\n",
       "      <td>132.220001</td>\n",
       "      <td>129.470001</td>\n",
       "      <td>130.839996</td>\n",
       "      <td>129.283798</td>\n",
       "      <td>97918500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-18</th>\n",
       "      <td>129.199997</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>127.410004</td>\n",
       "      <td>129.710007</td>\n",
       "      <td>128.167236</td>\n",
       "      <td>96856700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-19</th>\n",
       "      <td>130.240005</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>129.869995</td>\n",
       "      <td>128.325333</td>\n",
       "      <td>87668800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-02-22</th>\n",
       "      <td>128.009995</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>124.501358</td>\n",
       "      <td>103916400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07</th>\n",
       "      <td>150.639999</td>\n",
       "      <td>155.229996</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>154.649994</td>\n",
       "      <td>154.414230</td>\n",
       "      <td>83322600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08</th>\n",
       "      <td>153.880005</td>\n",
       "      <td>154.580002</td>\n",
       "      <td>151.169998</td>\n",
       "      <td>151.919998</td>\n",
       "      <td>151.688400</td>\n",
       "      <td>64120100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09</th>\n",
       "      <td>153.779999</td>\n",
       "      <td>154.330002</td>\n",
       "      <td>150.419998</td>\n",
       "      <td>150.869995</td>\n",
       "      <td>150.639999</td>\n",
       "      <td>56007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-10</th>\n",
       "      <td>149.460007</td>\n",
       "      <td>151.339996</td>\n",
       "      <td>149.220001</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>151.009995</td>\n",
       "      <td>57409100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-13</th>\n",
       "      <td>150.951996</td>\n",
       "      <td>153.690002</td>\n",
       "      <td>150.919998</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>153.389999</td>\n",
       "      <td>21700329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Datetime                                                                 \n",
       "2021-02-16  135.490005  136.009995  132.789993  133.190002  131.605835   \n",
       "2021-02-17  131.250000  132.220001  129.470001  130.839996  129.283798   \n",
       "2021-02-18  129.199997  130.000000  127.410004  129.710007  128.167236   \n",
       "2021-02-19  130.240005  130.710007  128.800003  129.869995  128.325333   \n",
       "2021-02-22  128.009995  129.720001  125.599998  126.000000  124.501358   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-02-07  150.639999  155.229996  150.639999  154.649994  154.414230   \n",
       "2023-02-08  153.880005  154.580002  151.169998  151.919998  151.688400   \n",
       "2023-02-09  153.779999  154.330002  150.419998  150.869995  150.639999   \n",
       "2023-02-10  149.460007  151.339996  149.220001  151.009995  151.009995   \n",
       "2023-02-13  150.951996  153.690002  150.919998  153.389999  153.389999   \n",
       "\n",
       "               Volume  \n",
       "Datetime               \n",
       "2021-02-16   80576300  \n",
       "2021-02-17   97918500  \n",
       "2021-02-18   96856700  \n",
       "2021-02-19   87668800  \n",
       "2021-02-22  103916400  \n",
       "...               ...  \n",
       "2023-02-07   83322600  \n",
       "2023-02-08   64120100  \n",
       "2023-02-09   56007100  \n",
       "2023-02-10   57409100  \n",
       "2023-02-13   21700329  \n",
       "\n",
       "[503 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datad = yf.download(tickers='AAPL',period=\"2y\",interval=\"1d\",progress=False)\n",
    "datad.index.names = ['Datetime']\n",
    "datad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "-------\n",
      "   Ticker     Industry Group                          Sector      Index\n",
      "0    AAPL         Technology            Consumer Electronics  NASDAQ100\n",
      "1    ABNB  Consumer Cyclical                 Travel Services  NASDAQ100\n",
      "2    ADBE         Technology         Softwareâ€”Infrastructure  NASDAQ100\n",
      "3     ADI         Technology                  Semiconductors  NASDAQ100\n",
      "4     ADP        Industrials  Staffing & Employment Services  NASDAQ100\n",
      "..    ...                ...                             ...        ...\n",
      "70    WBA         Healthcare        Pharmaceutical Retailers  NASDAQ100\n",
      "71   WDAY         Technology            Softwareâ€”Application  NASDAQ100\n",
      "72    XEL          Utilities    Utilitiesâ€”Regulated Electric  NASDAQ100\n",
      "73     ZM         Technology            Softwareâ€”Application  NASDAQ100\n",
      "74     ZS         Technology         Softwareâ€”Infrastructure  NASDAQ100\n",
      "\n",
      "[75 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By \n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "all_link = []\n",
    "op = webdriver.ChromeOptions()\n",
    "op.add_argument('headless') \n",
    "driver = webdriver.Chrome(options=op)\n",
    "df2 = pd.DataFrame()\n",
    "print(len(nasdaq))\n",
    "for j in nasdaq:\n",
    "    InsSec = []\n",
    "    driver.get(\"https://finance.yahoo.com/quote/%s/profile?p=%s\" %(j,j))\n",
    "    numlink = driver.find_elements(By.XPATH, '//span[@class=\"Fw(600)\"]')\n",
    "    for i in numlink[:2]:\n",
    "        InsSec.append(i.text)\n",
    "    df1 = pd.DataFrame({'Ticker': [j], 'Industry Group': [InsSec[0]], 'Sector': [InsSec[1]], 'Index': ['NASDAQ100']})\n",
    "    df2 = pd.concat([df2,df1],ignore_index=True)\n",
    "    print('-------')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"stock.sqlite\")\n",
    "df2.to_sql('stock_info',con=conn,if_exists='append',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "05c649cbfb4c288b76adc3417e379a1dde9839d571840c9111dd43481f544c80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
